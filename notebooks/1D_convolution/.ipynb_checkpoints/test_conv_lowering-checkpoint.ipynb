{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnx.helper as oh\n",
    "import onnx.numpy_helper as np_helper\n",
    "from onnx import TensorProto\n",
    "from pkgutil import get_data\n",
    "\n",
    "import finn.core.onnx_exec as oxe\n",
    "from finn.core.datatype import DataType\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.custom_op.general.im2col import compute_conv_output_dim_2D_padding\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from finn.util.basic import gen_finn_dt_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "import onnx \n",
    "\n",
    "def test_dilation(idt, k_H, k_W, ifm_dim_H, ifm_dim_W, ifm_ch, stride, padding, dilation):\n",
    "\n",
    "    if k_H > ifm_dim_H:\n",
    "        pytest.skip(\"Kernel height must be smaller than image height\")\n",
    "    if k_W > ifm_dim_W:\n",
    "        pytest.skip(\"Kernel width must be smaller than image height\")\n",
    "\n",
    "    wdt = idt\n",
    "    odt = DataType.INT32\n",
    "    ofm_ch = ifm_ch\n",
    "    pad_H = padding[0] + padding[2]\n",
    "    pad_W = padding[1] + padding[3]\n",
    "    ofm_dim_H = compute_conv_output_dim_2D_padding(ifm_dim_H, k_H, stride, pad_H)\n",
    "    ofm_dim_W = compute_conv_output_dim_2D_padding(ifm_dim_W, k_W, stride, pad_W)\n",
    "\n",
    "    # set up onnx model\n",
    "    inp = oh.make_tensor_value_info(\n",
    "        \"inp\", TensorProto.FLOAT, [1, ifm_ch, ifm_dim_H, ifm_dim_W]\n",
    "    )\n",
    "    outp = oh.make_tensor_value_info(\n",
    "        \"outp\", TensorProto.FLOAT, [1, ofm_ch, ofm_dim_H, ofm_dim_W]\n",
    "    )\n",
    "\n",
    "    W = oh.make_tensor_value_info(\"W\", TensorProto.FLOAT, [ofm_ch, ifm_ch, k_H, k_W])\n",
    "\n",
    "    dw_cnv = oh.make_node(\n",
    "        \"Conv\",\n",
    "        inputs=[\"inp\", \"W\"],\n",
    "        outputs=[\"outp\"],\n",
    "        kernel_shape=[k_H, k_W],\n",
    "        pads=padding,\n",
    "        strides=[stride, stride],\n",
    "        group=ifm_ch,\n",
    "        dilations=dilation\n",
    "    )\n",
    "    graph = oh.make_graph(\n",
    "        nodes=[dw_cnv],\n",
    "        name=\"dw_cnv_graph\",\n",
    "        inputs=[inp],\n",
    "        outputs=[outp],\n",
    "        value_info=[W],\n",
    "    )\n",
    "\n",
    "    model = oh.make_model(graph, producer_name=\"dws_cnv-model\")\n",
    "    model = ModelWrapper(model)\n",
    "    model.set_tensor_datatype(\"inp\", idt)\n",
    "    model.set_tensor_datatype(\"outp\", odt)\n",
    "    model.set_tensor_datatype(\"W\", wdt)\n",
    "    w_tensor = gen_finn_dt_tensor(wdt, [ofm_ch, ifm_ch, k_H, k_W])\n",
    "    model.set_initializer(\"W\", w_tensor)\n",
    "        \n",
    "    model = model.transform(InferShapes())\n",
    "\n",
    "    ###\n",
    "    model.save(\"/tmp/conv_node_test.onnx\")\n",
    "    showInNetron(\"/tmp/conv_node_test.onnx\")\n",
    "    \n",
    "    input_tensor = gen_finn_dt_tensor(idt, [1, ifm_ch, ifm_dim_H, ifm_dim_W])\n",
    "    input_dict = {\"inp\": input_tensor}\n",
    "    output_dict = oxe.execute_onnx(model, input_dict)\n",
    "    expected = output_dict[\"outp\"]\n",
    "\n",
    "    print(expected)\n",
    "    \n",
    "    #model = model.transform(LowerConvsToMatMul())\n",
    "    #output_dict = oxe.execute_onnx(model, input_dict)\n",
    "    #produced = output_dict[\"outp\"]\n",
    "    #assert (produced == expected).all()\n",
    "\n",
    "    # check if created nodes have attributes that indicate depthwise conv\n",
    "    #assert model.get_tensor_sparsity(\"W\") is not None\n",
    "    #im2col_node = getCustomOp(model.graph.node[1])\n",
    "    #assert im2col_node.get_nodeattr(\"depthwise\") == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Inferred shape and existing shape differ in dimension 2: (3) vs (4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-10d2a27f67f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdilation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtest_dilation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mifm_dim_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mifm_dim_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mifm_ch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-04832df29e51>\u001b[0m in \u001b[0;36mtest_dilation\u001b[0;34m(idt, k_H, k_W, ifm_dim_H, ifm_dim_W, ifm_ch, stride, padding, dilation)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInferShapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn-base/src/finn/core/modelwrapper.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, transformation, make_deepcopy, cleanup, fix_float64)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mmodel_was_changed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             (transformed_model, model_was_changed) = transformation.apply(\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0mtransformed_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             )\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn-base/src/finn/transformation/infer_shapes.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mhidden_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_hide_finn_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# call regular ONNX shape inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;31m# bring back hidden ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0m_restore_finn_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/onnx/shape_inference.py\u001b[0m in \u001b[0;36minfer_shapes\u001b[0;34m(model, check_type)\u001b[0m\n\u001b[1;32m     33\u001b[0m                          'incorrect type: {}'.format(type(model)))\n\u001b[1;32m     34\u001b[0m     \u001b[0mmodel_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0minferred_model_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minferred_model_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Inferred shape and existing shape differ in dimension 2: (3) vs (4)"
     ]
    }
   ],
   "source": [
    "idt = DataType.INT2\n",
    "k_H = 2\n",
    "k_W = 2\n",
    "ifm_dim_H = 5\n",
    "ifm_dim_W = 5\n",
    "ifm_ch = 1\n",
    "stride = 1\n",
    "padding = [0,0,0,0]\n",
    "dilation = [2, 2]\n",
    "\n",
    "test_dilation(idt, k_H, k_W, ifm_dim_H, ifm_dim_W, ifm_ch, stride, padding, dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conv_lowering_convmnist():\n",
    "\n",
    "    # load the onnx model\n",
    "    raw_m = get_data(\"finn.data\", \"onnx/mnist-conv/model.onnx\")\n",
    "    model = ModelWrapper(raw_m)\n",
    "    # model = model.transform(InferShapes())\n",
    "    # model = model.transform(FoldConstants())\n",
    "    raw_i = get_data(\"finn.data\", \"onnx/mnist-conv/test_data_set_0/input_0.pb\")\n",
    "    input_tensor = onnx.load_tensor_from_string(raw_i)\n",
    "    input_tensor = np_helper.to_array(input_tensor)\n",
    "    # execute imported model to get expected answer\n",
    "    input_name = model.graph.input[0].name\n",
    "    output_name = model.graph.output[0].name\n",
    "    input_dict = {input_name: input_tensor}\n",
    "    output_dict_e = oxe.execute_onnx(model, input_dict)\n",
    "    expected = output_dict_e[output_name]\n",
    "    # execute transformed model and compare\n",
    "    model = model.transform(LowerConvsToMatMul())\n",
    "    model = model.transform(InferShapes())\n",
    "    output_dict_p = oxe.execute_onnx(model, input_dict)\n",
    "    produced = output_dict_p[output_name]\n",
    "    assert np.isclose(produced, expected).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28:28 \t 28:28\n",
      "14:14 \t 14:14\n",
      "28:28 \t 28:28\n",
      "14:14 \t 14:14\n",
      "28:28 \t 28:28\n",
      "14:14 \t 14:14\n"
     ]
    }
   ],
   "source": [
    "test_conv_lowering_convmnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "import onnx \n",
    "\n",
    "def test_depthwise_conv_lowering(idt, k_H, k_W, ifm_dim_H, ifm_dim_W, ifm_ch, stride, padding):\n",
    "\n",
    "    if k_H > ifm_dim_H:\n",
    "        pytest.skip(\"Kernel height must be smaller than image height\")\n",
    "    if k_W > ifm_dim_W:\n",
    "        pytest.skip(\"Kernel width must be smaller than image height\")\n",
    "\n",
    "    wdt = idt\n",
    "    odt = DataType.INT32\n",
    "    ofm_ch = ifm_ch\n",
    "    pad_H = padding[0] + padding[2]\n",
    "    pad_W = padding[1] + padding[3]\n",
    "    ofm_dim_H = compute_conv_output_dim_2D_padding(ifm_dim_H, k_H, stride, pad_H)\n",
    "    ofm_dim_W = compute_conv_output_dim_2D_padding(ifm_dim_W, k_W, stride, pad_W)\n",
    "\n",
    "    # set up onnx model\n",
    "    inp = oh.make_tensor_value_info(\n",
    "        \"inp\", TensorProto.FLOAT, [1, ifm_ch, ifm_dim_H, ifm_dim_W]\n",
    "    )\n",
    "    outp = oh.make_tensor_value_info(\n",
    "        \"outp\", TensorProto.FLOAT, [1, ofm_ch, ofm_dim_H, ofm_dim_W]\n",
    "    )\n",
    "\n",
    "    W = oh.make_tensor_value_info(\"W\", TensorProto.FLOAT, [ofm_ch, 1, k_H, k_W])\n",
    "\n",
    "    dw_cnv = oh.make_node(\n",
    "        \"Conv\",\n",
    "        inputs=[\"inp\", \"W\"],\n",
    "        outputs=[\"outp\"],\n",
    "        kernel_shape=[k_H, k_W],\n",
    "        pads=padding,\n",
    "        strides=[stride, stride],\n",
    "        group=ifm_ch,\n",
    "    )\n",
    "    graph = oh.make_graph(\n",
    "        nodes=[dw_cnv],\n",
    "        name=\"dw_cnv_graph\",\n",
    "        inputs=[inp],\n",
    "        outputs=[outp],\n",
    "        value_info=[W],\n",
    "    )\n",
    "\n",
    "    model = oh.make_model(graph, producer_name=\"dws_cnv-model\")\n",
    "    model = ModelWrapper(model)\n",
    "    model.set_tensor_datatype(\"inp\", idt)\n",
    "    model.set_tensor_datatype(\"outp\", odt)\n",
    "    model.set_tensor_datatype(\"W\", wdt)\n",
    "    w_tensor = gen_finn_dt_tensor(wdt, [ofm_ch, 1, k_H, k_W])\n",
    "    model.set_initializer(\"W\", w_tensor)\n",
    "        \n",
    "    model = model.transform(InferShapes())\n",
    "\n",
    "    ###\n",
    "    model.save(\"/tmp/conv_node_test.onnx\")\n",
    "    showInNetron(\"/tmp/conv_node_test.onnx\")\n",
    "    \n",
    "    input_tensor = gen_finn_dt_tensor(idt, [1, ifm_ch, ifm_dim_H, ifm_dim_W])\n",
    "    input_dict = {\"inp\": input_tensor}\n",
    "    output_dict = oxe.execute_onnx(model, input_dict)\n",
    "    expected = output_dict[\"outp\"]\n",
    "\n",
    "    model = model.transform(LowerConvsToMatMul())\n",
    "    output_dict = oxe.execute_onnx(model, input_dict)\n",
    "    produced = output_dict[\"outp\"]\n",
    "    assert (produced == expected).all()\n",
    "\n",
    "    # check if created nodes have attributes that indicate depthwise conv\n",
    "    assert model.get_tensor_sparsity(\"W\") is not None\n",
    "    im2col_node = getCustomOp(model.graph.node[1])\n",
    "    assert im2col_node.get_nodeattr(\"depthwise\") == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/conv_node_test.onnx' at http://0.0.0.0:8081\n",
      "4:1 \t 2:3\n",
      "4:1 \t 2:3\n"
     ]
    }
   ],
   "source": [
    "idt = DataType.INT2\n",
    "k_H = 4\n",
    "k_W = 2\n",
    "ifm_dim_H = 4\n",
    "ifm_dim_W = 2\n",
    "ifm_ch = 2\n",
    "stride = 1\n",
    "padding = [0,1,0,1]\n",
    "\n",
    "test_depthwise_conv_lowering(idt, k_H, k_W, ifm_dim_H, ifm_dim_W, ifm_ch, stride, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conv_lowering_conv_1x1():\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    in_feature_dim_H = 7\n",
    "    in_feature_dim_W = 7\n",
    "    in_chn = 3\n",
    "    kernel_size = 1\n",
    "    out_feature_dim_H = in_feature_dim_H\n",
    "    out_feature_dim_W = in_feature_dim_W\n",
    "\n",
    "    input_shape = [1, in_chn, in_feature_dim_H, in_feature_dim_W]\n",
    "    output_shape = [1, in_chn, out_feature_dim_H, out_feature_dim_W]\n",
    "\n",
    "    conv_param_shape = [in_chn, in_chn, kernel_size, kernel_size]\n",
    "\n",
    "    conv_config = {}\n",
    "    conv_config[\"dilations\"] = [1, 1]\n",
    "    conv_config[\"group\"] = 1\n",
    "    conv_config[\"kernel_shape\"] = [kernel_size, kernel_size]\n",
    "    conv_config[\"pads\"] = [0, 0, 0, 0]\n",
    "    conv_config[\"strides\"] = [1, 1]\n",
    "\n",
    "    top_in = oh.make_tensor_value_info(\"top_in\", TensorProto.FLOAT, input_shape)\n",
    "    top_out = oh.make_tensor_value_info(\"top_out\", TensorProto.FLOAT, output_shape)\n",
    "\n",
    "    value_info = [oh.make_tensor_value_info(\"p1\", TensorProto.FLOAT, conv_param_shape)]\n",
    "\n",
    "    modelproto = oh.make_model(\n",
    "        oh.make_graph(\n",
    "            name=\"test\",\n",
    "            inputs=[top_in],\n",
    "            outputs=[top_out],\n",
    "            value_info=value_info,\n",
    "            nodes=[oh.make_node(\"Conv\", [\"top_in\", \"p1\"], [\"top_out\"], **conv_config)],\n",
    "        )\n",
    "    )\n",
    "    model = ModelWrapper(modelproto)\n",
    "    model = model.transform(InferShapes())\n",
    "    model.set_initializer(\"p1\", np.random.rand(*conv_param_shape).astype(np.float32))\n",
    "\n",
    "    new_model = model.transform(LowerConvsToMatMul())\n",
    "    inp_dict = {\"top_in\": np.random.rand(*input_shape).astype(np.float32)}\n",
    "\n",
    "    assert oxe.compare_execution(model, new_model, inp_dict)\n",
    "    assert new_model.graph.node[0].op_type == \"Transpose\"\n",
    "    assert new_model.graph.node[1].op_type == \"MatMul\"\n",
    "    assert new_model.graph.node[2].op_type == \"Transpose\"\n",
    "    assert len(new_model.graph.node) == 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conv_lowering_conv_1x1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_regular_conv_lowering(idt, k_H, k_W, ifm_dim_H, ifm_dim_W, ifm_ch, stride, padding):\n",
    "\n",
    "    if k_H > ifm_dim_H:\n",
    "        pytest.skip(\"Kernel height must be smaller than image height\")\n",
    "    if k_W > ifm_dim_W:\n",
    "        pytest.skip(\"Kernel width must be smaller than image height\")\n",
    "    # Ensure the right padding parameters are set\n",
    "    if ifm_dim_H == 1:\n",
    "        padding[0] = 0\n",
    "        padding[2] = 0\n",
    "    if ifm_dim_W == 1:\n",
    "        padding[1] = 0\n",
    "        padding[3] = 0\n",
    "\n",
    "    wdt = idt\n",
    "    odt = DataType.INT32\n",
    "    ofm_ch = ifm_ch\n",
    "    pad_W = padding[0] + padding[2]\n",
    "    pad_H = padding[1] + padding[3]\n",
    "    ofm_dim_H = compute_conv_output_dim_2D_padding(ifm_dim_H, k_H, stride, pad_H)\n",
    "    ofm_dim_W = compute_conv_output_dim_2D_padding(ifm_dim_W, k_W, stride, pad_W)\n",
    "\n",
    "    # set up onnx model\n",
    "    inp = oh.make_tensor_value_info(\n",
    "        \"inp\", TensorProto.FLOAT, [1, ifm_ch, ifm_dim_H, ifm_dim_W]\n",
    "    )\n",
    "    outp = oh.make_tensor_value_info(\n",
    "        \"outp\", TensorProto.FLOAT, [1, ofm_ch, ofm_dim_H, ofm_dim_W]\n",
    "    )\n",
    "\n",
    "    W = oh.make_tensor_value_info(\"W\", TensorProto.FLOAT, [ofm_ch, ifm_ch, k_H, k_W])\n",
    "\n",
    "    dw_cnv = oh.make_node(\n",
    "        \"Conv\",\n",
    "        inputs=[\"inp\", \"W\"],\n",
    "        outputs=[\"outp\"],\n",
    "        kernel_shape=[k_H, k_W],\n",
    "        pads=padding,\n",
    "        strides=[stride, stride],\n",
    "        group=1,\n",
    "    )\n",
    "    graph = oh.make_graph(\n",
    "        nodes=[dw_cnv],\n",
    "        name=\"dw_cnv_graph\",\n",
    "        inputs=[inp],\n",
    "        outputs=[outp],\n",
    "        value_info=[W],\n",
    "    )\n",
    "\n",
    "    model = oh.make_model(graph, producer_name=\"dws_cnv-model\")\n",
    "    model = ModelWrapper(model)\n",
    "    model.set_tensor_datatype(\"inp\", idt)\n",
    "    model.set_tensor_datatype(\"outp\", odt)\n",
    "    model.set_tensor_datatype(\"W\", wdt)\n",
    "    w_tensor = gen_finn_dt_tensor(wdt, [ofm_ch, ifm_ch, k_H, k_W])\n",
    "    model.set_initializer(\"W\", w_tensor)\n",
    "    model = model.transform(InferShapes())\n",
    "\n",
    "    input_tensor = gen_finn_dt_tensor(idt, [1, ifm_ch, ifm_dim_H, ifm_dim_W])\n",
    "    input_dict = {\"inp\": input_tensor}\n",
    "    output_dict = oxe.execute_onnx(model, input_dict)\n",
    "    expected = output_dict[\"outp\"]\n",
    "\n",
    "    model = model.transform(LowerConvsToMatMul())\n",
    "    output_dict = oxe.execute_onnx(model, input_dict)\n",
    "    produced = output_dict[\"outp\"]\n",
    "    assert (produced == expected).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idt = DataType.INT2\n",
    "k_H = 4\n",
    "k_W = 1\n",
    "ifm_dim_H = 4\n",
    "ifm_dim_W = 1\n",
    "ifm_ch = 2\n",
    "stride = 1\n",
    "padding = [1,0,1,0]\n",
    "\n",
    "test_depthwise_conv_lowering(idt, k_H, k_W, ifm_dim_H, ifm_dim_W, ifm_ch, stride, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def _auto_pad_to_explicit_padding(autopad_str, idim_H, idim_W, k_H, k_W, stride, n_dims):\n",
    "    pad_total_H = (stride - 1) * idim_H - stride + k_H\n",
    "    pad_total_W = (stride - 1) * idim_W - stride + k_W\n",
    "    pad_half_small_H = int((pad_total_H / 2))\n",
    "    pad_half_small_W = int((pad_total_W / 2))\n",
    "    pad_half_large_H = pad_total_H - pad_half_small_H\n",
    "    pad_half_large_W = pad_total_W - pad_half_small_W\n",
    "    if autopad_str == \"VALID\":\n",
    "        return [0 for i in range(2 * n_dims)]\n",
    "    elif autopad_str == \"SAME_UPPER\":\n",
    "        return [pad_half_small_H, pad_half_small_W, pad_half_large_H, pad_half_large_W]\n",
    "    elif autopad_str == \"SAME_LOWER\":\n",
    "        return [pad_half_large_H, pad_half_large_W, pad_half_small_H, pad_half_small_W]\n",
    "    else:\n",
    "        raise Exception(\"Unsupported auto_pad: \" + autopad_str)\n",
    "        \n",
    "a = _auto_pad_to_explicit_padding(\"SAME_LOWER\", 5, 5, 2, 2, 1, 2)        \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting relevant conv node attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do: find out how to map conv node input to what is expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from finn.util.visualization import showInNetron\n",
    "import onnx\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.util.basic import *\n",
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "from finn.transformation.fold_constants import FoldConstants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"/tmp/quartznet.onnx\"\n",
    "#model = ModelWrapper(file_name)\n",
    "#model = model.transform(InferShapes())\n",
    "#model = model.transform(FoldConstants())\n",
    "#model = model.transform(GiveUniqueNodeNames())\n",
    "#model = model.transform(GiveReadableTensorNames())\n",
    "#model = model.transform(InferDataTypes())\n",
    "#model = model.transform(RemoveStaticGraphInputs())\n",
    "#model.save(\"/tmp/quartznet_cleaned.onnx\")\n",
    "file_name = \"/tmp/quartznet_cleaned.onnx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idt, k_H, k_W, ifm_dim_H, ifm_dim_W, ifm_ch, stride, padding)\n",
    "model = ModelWrapper(file_name)\n",
    "conv_node_count=0\n",
    "idt = []\n",
    "k_W = []\n",
    "ifm_dim_W = []\n",
    "ifm_ch = []\n",
    "stride = []\n",
    "padding = []\n",
    "group = []\n",
    "for n in model.graph.node:\n",
    "    if(n.op_type==\"Conv\"):\n",
    "        conv_node_count = conv_node_count+1\n",
    "        input_name = n.input[0]\n",
    "        input_datatype = model.get_tensor_datatype(input_name)\n",
    "        idt.append(input_datatype)\n",
    "        \n",
    "        weight_name = n.input[1]\n",
    "        weight_shape = model.get_tensor_shape(weight_name)\n",
    "        k_W.append(weight_shape[2])\n",
    "\n",
    "        input_shape = model.get_tensor_shape(input_name)\n",
    "        ifm_dim_W.append(input_shape[2])\n",
    "\n",
    "        ifm_ch.append(input_shape[1])\n",
    "        \n",
    "        strds = get_by_name(n.attribute, \"strides\", \"name\").ints[0]\n",
    "        stride.append(strds)\n",
    "        \n",
    "        pads = [0, 0, get_by_name(n.attribute, \"pads\", \"name\").ints[0], get_by_name(n.attribute, \"pads\", \"name\").ints[1]] # Note: I assumed dim(H)=1\n",
    "        padding.append(pads)\n",
    "        \n",
    "        grp = get_by_name(n.attribute, \"group\", \"name\").i\n",
    "        group.append(grp)\n",
    "        \n",
    "ifm_dim_H = [1]*conv_node_count        \n",
    "k_H = [1]*conv_node_count\n",
    "\n",
    "#print(\"{}\\n{}\".format(len(padding),padding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    print(group[i])\n",
    "    test_depthwise_conv_lowering(DataType.INT8, k_H[i], k_W[i], ifm_dim_H[i], ifm_dim_W[i], ifm_ch[i], stride[i], padding[i], group[i])\n",
    "    print(\"Test {} passed\" .format(i))\n",
    "    \n",
    "#idt = DataType.INT2\n",
    "#k_H = k[0][0]\n",
    "#k_W = k[0][1]\n",
    "#ifm_dim = [[4,4]]\n",
    "#ifm_dim_H = ifm_dim[0][0]\n",
    "#ifm_dim_W = ifm_dim[0][1]\n",
    "#ifm_ch = 2\n",
    "#stride = 1\n",
    "#padding = [0,0,0,0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
