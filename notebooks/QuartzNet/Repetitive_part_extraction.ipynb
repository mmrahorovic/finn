{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/tmp/quartznet.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdd190faa20>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get onnx file, run in terminal:\n",
    "# python setup.py test --addopts \"-k test_brevitas_quartznet\" \n",
    "import numpy as np\n",
    "from finn.util.visualization import showInNetron\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "\n",
    "file_name = '/tmp/quartznet.onnx'\n",
    "showInNetron(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Conv+Mul+Mt node in QuartzNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from finn.util.basic import gen_finn_dt_tensor\n",
    "from finn.core.datatype import DataType\n",
    "from finn.util.basic import get_by_name\n",
    "\n",
    "\n",
    "def set_all_initializers(model):\n",
    "    \"\"\" Sets all initializers of the graph to a random value. \"\"\"\n",
    "    for n in model.graph.node:\n",
    "        if len(n.input) > 1:\n",
    "            init_name = n.input[1]\n",
    "            init_shape = model.get_tensor_shape(init_name)\n",
    "            init_val = gen_finn_dt_tensor(DataType.FLOAT32, init_shape)\n",
    "            model.set_initializer(init_name, init_val)\n",
    "\n",
    "Conv1_node = onnx.helper.make_node(\n",
    "    \"Conv\",\n",
    "    inputs=['in1_conv1', 'in2_conv1'],\n",
    "    outputs=['out1_conv1'],\n",
    "    name=\"Conv1\",\n",
    "    dilations=[1],\n",
    "    group=256,\n",
    "    kernel_shape=[33],\n",
    "    pads=[16, 16],\n",
    "    strides=[1]\n",
    ")\n",
    "\n",
    "Mul1_node = onnx.helper.make_node(\n",
    "    \"Mul\",\n",
    "    inputs=['out1_conv1', 'in2_mul1'],\n",
    "    outputs=['out1_mul1']\n",
    ")\n",
    "\n",
    "MultiThreshold1_node = onnx.helper.make_node(\n",
    "    \"MultiThreshold\",\n",
    "    inputs=['out1_mul1', 'in2_mt1'],\n",
    "    outputs=['out1_mt1'],\n",
    "    out_dtype='UINT4'\n",
    ")\n",
    "\n",
    "\n",
    "# Inputs\n",
    "in1_conv1 = onnx.helper.make_tensor_value_info(\"in1_conv1\", onnx.TensorProto.FLOAT, [1, 256, 128])\n",
    "out1_add7 = onnx.helper.make_tensor_value_info(\"out1_mt1\", onnx.TensorProto.FLOAT, [1, 256, 128])\n",
    "\n",
    "# Value infos\n",
    "out1_conv1 = onnx.helper.make_tensor_value_info(\"out1_conv1\", onnx.TensorProto.FLOAT, [1, 256, 128])\n",
    "out1_mul1 = onnx.helper.make_tensor_value_info(\"out1_mul1\", onnx.TensorProto.FLOAT, [1, 256, 128])\n",
    "\n",
    "# Initializers\n",
    "in2_conv1 = onnx.helper.make_tensor_value_info(\"in2_conv1\", onnx.TensorProto.FLOAT, [256, 1, 33])\n",
    "in2_mul1 = onnx.helper.make_tensor_value_info(\"in2_mul1\", onnx.TensorProto.FLOAT, [1])\n",
    "in2_mt1 = onnx.helper.make_tensor_value_info(\"in2_mt1\", onnx.TensorProto.FLOAT, [256, 15])\n",
    "\n",
    "# Graph\n",
    "graph = onnx.helper.make_graph(\n",
    "    nodes=[\n",
    "        Conv1_node,\n",
    "        Mul1_node,\n",
    "        MultiThreshold1_node\n",
    "    ],\n",
    "    name=\"test_graph\",\n",
    "    inputs=[in1_conv1],\n",
    "    outputs=[out1_add7],\n",
    "    value_info=[\n",
    "        out1_conv1,\n",
    "        out1_mul1,\n",
    "        in2_conv1,\n",
    "        in2_mul1, \n",
    "        in2_mt1\n",
    "    ]\n",
    ")\n",
    "\n",
    "onnx_model = onnx.helper.make_model(graph, producer_name=\"4d_conversion_test-model\")\n",
    "model = ModelWrapper(onnx_model)\n",
    "set_all_initializers(model)\n",
    "model.save(\"/tmp/conv_mul_mt_graph.onnx\")\n",
    "\n",
    "## 3D to 4D\n",
    "from finn.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors\n",
    "model = ModelWrapper(\"/tmp/conv_mul_mt_graph.onnx\")\n",
    "model = model.transform(Change3DTo4DTensors())\n",
    "model.save(\"/tmp/conv_mul_mt_graph_4d.onnx\")\n",
    "\n",
    "## Streamline\n",
    "from finn.transformation.streamline.absorb import AbsorbMulIntoMultiThreshold\n",
    "model = ModelWrapper(\"/tmp/conv_mul_mt_graph_4d.onnx\")\n",
    "model = model.transform(AbsorbMulIntoMultiThreshold())\n",
    "model.save(\"/tmp/conv_mul_mt_graph_streamlined.onnx\")\n",
    "\n",
    "## Lowering\n",
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "model = ModelWrapper(\"/tmp/conv_mul_mt_graph_streamlined.onnx\")\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model.save(\"/tmp/conv_mul_mt_graph_lowered.onnx\")\n",
    "\n",
    "## Convert to HLS\n",
    "#from finn.transformation.fpgadataflow.convert_to_hls_layers import InferConvInpGen\n",
    "#model = ModelWrapper(\"/tmp/conv_mul_mt_graph_lowered.onnx\")\n",
    "#model = model.transform(InferConvInpGen())\n",
    "#model.save(\"/tmp/conv_mul_mt_graph_hls.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"/tmp/conv_mul_mt_graph.onnx\"\n",
    "file2 = \"/tmp/conv_mul_mt_graph_4d.onnx\"\n",
    "file3 = \"/tmp/conv_mul_mt_graph_streamlined.onnx\"\n",
    "file4 = \"/tmp/conv_mul_mt_graph_lowered.onnx\"\n",
    "#ile5 = \"/tmp/conv_mul_mt_graph_hls.onnx\"\n",
    "\n",
    "showInNetron(file4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct FMPadding_Batch + ConvInputGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transpose\n",
      "Im2Col\n",
      "MatMul\n",
      "Transpose\n",
      "MultiThreshold\n",
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/conv_mul_mt_graph_hls.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f7b66074400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnx\n",
    "from finn.util.basic import gen_finn_dt_tensor\n",
    "from finn.core.datatype import DataType\n",
    "from finn.util.basic import get_by_name\n",
    "\n",
    "model=ModelWrapper(\"/tmp/conv_mul_mt_graph_lowered.onnx\")\n",
    "\n",
    "node_ind=0\n",
    "for n in model.graph.node:\n",
    "    node_ind += 1\n",
    "    if n.op_type=='Im2Col':\n",
    "        padding_node = onnx.helper.make_node(\n",
    "        \"FMPadding_Batch\",\n",
    "        [n.input[0]],\n",
    "        [n.output[0]],\n",
    "        domain=\"finn.custom_op.fpgadataflow\",\n",
    "        backend=\"fpgadataflow\",\n",
    "        ImgDim=100,\n",
    "        Padding=1,\n",
    "        NumChannels=1,\n",
    "        inputDataType=onnx.TensorProto.FLOAT,\n",
    "        SIMD=1\n",
    "        )\n",
    "        #graph.node.remove(n)\n",
    "        graph.node.insert(node_ind, padding_node)\n",
    "\n",
    "for n in model.graph.node:\n",
    "    print(n.op_type)\n",
    "model.save(\"/tmp/conv_mul_mt_graph_hls.onnx\")\n",
    "showInNetron(\"/tmp/conv_mul_mt_graph_hls.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting repetitive part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Mul_3': 9, 'MultiThreshold_13': 68}, {'Mul_26': 69, 'MultiThreshold_25': 128}, {'Mul_49': 129, 'MultiThreshold_37': 188}, {'Mul_72': 189, 'MultiThreshold_49': 248}, {'Mul_95': 249, 'MultiThreshold_61': 308}, {'Mul_118': 309, 'MultiThreshold_73': 368}, {'Mul_141': 369, 'MultiThreshold_85': 428}, {'Mul_164': 429, 'MultiThreshold_97': 488}, {'Mul_187': 489, 'MultiThreshold_109': 548}, {'Mul_210': 549, 'MultiThreshold_121': 608}, {'Mul_233': 609, 'MultiThreshold_133': 668}, {'Mul_256': 669, 'MultiThreshold_145': 728}, {'Mul_279': 729, 'MultiThreshold_157': 788}, {'Mul_302': 789, 'MultiThreshold_169': 848}, {'Mul_325': 849, 'MultiThreshold_181': 908}]\n",
      "[9, 68]\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/quartznet_repetitive_nodes.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdd190fa9e8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from finn.util.visualization import showInNetron\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.general import *\n",
    "import copy\n",
    "\n",
    "model = ModelWrapper(\"/tmp/quartznet.onnx\")\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames.onnx\")\n",
    "#showInNetron(\"/tmp/quartznet_uniqueNames.onnx\")\n",
    "\n",
    "list_of_repetitions = []\n",
    "for idx, n in enumerate(model.graph.node):\n",
    "    is_fork = model.is_fork_node(n)\n",
    "    if is_fork is True:\n",
    "        rep = {}\n",
    "        start_node_id = idx\n",
    "        rep[n.name] = idx\n",
    "        for idx, n in enumerate(model.graph.node):\n",
    "            if idx<=start_node_id:\n",
    "                continue\n",
    "            is_join = model.is_join_node(n)\n",
    "            if is_join is True:\n",
    "                end_node_id = idx+1 # one node after the join node\n",
    "                end_node_name = model.graph.node[end_node_id].name\n",
    "                rep[end_node_name] = end_node_id\n",
    "                list_of_repetitions.append(rep)\n",
    "                break\n",
    "        \n",
    "print(\"{}\".format(list_of_repetitions))\n",
    "\n",
    "rep_structure = list_of_repetitions[0] #0-14\n",
    "start_end = []\n",
    "for v in rep_structure.values():\n",
    "    start_end.append(v)\n",
    "print(start_end)\n",
    "start_node_id = start_end[0]\n",
    "end_node_id = start_end[1]\n",
    "\n",
    "nodes = copy.deepcopy(model.graph.node)\n",
    "for idx, n in enumerate(nodes):\n",
    "    if idx<start_node_id or idx>end_node_id:\n",
    "        model.graph.node.remove(n)\n",
    "\n",
    "model.transform(RemoveUnusedTensors())\n",
    "        \n",
    "model.save(\"/tmp/quartznet_repetitive_nodes.onnx\")\n",
    "showInNetron(\"/tmp/quartznet_repetitive_nodes.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/quartznet_repetitive_nodes_subpart.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe8fd306b00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from onnx import TensorProto\n",
    "from onnx import helper as oh\n",
    "import onnx\n",
    "\n",
    "model = ModelWrapper(\"/tmp/quartznet_repetitive_nodes.onnx\")\n",
    "\n",
    "in_tensor=onnx.helper.make_tensor_value_info(\"in_tensor\", onnx.TensorProto.FLOAT, [1, 256, 128])\n",
    "out_tensor=onnx.helper.make_tensor_value_info(\"out_tensor\", onnx.TensorProto.FLOAT, [1, 256, 128])\n",
    "\n",
    "old_input = model.graph.input[0]\n",
    "model.graph.input.remove(old_input)\n",
    "model.graph.input.extend([in_tensor])\n",
    "\n",
    "old_output = model.graph.output[0]\n",
    "model.graph.output.remove(old_output)\n",
    "model.graph.output.extend([out_tensor])\n",
    "\n",
    "input_node = model.graph.node[0]\n",
    "input_node.input[0] = 'in_tensor'\n",
    "\n",
    "output_node = model.graph.node[-1]\n",
    "output_node.output[0] = 'out_tensor'\n",
    "\n",
    "##### To have unique initializers:\n",
    "#list_of_initializers = []\n",
    "#for n in model.graph.node:\n",
    "#    init_name = n.input[1]\n",
    "#    if init_name in list_of_initializers:\n",
    "#        init_val = model.get_initializer(n.input[1])\n",
    "#        init_shape = np.shape(init_val)\n",
    "#        if len(init_shape) < 1:\n",
    "#            init_shape = (1,)       \n",
    "#        new_init = oh.make_tensor_value_info(\n",
    "#            model.make_new_valueinfo_name(), TensorProto.FLOAT, init_shape\n",
    "#        )\n",
    "#        model.graph.value_info.append(new_init)\n",
    "#        model.set_initializer(new_init.name, init_val)\n",
    "#        n.input[1] = new_init.name\n",
    "#    else:\n",
    "#        list_of_initializers.append(n.input[1])\n",
    "#####\n",
    "\n",
    "from finn.transformation.general import GiveRandomTensorNames, GiveReadableTensorNames\n",
    "model = model.transform(GiveRandomTensorNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "\n",
    "model.save(\"/tmp/quartznet_repetitive_nodes_subpart.onnx\")\n",
    "showInNetron(\"/tmp/quartznet_repetitive_nodes_subpart.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For running tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.general import GiveRandomTensorNames, GiveReadableTensorNames, GiveUniqueNodeNames\n",
    "model = ModelWrapper(\"/tmp/quartznet.onnx\")\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveRandomTensorNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model.save(\"/tmp/quartznet_uniqueNames.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn/src/finn/transformation/streamline/absorb.py:177: RuntimeWarning: overflow encountered in true_divide\n",
      "  Tnew = T / A.reshape(-1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313.2522694749641\n"
     ]
    }
   ],
   "source": [
    "# Add timer and test streamlining over complete QuartzNet (if even possible)\n",
    "from finn.transformation.streamline import *\n",
    "from finn.transformation.streamline.reorder import MoveMulPastDWConv, MoveLinearPastEltwiseAdd, MoveMulPastFork\n",
    "from finn.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors\n",
    "from finn.util.basic import get_by_name\n",
    "from finn.core.datatype import DataType\n",
    "import time\n",
    "\n",
    "model = ModelWrapper(\"/tmp/quartznet_uniqueNames.onnx\")\n",
    "\n",
    "## Convert to float128 to prevent overflow error \n",
    "#### However... the warning is still present..\n",
    "for n in model.graph.node:\n",
    "    if len(n.input)>1:\n",
    "        init_val = model.get_initializer(n.input[1])\n",
    "        if init_val is None:\n",
    "            continue\n",
    "        else:\n",
    "            old_dtype = init_val.dtype\n",
    "            init_val = init_val.astype(np.float64, casting='safe')\n",
    "            model.set_initializer(n.input[1], init_val)\n",
    "            new_dtype = model.get_initializer(n.input[1]).dtype\n",
    "\n",
    "            \n",
    "start_time = time.perf_counter()\n",
    "###############################################\n",
    "\n",
    "model = model.transform(Change3DTo4DTensors())\n",
    "model = model.transform(BatchNormToAffine())\n",
    "model = model.transform(MoveAddPastMul())\n",
    "model = model.transform(MoveAddPastConv())\n",
    "model = model.transform(MoveAddPastMul())\n",
    "model = model.transform(MoveMulPastFork())\n",
    "model = model.transform(MoveScalarMulPastConv())\n",
    "model = model.transform(MoveMulPastDWConv())\n",
    "model = model.transform(MoveLinearPastEltwiseAdd())\n",
    "model = model.transform(CollapseRepeatedAdd()) # (output node datatype is set to FLOAT32 by default here)\n",
    "model = model.transform(CollapseRepeatedMul()) # (output node datatype is set to FLOAT32 by default here)\n",
    "model = model.transform(AbsorbAddIntoMultiThreshold())\n",
    "model = model.transform(FactorOutMulSignMagnitude())\n",
    "model = model.transform(Absorb1BitMulIntoConv())\n",
    "model = model.transform(AbsorbMulIntoMultiThreshold())\n",
    "\n",
    "## Add quantization annotation to ensure RoundAndClipThresholds works\n",
    "for n in model.graph.node:\n",
    "    if n.op_type==\"MultiThreshold\":\n",
    "        odtype = get_by_name(n.attribute, \"out_dtype\", name_field=\"name\").s.decode(\"utf-8\")\n",
    "        dtype = getattr(DataType, odtype) \n",
    "        \n",
    "        # Set tensor datatype equal to expected output datatype\n",
    "        #model.set_tensor_datatype(n.input[0], dtype)\n",
    "        model.set_tensor_datatype(n.input[0], DataType.INT16)\n",
    "\n",
    "model = model.transform(RoundAndClipThresholds())\n",
    "\n",
    "#model = model.transform(LowerConvsToMatMul())\n",
    "\n",
    "#model = model.transform(AbsorbTransposeIntoMultiThreshold())\n",
    "\n",
    "###############################################\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "\n",
    "print(\"{}\".format(elapsed_time))\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/quartznet_uniqueNames_streamlined.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb2f7655320>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(\"/tmp/quartznet_uniqueNames_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "\n",
    "model = ModelWrapper(\"/tmp/quartznet_uniqueNames_streamlined_lowered105.onnx\")\n",
    "\n",
    "for i in range(0,5):\n",
    "    model = model.transform(LowerConvsToMatMul(), make_deepcopy=False, cleanup=True)\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames_streamlined_lowered110.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/quartznet_uniqueNames_streamlined_lowered90.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd8d9840d68>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('172.17.0.1', 58744)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\n",
      "    self.handle()\n",
      "  File \"/opt/conda/lib/python3.6/http/server.py\", line 418, in handle\n",
      "    self.handle_one_request()\n",
      "  File \"/opt/conda/lib/python3.6/http/server.py\", line 406, in handle_one_request\n",
      "    method()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/netron/server.py\", line 108, in do_GET\n",
      "    self.handler()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/netron/server.py\", line 105, in handler\n",
      "    self.wfile.write(buffer)\n",
      "  File \"/opt/conda/lib/python3.6/socketserver.py\", line 803, in write\n",
      "    self._sock.sendall(b)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "showInNetron(\"/tmp/quartznet_uniqueNames_streamlined_lowered90.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.575736945000244\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "model = model.transform(BatchNormToAffine())\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(\"{}\".format(elapsed_time))\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.949343863001559\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "model = model.transform(MoveAddPastMul())\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(\"{}\".format(elapsed_time))\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.04196755500743\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "model = model.transform(MoveAddPastConv())\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(\"{}\".format(elapsed_time))\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.880800654005725\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "model = model.transform(MoveAddPastMul())\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(\"{}\".format(elapsed_time))\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.69963248699787\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "model = model.transform(MoveMulPastFork())\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(\"{}\".format(elapsed_time))\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.285983692010632\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "model = model.transform(MoveScalarMulPastConv())\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(\"{}\".format(elapsed_time))\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.653810796007747\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "model = model.transform(MoveMulPastDWConv())\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(\"{}\".format(elapsed_time))\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.26131905199145\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "model = model.transform(MoveLinearPastEltwiseAdd())\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(\"{}\".format(elapsed_time))\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.518790405010805\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "model = model.transform(CollapseRepeatedAdd())\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(\"{}\".format(elapsed_time))\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.648896538012195\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "model = model.transform(CollapseRepeatedMul())\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(\"{}\".format(elapsed_time))\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.107187604997307\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "model = model.transform(AbsorbAddIntoMultiThreshold())\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(\"{}\".format(elapsed_time))\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.854793280013837\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "model = model.transform(FactorOutMulSignMagnitude())\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(\"{}\".format(elapsed_time))\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.46866467001382\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "model = model.transform(Absorb1BitMulIntoConv())\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(\"{}\".format(elapsed_time))\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn/src/finn/transformation/streamline/absorb.py:177: RuntimeWarning: overflow encountered in true_divide\n",
      "  Tnew = T / A.reshape(-1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7690469119988848\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "model = model.transform(AbsorbMulIntoMultiThreshold())\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(\"{}\".format(elapsed_time))\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6426278399885632\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "model = model.transform(RoundAndClipThresholds())\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(\"{}\".format(elapsed_time))\n",
    "\n",
    "model.save(\"/tmp/quartznet_uniqueNames_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply streamlining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/quartznet_repetitive_nodes_subpart_streamlined.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdd190fa9b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.transformation.streamline import *\n",
    "from finn.transformation.streamline.reorder import MoveMulPastDWConv, MoveLinearPastEltwiseAdd, MoveMulPastFork\n",
    "from finn.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors\n",
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from finn.transformation.streamline.absorb import AbsorbConsecutiveTransposes # No effect (only on consecutive transpose nodes)\n",
    "from finn.transformation.streamline.absorb import AbsorbTransposeIntoMultiThreshold\n",
    "from finn.util.basic import get_by_name\n",
    "from finn.core.datatype import DataType\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.util.visualization import showInNetron\n",
    "from finn.transformation.general import GiveRandomTensorNames, GiveReadableTensorNames, GiveUniqueParameterTensors\n",
    "\n",
    "model = ModelWrapper(\"/tmp/quartznet_repetitive_nodes_subpart.onnx\")\n",
    "\n",
    "model = model.transform(GiveRandomTensorNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(GiveUniqueParameterTensors())\n",
    "\n",
    "# Convert to supported format\n",
    "model = model.transform(Change3DTo4DTensors())\n",
    "\n",
    "# Collapse BatchNorm to Add and Mul\n",
    "model = model.transform(BatchNormToAffine())\n",
    "\n",
    "# Group additions\n",
    "model = model.transform(MoveAddPastMul())\n",
    "model = model.transform(MoveAddPastConv())\n",
    "model = model.transform(MoveAddPastMul())\n",
    "\n",
    "# Group multiplications\n",
    "#### Move mul past fork\n",
    "model = model.transform(MoveMulPastFork())\n",
    "model = model.transform(MoveScalarMulPastConv())\n",
    "model = model.transform(MoveMulPastDWConv())\n",
    "\n",
    "# Move Mul/Add past join node\n",
    "model = model.transform(MoveLinearPastEltwiseAdd())\n",
    "\n",
    "# Collapes additions & multiplications\n",
    "model = model.transform(CollapseRepeatedAdd())\n",
    "model = model.transform(CollapseRepeatedMul())\n",
    "\n",
    "# Absorb Add/Mul into multithreshold\n",
    "model = model.transform(AbsorbAddIntoMultiThreshold())\n",
    "model = model.transform(FactorOutMulSignMagnitude())\n",
    "model = model.transform(Absorb1BitMulIntoConv())\n",
    "model = model.transform(AbsorbMulIntoMultiThreshold())\n",
    "\n",
    "# Ensure thresholds are integers\n",
    "## Add quantization annotation to ensure RoundAndClipThresholds works\n",
    "for n in model.graph.node:\n",
    "    if n.op_type==\"MultiThreshold\":\n",
    "        odtype = get_by_name(n.attribute, \"out_dtype\", name_field=\"name\").s.decode(\"utf-8\")\n",
    "        dtype = getattr(DataType, odtype) \n",
    "        #model.set_tensor_datatype(n.input[0], dtype)\n",
    "        model.set_tensor_datatype(n.input[0], DataType.INT32)\n",
    "\n",
    "#from finn.transformation.infer_datatypes import InferDataTypes\n",
    "#model = model.transform(InferDataTypes())\n",
    "        \n",
    "model = model.transform(RoundAndClipThresholds())\n",
    "\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "\n",
    "model = model.transform(AbsorbTransposeIntoMultiThreshold())\n",
    "\n",
    "\n",
    "model.save(\"/tmp/quartznet_repetitive_nodes_subpart_streamlined.onnx\")\n",
    "showInNetron(\"/tmp/quartznet_repetitive_nodes_subpart_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'global_in': array([[[ 39., 107.,   9., ...,  80.,  37., 104.],\n",
      "        [  0., 100.,  21., ..., 105.,  61.,  99.],\n",
      "        [ 68.,   2.,  58., ...,  25.,  77.,  34.],\n",
      "        ...,\n",
      "        [ 53.,  43., 111., ...,  23.,  70., 112.],\n",
      "        [ 64.,  62.,  15., ...,  23., 105.,  74.],\n",
      "        [ 30.,  27.,  35., ...,  91., 123.,  31.]]], dtype=float32)}\n",
      "(1, 256, 128)\n",
      "[[[15. 15. 15. ... 15. 15. 15.]\n",
      "  [15.  0.  0. ...  0.  0.  0.]\n",
      "  [15.  0. 15. ... 15.  0. 15.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  0.  0. 15.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [15. 15. 15. ... 15. 15. 15.]]]\n"
     ]
    }
   ],
   "source": [
    "import finn.core.onnx_exec as oxe\n",
    "from finn.util.basic import *\n",
    "\n",
    "def generate_random_input(model):\n",
    "    \"\"\" Creates input dictionary with a random numpy array that matches the input tensor shape \"\"\"\n",
    "    i_shape = []\n",
    "    input_dict={}\n",
    "    for i in range(len(model.graph.input)):\n",
    "        input_node = model.graph.input[i]\n",
    "        input_node_name = input_node.name\n",
    "        input_node_shape = model.get_tensor_shape(input_node_name)\n",
    "\n",
    "        #i_val = gen_finn_dt_tensor(DataType.FLOAT32, input_node_shape)\n",
    "        i_val = np.random.randint(0, 128, input_node_shape).astype(np.float32) #float32 is expected input\n",
    "        \n",
    "        input_dict[input_node_name] = i_val\n",
    "    return input_dict\n",
    "\n",
    "model = ModelWrapper(\"/tmp/quartznet_repetitive_nodes_subpart.onnx\")\n",
    "input_dict = generate_random_input(model)\n",
    "print(input_dict)\n",
    "output_node_name = model.graph.output[0].name\n",
    "output_dict = oxe.execute_onnx(model, input_dict, return_full_exec_context=True)\n",
    "expected_old = output_dict[output_node_name]\n",
    "\n",
    "print(\"{}\\n{}\".format(np.shape(expected_old),expected_old))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn-base/src/finn/util/basic.py:380: UserWarning: The values of tensor MultiThreshold_2_param0 can't be represented with the set FINN datatype (DataType.INT32), they will be rounded to match the FINN datatype.\n",
      "  \"FINN datatype.\".format(tensor, dtype)\n",
      "/workspace/finn-base/src/finn/util/basic.py:380: UserWarning: The values of tensor MultiThreshold_4_param0 can't be represented with the set FINN datatype (DataType.INT32), they will be rounded to match the FINN datatype.\n",
      "  \"FINN datatype.\".format(tensor, dtype)\n",
      "/workspace/finn-base/src/finn/util/basic.py:380: UserWarning: The values of tensor MultiThreshold_6_param0 can't be represented with the set FINN datatype (DataType.INT32), they will be rounded to match the FINN datatype.\n",
      "  \"FINN datatype.\".format(tensor, dtype)\n",
      "/workspace/finn-base/src/finn/util/basic.py:380: UserWarning: The values of tensor MultiThreshold_8_param0 can't be represented with the set FINN datatype (DataType.INT32), they will be rounded to match the FINN datatype.\n",
      "  \"FINN datatype.\".format(tensor, dtype)\n",
      "/workspace/finn-base/src/finn/util/basic.py:380: UserWarning: The values of tensor MultiThreshold_10_param0 can't be represented with the set FINN datatype (DataType.INT32), they will be rounded to match the FINN datatype.\n",
      "  \"FINN datatype.\".format(tensor, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 128)\n",
      "[[[15. 15. 15. ... 15. 15. 15.]\n",
      "  [15.  0.  0. ...  0.  0.  0.]\n",
      "  [15.  0. 15. ... 15.  0. 15.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  0.  0. 15.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [15. 15. 15. ... 15. 15. 15.]]]\n"
     ]
    }
   ],
   "source": [
    "old_input_name = model.graph.input[0].name\n",
    "old_input_dict_val = input_dict[old_input_name]\n",
    "\n",
    "model = ModelWrapper(\"/tmp/quartznet_repetitive_nodes_subpart_streamlined.onnx\")\n",
    "\n",
    "input_dict_val = old_input_dict_val\n",
    "if len(np.shape(input_dict_val))<4:\n",
    "    input_dict_val = np.reshape(input_dict_val, np.shape(input_dict_val)+(1,))\n",
    "    \n",
    "input_dict[model.graph.input[0].name] = input_dict_val\n",
    "\n",
    "assert (input_dict_val==np.reshape(old_input_dict_val,np.shape(input_dict_val))).all()\n",
    "\n",
    "output_node_name = model.graph.output[0].name\n",
    "output_dict = oxe.execute_onnx(model, input_dict, return_full_exec_context=True)\n",
    "expected_new = output_dict[output_node_name]\n",
    "\n",
    "expected_new = np.reshape(expected_new, np.shape(expected_old))\n",
    "\n",
    "print(\"{}\\n{}\".format(np.shape(expected_new),expected_new))\n",
    "\n",
    "assert(expected_old==expected_new).all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare results before and after convolution lowering (and 3D to 4D transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_tensor': array([[[  24.729836  ,  -40.49649   ,   34.416332  , ...,\n",
      "          235.03418   ,    4.5277877 ,   92.97527   ],\n",
      "        [  79.53794   ,  -40.87957   ,   73.34267   , ...,\n",
      "           22.228552  ,   84.4919    ,   28.186167  ],\n",
      "        [  98.58585   ,  -57.142715  ,  -31.651863  , ...,\n",
      "           -1.5053351 , -156.42383   ,  -83.71322   ],\n",
      "        ...,\n",
      "        [  37.764263  ,   87.98556   ,   85.11785   , ...,\n",
      "          -60.03188   ,  201.65121   ,  -35.476322  ],\n",
      "        [-163.42583   , -100.1717    ,  227.94485   , ...,\n",
      "         -143.96017   ,  -10.710757  ,  -60.51425   ],\n",
      "        [  66.505356  ,   -0.40468973, -132.48183   , ...,\n",
      "           10.493427  ,   27.054792  ,   -6.463161  ]]], dtype=float32)}\n",
      "(1, 256, 128)\n",
      "[[[15. 15. 15. ... 15. 15. 15.]\n",
      "  [ 0.  0. 15. ... 15. 15.  0.]\n",
      "  [15.  0. 15. ...  0. 15.  0.]\n",
      "  ...\n",
      "  [ 0. 15. 15. ... 15. 15. 15.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0. 15. 15. ... 15. 15. 15.]]]\n",
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/quartznet_repetitive_nodes_subpart.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0eb00e2668>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import finn.core.onnx_exec as oxe\n",
    "from finn.util.basic import *\n",
    "\n",
    "model = ModelWrapper(\"/tmp/quartznet_repetitive_nodes_subpart.onnx\")\n",
    "\n",
    "def generate_random_input(model):\n",
    "    \"\"\" Creates input dictionary with a random numpy array that matches the input tensor shape \"\"\"\n",
    "    i_shape = []\n",
    "    input_dict={}\n",
    "    for i in range(len(model.graph.input)):\n",
    "        input_node = model.graph.input[i]\n",
    "        input_node_name = input_node.name\n",
    "        input_node_shape = model.get_tensor_shape(input_node_name)\n",
    "\n",
    "        i_val = gen_finn_dt_tensor(DataType.FLOAT32, input_node_shape)\n",
    "        input_dict[input_node_name] = i_val*100\n",
    "    return input_dict\n",
    "\n",
    "input_dict = generate_random_input(model)\n",
    "print(input_dict)\n",
    "\n",
    "output_node_name = model.graph.output[0].name\n",
    "output_dict = oxe.execute_onnx(model, input_dict, return_full_exec_context=True)\n",
    "expected_old = output_dict[output_node_name]\n",
    "\n",
    "print(\"{}\\n{}\".format(np.shape(expected_old),expected_old))\n",
    "\n",
    "showInNetron(\"/tmp/quartznet_repetitive_nodes_subpart.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 128, 1)\n",
      "(1, 256, 128)\n",
      "[[[15. 15. 15. ... 15. 15. 15.]\n",
      "  [ 0.  0. 15. ... 15. 15.  0.]\n",
      "  [15.  0. 15. ...  0. 15.  0.]\n",
      "  ...\n",
      "  [ 0. 15. 15. ... 15. 15. 15.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0. 15. 15. ... 15. 15. 15.]]]\n",
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/quartznet_subpart_4d.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0ea3424f98>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors\n",
    "\n",
    "model = model.transform(Change3DTo4DTensors())\n",
    "#for k,v in input_dict.items():\n",
    "#    old_in_name = k\n",
    "#    old_in_val = v\n",
    "#    old_shape = np.shape(v)\n",
    "#    new_in_name = model.graph.input[0].name\n",
    "#    new_shape = old_shape + (1,)\n",
    "#new_in_val = np.reshape(v, new_shape)\n",
    "#del input_dict[old_in_name]\n",
    "#input_dict[new_in_name] = new_in_val\n",
    "input_dict_val = input_dict['global_in']\n",
    "input_dict_val = np.reshape(input_dict_val, np.shape(input_dict_val)+(1,))\n",
    "input_dict[model.graph.input[0].name] = input_dict_val\n",
    "\n",
    "output_node_name = model.graph.output[0].name\n",
    "output_dict = oxe.execute_onnx(model, input_dict, return_full_exec_context=True)\n",
    "expected_new = output_dict[output_node_name]\n",
    "\n",
    "expected_new = np.reshape(expected_new, np.shape(expected_old))\n",
    "\n",
    "print(\"{}\\n{}\".format(np.shape(expected_new),expected_new))\n",
    "\n",
    "assert(expected_old==expected_new).all()\n",
    "\n",
    "model.save(\"/tmp/quartznet_subpart_4d.onnx\")\n",
    "showInNetron(\"/tmp/quartznet_subpart_4d.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 128)\n",
      "[[[15. 15. 15. ... 15. 15. 15.]\n",
      "  [ 0.  0. 15. ... 15. 15.  0.]\n",
      "  [15.  0. 15. ...  0. 15.  0.]\n",
      "  ...\n",
      "  [ 0. 15. 15. ... 15. 15. 15.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0. 15. 15. ... 15. 15. 15.]]]\n",
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/quartznet_subpart_lowered.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0ea34240b8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "\n",
    "model = ModelWrapper(\"/tmp/quartznet_subpart_4d.onnx\")\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "\n",
    "output_node_name = model.graph.output[0].name\n",
    "output_dict = oxe.execute_onnx(model, input_dict, return_full_exec_context=True)\n",
    "expected_lowered = output_dict[output_node_name]\n",
    "\n",
    "expected_lowered = np.reshape(expected_lowered, np.shape(expected_old))\n",
    "\n",
    "print(\"{}\\n{}\".format(np.shape(expected_lowered),expected_lowered))\n",
    "\n",
    "assert(expected_lowered==expected_new).all()\n",
    "\n",
    "model.save(\"/tmp/quartznet_subpart_lowered.onnx\")\n",
    "showInNetron(\"/tmp/quartznet_subpart_lowered.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
