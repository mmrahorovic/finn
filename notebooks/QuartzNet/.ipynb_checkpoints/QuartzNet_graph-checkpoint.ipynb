{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/quartznet.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f98d80eccf8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get onnx file, run in terminal:\n",
    "# python setup.py test --addopts \"-k test_brevitas_quartznet\" \n",
    "import numpy as np\n",
    "from finn.util.visualization import showInNetron\n",
    "import onnx\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "\n",
    "file_name = '/tmp/quartznet.onnx'\n",
    "showInNetron(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel_shape', 'dilations', 'strides', 'group', 'pads'}\n"
     ]
    }
   ],
   "source": [
    "from finn.util.basic import *\n",
    "\n",
    "model = ModelWrapper(file_name)\n",
    "attributes=[]\n",
    "for n in model.graph.node:\n",
    "    if n.op_type==\"Conv\":\n",
    "        for i in range(len(n.attribute)):\n",
    "            attributes.append(n.attribute[i].name)\n",
    "attributes = set(attributes)\n",
    "print(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the parameters of the conv node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(file_name)\n",
    "num_of_convs=0\n",
    "param_dict={}\n",
    "param_dict[\"dilations\"]=[]\n",
    "param_dict[\"kernel_shape\"]=[]\n",
    "param_dict[\"pads\"]=[]\n",
    "param_dict[\"strides\"]=[]\n",
    "param_dict[\"group\"]=[]\n",
    "attributes=[]\n",
    "for n in model.graph.node:\n",
    "    if n.op_type==\"Conv\":\n",
    "        num_of_convs=num_of_convs+1\n",
    "        #print(n.attribute)\n",
    "        for i in range(len(n.attribute)):\n",
    "            attributes.append(n.attribute[i].name)\n",
    "        dilations = get_by_name(n.attribute, \"dilations\",\"name\").ints[0]\n",
    "        kernel_shape = get_by_name(n.attribute, \"kernel_shape\",\"name\").ints[0]\n",
    "        pads = [get_by_name(n.attribute, \"pads\", \"name\").ints[0], get_by_name(n.attribute, \"pads\", \"name\").ints[1]]\n",
    "        strides = get_by_name(n.attribute, \"strides\", \"name\").ints[0]\n",
    "        group = get_by_name(n.attribute, \"group\", \"name\").i\n",
    "        param_dict[\"dilations\"].append(dilations)\n",
    "        param_dict[\"kernel_shape\"].append(kernel_shape)\n",
    "        param_dict[\"pads\"].append(pads)\n",
    "        param_dict[\"strides\"].append(strides)\n",
    "        param_dict[\"group\"].append(group)\n",
    "print(num_of_convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dilations \t {1, 2}\n",
      "kernel_shape \t {33, 1, 39, 75, 51, 87, 63}\n",
      "pads \t [[0, 0], [16, 16], [19, 19], [25, 25], [31, 31], [37, 37], [86, 86]]\n",
      "strides \t {1, 2}\n",
      "group \t {64, 1, 256, 512}\n"
     ]
    }
   ],
   "source": [
    "param_dict[\"dilations\"]=set(param_dict[\"dilations\"])\n",
    "param_dict[\"kernel_shape\"]=set(param_dict[\"kernel_shape\"])\n",
    "val, val_idx = np.unique(param_dict[\"pads\"], return_index=True, axis=0)\n",
    "param_dict[\"pads\"]= [param_dict[\"pads\"][el] for el in val_idx]\n",
    "param_dict[\"strides\"]=set(param_dict[\"strides\"])\n",
    "param_dict[\"group\"]=set(param_dict[\"group\"])\n",
    "\n",
    "for key, value in param_dict.items():\n",
    "    print(\"{} \\t {}\" .format(key,value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply transformation\n",
    "### Testing how to convert NCH -> NCH1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/quartznet_modified.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f98d80e7ba8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from finn.transformation.general import RemoveUnusedTensors\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "from finn.util.basic import *\n",
    "from finn.custom_op import *\n",
    "from onnx import helper\n",
    "#import onnx\n",
    "\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferShapes())\n",
    "#model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "model.save(\"/tmp/quartznet_modified.onnx\")\n",
    "showInNetron(\"/tmp/quartznet_modified.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/quartznet_modified_4d.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f98d80e76a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_invalid_nodes(model):\n",
    "    \"\"\" Verifies whether the graph contains valid nodes \"\"\"\n",
    "    valid_nodes = [\"Add\", \"Mul\", \"BatchNormalization\", \"MultiThreshold\", \"Conv\", \"Transpose\", \"LogSoftmax\", \"ArgMax\"]\n",
    "    invalid_nodes = []\n",
    "    for n in model.graph.node:\n",
    "        node_op_type = n.op_type\n",
    "        if node_op_type in valid_nodes:\n",
    "            continue\n",
    "        else:\n",
    "            invalid_nodes.append(node_op_type)\n",
    "    if not invalid_nodes: # if there are no invalid nodes\n",
    "        return True\n",
    "    else:\n",
    "        raise Exception(\"Nodes {} are not supported in this transformation\".format(invalid_nodes))\n",
    "\n",
    "def convert_3d_to_4d_tensors(model):\n",
    "    \"\"\" Converts 3D tensors (input, value_info, output) to 4D tensors \"\"\"\n",
    "    tensor_names = {}\n",
    "    ## Inputs\n",
    "    for t in model.graph.input:\n",
    "        tensor_name = t.name\n",
    "        tensor_type = t.type.tensor_type.elem_type\n",
    "        tensor_shape = model.get_tensor_shape(tensor_name)\n",
    "        tensor_names[tensor_name] = [tensor_type]\n",
    "        tensor_names[tensor_name].append(tensor_shape)\n",
    "\n",
    "    ## Initializers\n",
    "    initializer_names = []\n",
    "    for i in model.graph.initializer:\n",
    "        initializer_names.append(i.name)\n",
    "\n",
    "    ## Value infos\n",
    "    for t in model.graph.value_info:\n",
    "        tensor_name = t.name\n",
    "        if tensor_name in initializer_names:\n",
    "            continue\n",
    "        else:\n",
    "            tensor_type = t.type.tensor_type.elem_type\n",
    "            tensor_shape = model.get_tensor_shape(tensor_name)\n",
    "            tensor_names[tensor_name] = [tensor_type]\n",
    "            tensor_names[tensor_name].append(tensor_shape)\n",
    "\n",
    "    ## Outputs\n",
    "    for t in model.graph.output:\n",
    "        tensor_name = t.name\n",
    "        tensor_type = t.type.tensor_type.elem_type\n",
    "        tensor_shape = model.get_tensor_shape(tensor_name)\n",
    "        tensor_names[tensor_name] = [tensor_type]\n",
    "        tensor_names[tensor_name].append(tensor_shape)\n",
    "\n",
    "    ## Find tensors that are the output of nodes that reduce the dimension\n",
    "    tensors_reduced_dimension = []\n",
    "    for n in model.graph.node:\n",
    "        if n.op_type==\"ArgMax\":\n",
    "            keep_dims = get_by_name(n.attribute, \"keepdims\", \"name\").i\n",
    "            if keep_dims == 0:\n",
    "                node_out = n.output\n",
    "                for n_o in node_out:\n",
    "                    tensors_reduced_dimension.append(n_o)\n",
    "\n",
    "    ## Change format of each value_info + input + output tensors\n",
    "    for k, v in tensor_names.items():\n",
    "        tensor_type = v[0]\n",
    "        shape = v[1]\n",
    "        ## Add extra dimension for tensors:\n",
    "        # 1) Have 3 dimensions (NCH -> NCH1)\n",
    "        # 2) Tensors following operations that reduce their dimension: {Argmax, ...}\n",
    "        if len(shape)==3 or k in tensors_reduced_dimension:\n",
    "            shape.append(1)\n",
    "            model.set_tensor_shape(k, shape, tensor_type)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "def make_node_4d_compatible(model):\n",
    "    \"\"\" Each node from the list of supported nodes is made compatible with 4D tensors\"\"\"\n",
    "    for n in model.graph.node:\n",
    "        node_op_type = n.op_type\n",
    "        if node_op_type == \"Transpose\":\n",
    "            perm = get_by_name(n.attribute,\"perm\", \"name\").ints\n",
    "            if len(perm) == 3: # Meaning transpose was on 3D tensor\n",
    "                perm.append(3) # append 4th dimension\n",
    "        elif node_op_type == \"ArgMax\" or node_op_type == \"LogSoftMax\":\n",
    "            axis = get_by_name(n.attribute, \"axis\", \"name\")\n",
    "            if axis.i == -1:\n",
    "                axis.i = 2 # argmax is now on the second-to-last axis\n",
    "        elif node_op_type == \"Conv\":\n",
    "            dilations = get_by_name(n.attribute, \"dilations\", \"name\").ints\n",
    "            kernel_shape = get_by_name(n.attribute, \"kernel_shape\", \"name\").ints\n",
    "            pads = get_by_name(n.attribute, \"pads\", \"name\").ints\n",
    "            strides = get_by_name(n.attribute, \"strides\", \"name\").ints\n",
    "            if len(dilations) == 1: # we must add another dimension to it\n",
    "                dilations.append(dilations[0]) # only equal dilation value along each spatial axis is supported\n",
    "            if len(kernel_shape) == 1: # we must add another dimension to it\n",
    "                kernel_shape.append(1)\n",
    "            if len(pads) == 2: # pads = ([x1_begin, x1_end] -->) [x1_begin, x2_begin, x1_end, x2_end]\n",
    "                pads.insert(1, 0)\n",
    "                pads.append(0)\n",
    "            if len(strides) == 1: # strides = [stride_H, stride_W]\n",
    "                strides.append(1)\n",
    "\n",
    "def create_4d_initializers_conv_mul_add_node(model):\n",
    "    \"\"\" Conv, Mul and Add nodes are made compatible with 4D input tensors \"\"\"\n",
    "    initializers = {}\n",
    "    for i in model.graph.initializer:\n",
    "        init_name = i.name\n",
    "        if \"Conv\" in init_name:\n",
    "            init_dim = i.dims\n",
    "            init_dtype = i.data_type\n",
    "            initializers[init_name] = [init_dtype]\n",
    "            initializers[init_name].append(init_dim)\n",
    "        elif init_name[0:4] == \"Mul_\":\n",
    "            init_dim = i.dims\n",
    "            if len(i.dims) == 3:\n",
    "                init_dtype = i.data_type\n",
    "                initializers[init_name] = [init_dtype]\n",
    "                initializers[init_name].append(init_dim)\n",
    "        elif \"Add\" in init_name:\n",
    "            init_dim = i.dims\n",
    "            if len(i.dims) == 3:\n",
    "                init_dtype = i.data_type\n",
    "                initializers[init_name] = [init_dtype]\n",
    "                initializers[init_name].append(init_dim)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    for k, v in initializers.items():\n",
    "        init_dtype = v[0]\n",
    "        init_shape = v[1]\n",
    "        if len(init_shape) == 3:\n",
    "            # Change shape NCH -> NCH1\n",
    "            init_shape.append(1)\n",
    "            shape_init = model.get_initializer(k).shape\n",
    "            model.set_tensor_shape(k, init_shape, init_dtype)\n",
    "            \n",
    "\n",
    "model = ModelWrapper(\"/tmp/quartznet_modified.onnx\")            \n",
    "assert find_invalid_nodes(model)\n",
    "convert_3d_to_4d_tensors(model)\n",
    "make_node_4d_compatible(model)\n",
    "create_4d_initializers_conv_mul_add_node(model)\n",
    "\n",
    "model.save(\"/tmp/quartznet_modified_4d.onnx\")    \n",
    "showInNetron(\"/tmp/quartznet_modified_4d.onnx\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/quartznet_modified_4d_inferred_shapes.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9905f91e48>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelWrapper(\"/tmp/quartznet_modified_4d.onnx\")\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(InferShapes())\n",
    "model.save(\"/tmp/quartznet_modified_4d_inferred_shapes.onnx\")    \n",
    "showInNetron(\"/tmp/quartznet_modified_4d_inferred_shapes.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## UNDER CONSTRUCTION\n",
    "##\n",
    "\n",
    "# repetitive_nodes = []\n",
    "# rep = []\n",
    "# i = 0\n",
    "# for n in model.graph.node:\n",
    "#     is_fork = model.is_fork_node(n)\n",
    "#     if is_fork is True:\n",
    "#         i = (i+1)%2\n",
    "#     if i == 1:\n",
    "#         rep.append(n)\n",
    "#     if i == 0:\n",
    "#         if rep: # rep is non-empty\n",
    "#             repetitive_nodes.append(rep)\n",
    "#             break\n",
    "            \n",
    "# print(repetitive_nodes)\n",
    "\n",
    "# inp = []\n",
    "# out = []\n",
    "# value_info = []\n",
    "# initializers = []\n",
    "# for i, n in enumerate(repetitive_nodes[0]):\n",
    "#     if i == 0: # input node\n",
    "#         inp.append(n.input[0])\n",
    "#         initializers.append(n.input[1])\n",
    "#     elif i == len(repetitive_nodes[0])-1: # output node\n",
    "#         value_info.append(n.input[0])\n",
    "#         initializers.append(n.input[1])\n",
    "#         out.append(n.output[0])\n",
    "#     else: # intermediate node\n",
    "#         value_info.append(n.input[0])\n",
    "#         initializers.append(n.input[1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic transformations (leave commented)\n",
    "\n",
    "#from finn.util.basic import *\n",
    "#from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "#from finn.transformation.infer_shapes import InferShapes\n",
    "#from finn.transformation.infer_datatypes import InferDataTypes\n",
    "#from finn.transformation.fold_constants import FoldConstants\n",
    "\n",
    "#file_name = \"/tmp/quartznet.onnx\"\n",
    "#model = ModelWrapper(file_name)\n",
    "#model = model.transform(InferShapes())\n",
    "#model = model.transform(FoldConstants())\n",
    "#model = model.transform(GiveUniqueNodeNames())\n",
    "#model = model.transform(GiveReadableTensorNames())\n",
    "#model = model.transform(InferDataTypes())\n",
    "#model = model.transform(RemoveStaticGraphInputs())\n",
    "#model.save(\"/tmp/quartznet_cleaned.onnx\")\n",
    "#file_name = \"/tmp/quartznet_cleaned.onnx\"\n",
    "\n",
    "#showInNetron(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute graph and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.core.onnx_exec as oxe\n",
    "\n",
    "def make_unit_input(model):\n",
    "    \"\"\" Creates numpy array that matches the input tensor shape \"\"\"\n",
    "    i_shape = []\n",
    "    input_node = model.graph.input[0]\n",
    "    input_node_shape = input_node.type.tensor_type.shape.dim\n",
    "    input_node_name = input_node.name\n",
    "\n",
    "    for d in input_node_shape:\n",
    "        i_shape.append(d.dim_value)\n",
    "\n",
    "    i_val = np.ones(i_shape).astype(np.float32)\n",
    "\n",
    "    input_dict = {input_node_name: i_val}\n",
    "    \n",
    "    return input_dict\n",
    "\n",
    "def execute_unit_input_test(model):\n",
    "    \"\"\" Executes unit input test on the supplied model. Return value is the value of the output of the graph\"\"\"\n",
    "    output_node_name = model.graph.output[0].name\n",
    "    input_dict = make_unit_input(model)\n",
    "    output_dict = oxe.execute_onnx(model, input_dict)\n",
    "    expected = output_dict[output_node_name]\n",
    "    \n",
    "    return expected\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      "  28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      "  28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      "  28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      "  28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      "  28 28 28 28 28 28 28 28]]\n"
     ]
    }
   ],
   "source": [
    "model_unmodified = ModelWrapper(\"/tmp/quartznet_modified.onnx\")\n",
    "\n",
    "expected_unmodified = execute_unit_input_test(model_unmodified)\n",
    "print(\"{}\".format(expected_unmodified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]\n",
      "  [28]]]\n"
     ]
    }
   ],
   "source": [
    "model_modified = ModelWrapper(\"/tmp/quartznet_modified_4d.onnx\")\n",
    "\n",
    "expected_4d_model = execute_unit_input_test(model_modified)\n",
    "print(\"{}\".format(expected_4d_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got past infer shapes\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "\n",
    "model_lowered = ModelWrapper(\"/tmp/quartznet_modified_4d.onnx\")\n",
    "#import pdb; pdb.set_trace()\n",
    "\n",
    "model_lowered = model_lowered.transform(LowerConvsToMatMul(), make_deepcopy=True, cleanup=False, fix_float64=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "model_lowered = model_lowered.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_4d_lowered = execute_unit_input_test(model_lowered)\n",
    "print(\"{}\".format(expected_4d_lowered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Message ONNX_REL_1_7.ModelProto exceeds maximum protobuf size of 2GB: 3381322180",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-21e6f26d23b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_lowered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/workspace/finn/quartznet_lowered.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workspace/finn-base/src/finn/core/modelwrapper.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;34m\"\"\"Saves the wrapper ONNX ModelProto into a file with given name.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_proto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalysis_fxn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/onnx/__init__.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(proto, f, format)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mproto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite_external_data_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0m_save_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/onnx/__init__.py\u001b[0m in \u001b[0;36m_serialize\u001b[0;34m(proto)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SerializeToString'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Message ONNX_REL_1_7.ModelProto exceeds maximum protobuf size of 2GB: 3381322180"
     ]
    }
   ],
   "source": [
    "model_lowered.save(\"/workspace/finn/quartznet_lowered.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lowered = ModelWrapper(\"/tmp/quartznet_lowered.onnx\")\n",
    "\n",
    "expected_lowered_model = execute_unit_input_test(model_lowered)\n",
    "print(\"{}\".format(expected_lowered_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
