{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "linear-broadcasting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_model.onnx\t       quartznet_hls_cleaned.onnx\t       syn_v0  syn_v5\r\n",
      "quantized_input.npy    quartznet_hls_cleaned_partitioned.onnx  syn_v1  syn_v6\r\n",
      "quantized_output.npy   single_node_models\t\t       syn_v2  syn_v7\r\n",
      "quartznet_export.onnx  syn_end2end\t\t\t       syn_v3\r\n",
      "quartznet_hls.onnx     syn_low_folding\t\t\t       syn_v4\r\n"
     ]
    }
   ],
   "source": [
    "!ls /workspace/results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "harmful-earthquake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/workspace/results/quartznet_export.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f938a197b70>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "#showInNetron(\"/workspace/results/quartznet_hls_cleaned.onnx\")\n",
    "showInNetron(\"/workspace/results/quartznet_export.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-trustee",
   "metadata": {},
   "source": [
    "# Compare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "waiting-apartment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 346.10875359899364\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.util.basic import gen_finn_dt_tensor\n",
    "import finn.core.onnx_exec as oxe\n",
    "import time\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "################################################################################################\n",
    "####\n",
    "#### MODEL 1\n",
    "####\n",
    "model_1 = ModelWrapper(\"/workspace/results/quartznet_export.onnx\")\n",
    "#model_1 = ModelWrapper(\"/tmp/quartznet_export.onnx\")\n",
    "\n",
    "#### MODEL 1\n",
    "# Create input data\n",
    "input0_tensor_name = model_1.graph.input[0].name\n",
    "\n",
    "## Change input...\n",
    "#input_val = np.load(\"brevitas_reference/end2end_quartznet_input_quantized.npy\")\n",
    "#input_val = input_val[:,:,0:256].astype(np.float32)\n",
    "input_val = np.load(\"/workspace/results/librispeech_data/input_sample_1.npy\")\n",
    "\n",
    "input_dict = {}\n",
    "input_dict[input0_tensor_name] = input_val\n",
    "output0_tensor_name = model_1.graph.output[0].name\n",
    "\n",
    "expected_m1_dict = oxe.execute_onnx(model_1, input_dict, return_full_exec_context = False)\n",
    "expected_m1 = expected_m1_dict[output0_tensor_name]\n",
    "################################################################################################\n",
    "\n",
    "t2 = time.perf_counter() - t1\n",
    "print(\"Elapsed time: {}\".format(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "closed-reflection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128)\n",
      "(1, 128)\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "20\t20\n",
      "8\t8\n",
      "28\t5\n",
      "5\t28\n",
      "28\t28\n",
      "28\t0\n",
      "0\t0\n",
      "0\t28\n",
      "19\t19\n",
      "28\t28\n",
      "16\t16\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "9\t9\n",
      "14\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "0\t0\n",
      "0\t0\n",
      "23\t23\n",
      "28\t28\n",
      "1\t1\n",
      "19\t19\n",
      "19\t19\n",
      "28\t28\n",
      "0\t28\n",
      "0\t0\n",
      "28\t28\n",
      "21\t1\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "16\t16\n",
      "28\t28\n",
      "28\t28\n",
      "28\t15\n",
      "15\t18\n",
      "18\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "0\t0\n",
      "0\t28\n",
      "9\t28\n",
      "14\t14\n",
      "0\t0\n",
      "0\t0\n",
      "0\t0\n",
      "20\t20\n",
      "8\t8\n",
      "5\t5\n",
      "28\t0\n",
      "0\t0\n",
      "0\t28\n",
      "28\t28\n",
      "28\t13\n",
      "2\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t15\n",
      "5\t28\n",
      "28\t28\n",
      "28\t4\n",
      "28\t28\n",
      "4\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n"
     ]
    }
   ],
   "source": [
    "golden_output = np.load(\"/workspace/results/librispeech_data/output_sample_1.npy\")\n",
    "\n",
    "print(np.shape(golden_output))\n",
    "print(np.shape(expected_m1))\n",
    "\n",
    "for idx, el in enumerate(golden_output[0]):\n",
    "    print(\"{}\\t{}\".format(el, expected_m1[0][idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "educational-wedding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the spin was upor in the bed']\n",
      "['the spi was apor n the mod']\n"
     ]
    }
   ],
   "source": [
    "labels = [\" \", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\",\n",
    "         \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"'\"]\n",
    "    \n",
    "def __ctc_decoder_predictions_tensor(tensor, labels):\n",
    "    \"\"\"\n",
    "    Decodes a sequence of labels to words\n",
    "    \"\"\"\n",
    "    blank_id = len(labels)\n",
    "    hypotheses = []\n",
    "    labels_map = dict([(i, labels[i]) for i in range(len(labels))])\n",
    "    decoded_prediction = []\n",
    "    previous = len(labels)  # id of a blank symbol\n",
    "    prediction = tensor\n",
    "    for p in prediction:\n",
    "        if (p != previous or previous == blank_id) and p != blank_id:\n",
    "            decoded_prediction.append(p)\n",
    "        previous = p\n",
    "    hypothesis = ''.join([labels_map[c] for c in decoded_prediction])\n",
    "    hypotheses.append(hypothesis)\n",
    "    return hypotheses\n",
    "\n",
    "print(__ctc_decoder_predictions_tensor(golden_output[0], labels))\n",
    "print(__ctc_decoder_predictions_tensor(expected_m1[0], labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-surrey",
   "metadata": {},
   "source": [
    "# Compare outputs test_brevitas_quartznet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "statistical-caribbean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t1\n",
      "28\t14\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t14\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t15\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t0\n",
      "28\t0\n",
      "28\t28\n",
      "28\t28\n",
      "28\t2\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t21\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t6\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t9\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t19\n",
      "28\t8\n",
      "28\t28\n",
      "28\t28\n",
      "28\t1\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t5\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t0\n",
      "28\t0\n",
      "28\t28\n",
      "28\t28\n",
      "28\t16\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "28\t28\n",
      "['']\n",
      "['anno bufishae p']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "produced = np.load(\"/tmp/produced.npy\")\n",
    "expected = np.load(\"/tmp/expected.npy\")\n",
    "\n",
    "for idx, el in enumerate(expected[0]):\n",
    "    print(\"{}\\t{}\".format(el, produced[0][idx]))\n",
    "\n",
    "    \n",
    "labels = [\" \", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\",\n",
    "         \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"'\"]\n",
    "    \n",
    "def __ctc_decoder_predictions_tensor(tensor, labels):\n",
    "    \"\"\"\n",
    "    Decodes a sequence of labels to words\n",
    "    \"\"\"\n",
    "    blank_id = len(labels)\n",
    "    hypotheses = []\n",
    "    labels_map = dict([(i, labels[i]) for i in range(len(labels))])\n",
    "    decoded_prediction = []\n",
    "    previous = len(labels)  # id of a blank symbol\n",
    "    prediction = tensor\n",
    "    for p in prediction:\n",
    "        if (p != previous or previous == blank_id) and p != blank_id:\n",
    "            decoded_prediction.append(p)\n",
    "        previous = p\n",
    "    hypothesis = ''.join([labels_map[c] for c in decoded_prediction])\n",
    "    hypotheses.append(hypothesis)\n",
    "    return hypotheses\n",
    "\n",
    "print(__ctc_decoder_predictions_tensor(expected[0], labels))\n",
    "print(__ctc_decoder_predictions_tensor(produced[0], labels))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
