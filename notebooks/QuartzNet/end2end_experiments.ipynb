{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "linear-broadcasting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_model.onnx\t\t    single_node_models\tsyn_v0\tsyn_v3\tsyn_v6\r\n",
      "quartznet_hls.onnx\t    syn_end2end\t\tsyn_v1\tsyn_v4\tsyn_v7\r\n",
      "quartznet_hls_cleaned.onnx  syn_low_folding\tsyn_v2\tsyn_v5\r\n"
     ]
    }
   ],
   "source": [
    "!ls /workspace/results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "harmful-earthquake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/workspace/results/quartznet_hls_cleaned.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3528ce9e48>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(\"/workspace/results/quartznet_hls_cleaned.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vocational-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "from finn.transformation.fpgadataflow.set_folding import SetFolding\n",
    "from finn.transformation.create_generic_partitions import PartitionFromDict\n",
    "from finn.transformation.extend_partition import ExtendPartition\n",
    "from finn.transformation.fpgadataflow.annotate_cycles import AnnotateCycles\n",
    "from finn.util.fpgadataflow import is_fpgadataflow_node\n",
    "\n",
    "model = ModelWrapper(\"/workspace/results/quartznet_hls_cleaned.onnx\")\n",
    "\n",
    "model = model.transform(PartitionFromDict({0: range(1,371)}))\n",
    "for n in model.graph.node:\n",
    "    if n.op_type==\"GenericPartition\":\n",
    "        inst = getCustomOp(n)\n",
    "        model_path = inst.get_nodeattr(\"model\")\n",
    "        model_partition = ModelWrapper(model_path)\n",
    "        model_partition = model_partition.transform(SetFolding(target_cycles_per_frame=4300000)) \n",
    "        model_partition = model_partition.transform(AnnotateCycles())\n",
    "        model_partition.save(model_path)\n",
    "        \n",
    "model = model.transform(ExtendPartition([1]))\n",
    "\n",
    "for n in model.graph.node:\n",
    "    if is_fpgadataflow_node(n):\n",
    "        inst = getCustomOp(n)\n",
    "        if n.op_type==\"FMPadding_Batch\":\n",
    "            continue\n",
    "        elif n.op_type==\"DuplicateStreams_Batch\":\n",
    "            continue\n",
    "        elif n.op_type==\"AddStreams_Batch\":\n",
    "            continue\n",
    "            \n",
    "        elif n.op_type==\"ConvolutionInputGenerator1D\":\n",
    "            #Why? Because percentage-wise the least amount of LUTs are used to implement the ConvInpGen (after BRAM).\n",
    "            # For BRAM, you are using ~1%, for URAM ~2%, for LUTs ~1.10%\n",
    "            # However, we want to keep the BRAMs for the thresholds of the VVAU/StreamingFCLayer\n",
    "            inst.set_nodeattr(\"ram_style\", \"distributed\")\n",
    "            \n",
    "        elif n.op_type==\"Vector_Vector_Activate_Batch\":\n",
    "            inst.set_nodeattr(\"resType\", \"dsp\")\n",
    "            \n",
    "        elif n.op_type==\"StreamingFCLayer_Batch\":\n",
    "            inst.set_nodeattr(\"resType\", \"dsp\")\n",
    "            inst.set_nodeattr(\"ram_style\", \"ultra\")\n",
    "            inst.set_nodeattr(\"mem_mode\", \"decoupled\")\n",
    "            if inst.get_nodeattr(\"ram_style\")==\"ultra\":\n",
    "                inst.set_nodeattr(\"runtime_writeable_weights\", 1)\n",
    "            \n",
    "        elif n.op_type==\"Thresholding_Batch\":\n",
    "            inst.set_nodeattr(\"ram_style\", \"distributed\")\n",
    "            inst.set_nodeattr(\"mem_mode\", \"const\")\n",
    "            \n",
    "        else:\n",
    "            print(\"Missed: {}\".format(n.op_type))\n",
    "            break\n",
    "\n",
    "model.save(\"/workspace/results/quartznet_hls_cleaned_partitioned.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "indirect-height",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/workspace/results/quartznet_hls_cleaned_partitioned.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa034478a20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "showInNetron(\"/workspace/results/quartznet_hls_cleaned_partitioned.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-trustee",
   "metadata": {},
   "source": [
    "# Compare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "waiting-apartment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 338.4672104109777\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.util.basic import gen_finn_dt_tensor\n",
    "import finn.core.onnx_exec as oxe\n",
    "import time\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "################################################################################################\n",
    "####\n",
    "#### MODEL 1\n",
    "####\n",
    "model_1 = ModelWrapper(\"/workspace/finn/end2end_quartznet_export_dev.onnx\")\n",
    "\n",
    "#### MODEL 1\n",
    "# Create input data\n",
    "input0_tensor_name = model_1.graph.input[0].name\n",
    "\n",
    "## Change input...\n",
    "input_val = np.load(\"brevitas_reference/end2end_quartznet_input.npy\")\n",
    "input_val = input_val[:,:,0:256]\n",
    "\n",
    "# Quantize input data\n",
    "input_val = quantize_tensor(input_val, num_of_bits=8)\n",
    "\n",
    "input_dict = {}\n",
    "input_dict[input0_tensor_name] = input_val\n",
    "output0_tensor_name = model_1.graph.output[0].name\n",
    "\n",
    "expected_m1_dict = oxe.execute_onnx(model_1, input_dict, return_full_exec_context = False)\n",
    "expected_m1 = expected_m1_dict[output0_tensor_name]\n",
    "################################################################################################\n",
    "\n",
    "t2 = time.perf_counter() - t1\n",
    "print(\"Elapsed time: {}\".format(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "closed-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm brevitas_reference/end2end_quartznet_input_quantized.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "rural-dodge",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_save_dispatcher() missing 1 required positional argument: 'arr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-e35b723c7599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0minput_val_quantized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantize_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"brevitas_reference/end2end_quartznet_input_quantized.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_val_quantized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _save_dispatcher() missing 1 required positional argument: 'arr'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def quantize_tensor_v2(x, num_of_bits=8):\n",
    "    # https://leimao.github.io/article/Neural-Networks-Quantization/\n",
    "    alpha = x.min()\n",
    "    beta = x.max()\n",
    "    #alpha = -4.743273735046387\n",
    "    #beta = 29.181787490844727\n",
    "\n",
    "    b = num_of_bits\n",
    "    alpha_q = -2 ** (b-1)\n",
    "    beta_q = 2 ** (b-1) - 1\n",
    "\n",
    "    s = (beta - alpha) / (beta_q - alpha_q)\n",
    "    z = int((beta * alpha_q - alpha * beta_q) / (beta - alpha))\n",
    "\n",
    "    x_q = np.round(1 / s * x + z, decimals=0)\n",
    "    #x_q = torch.round(1 / s * x + z)\n",
    "    x_q = np.clip(x_q, a_min=alpha_q, a_max=beta_q)\n",
    "    #x_q = torch.clamp(x_q, min=alpha_q, max=beta_q)\n",
    "\n",
    "    return x_q\n",
    "\n",
    "input_val = np.load(\"brevitas_reference/end2end_quartznet_input.npy\")\n",
    "\n",
    "input_val_quantized = np.zeros(np.shape(input_val))\n",
    "channels = np.shape(input_val)[1]\n",
    "for c in range(channels):\n",
    "    input_val_quantized[0, c, :] = quantize_tensor_v2(input_val[0, c, :], 8)\n",
    "\n",
    "np.save(\"brevitas_reference/end2end_quartznet_input_quantized.npy\")\n",
    "print(np.shape(input_val))\n",
    "print(np.shape(input_val_quantized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "exempt-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\" \", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\",\n",
    "         \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"'\"]\n",
    "    \n",
    "def __ctc_decoder_predictions_tensor(tensor, labels):\n",
    "    \"\"\"\n",
    "    Decodes a sequence of labels to words\n",
    "    \"\"\"\n",
    "    blank_id = len(labels)\n",
    "    hypotheses = []\n",
    "    labels_map = dict([(i, labels[i]) for i in range(len(labels))])\n",
    "    decoded_prediction = []\n",
    "    previous = len(labels)  # id of a blank symbol\n",
    "    prediction = tensor\n",
    "    for p in prediction:\n",
    "        if (p != previous or previous == blank_id) and p != blank_id:\n",
    "            decoded_prediction.append(p)\n",
    "        previous = p\n",
    "    hypothesis = ''.join([labels_map[c] for c in decoded_prediction])\n",
    "    hypotheses.append(hypothesis)\n",
    "    return hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "norwegian-container",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      "  28 28 28 28 28  5 14 28 28 28 28 28 20 28 28 25 28 28 28  0 28 28 28  1\n",
      "  28 28 28 28  2 28 28  5 28 28 28 28 24 28 28 28 28 28  9 28 28 19 28 28\n",
      "  28 28  0 28 28 28 28  3 18 18 28 28  9 19 19 28 28 11 28 28 28 28 28  1\n",
      "  28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      "  28 28 28 28 28 28 28 28]]\n",
      "['vanity and vexation of spad']\n",
      "['enty abexis criska']\n"
     ]
    }
   ],
   "source": [
    "previous = [28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
    "  22, 28, 28,  1, 28, 28, 14, 28, 28,  9, 28, 28, 20, 28, 28, 25, 28, 28, 28,  0,  0, 28,  1, 14,\n",
    "   4,  4,  0,  0, 28, 22, 28, 28,  5, 28, 28, 28, 28, 24, 28, 28, 28, 28,  1, 28, 28, 28, 20,  9,\n",
    "   9, 28, 15, 14, 28, 28,  0,  0,  0, 28, 28, 15,  6, 28, 28, 28,  0, 28, 28, 19, 19, 28, 16, 28,\n",
    "  28, 28, 28,  1, 28, 28,  4, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
    "  28, 28, 28, 28, 28, 28, 28, 28]\n",
    "print(expected_m1)\n",
    "\n",
    "print(__ctc_decoder_predictions_tensor(previous, labels))\n",
    "print(__ctc_decoder_predictions_tensor(expected_m1[0], labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expanded-budget",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn/src/finn/custom_op/fpgadataflow/streamingfclayer_batch.py:651: UserWarning: Setting 0-valued first threshold to 1 to avoid vivado_hls bug\n",
      "  \"Setting 0-valued first threshold to 1 to avoid vivado_hls bug\"\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.fpgadataflow.prepare_cppsim import PrepareCppSim\n",
    "from finn.transformation.fpgadataflow.compile_cppsim import CompileCppSim\n",
    "from finn.transformation.fpgadataflow.set_exec_mode import SetExecMode\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "################################################################################################\n",
    "####\n",
    "#### MODEL 2\n",
    "####\n",
    "model_2 = ModelWrapper(\"/workspace/results/quartznet_hls_cleaned_partitioned.onnx\")\n",
    "exec_mode=\"cppsim\"\n",
    "\n",
    "if exec_mode==\"cppsim\":\n",
    "    model_2 = model_2.transform(PrepareCppSim())\n",
    "    model_2 = model_2.transform(CompileCppSim())\n",
    "    model_2 = model_2.transform(SetExecMode(\"cppsim\"))\n",
    "\n",
    "#### MODEL 2\n",
    "m1_input_val = input_val\n",
    "\n",
    "input0_tensor_name = model_2.graph.input[0].name\n",
    "input_dict = {}\n",
    "m2_input_val = np.reshape(m1_input_val, np.shape(m1_input_val)+(1,)) #extend to 4D\n",
    "input_dict[input0_tensor_name] = m2_input_val\n",
    "output0_tensor_name = model_2.graph.output[0].name\n",
    "\n",
    "expected_m2_dict = oxe.execute_onnx(model_2, input_dict, return_full_exec_context = False)\n",
    "expected_m2 = expected_m2_dict[output0_tensor_name]\n",
    "\n",
    "expected_m2 = np.reshape(expected_m2, np.shape(expected_m1))\n",
    "m2_input_val = np.reshape(m2_input_val, np.shape(m1_input_val))\n",
    "\n",
    "#assert(m1_input_val==m2_input_val).all()\n",
    "#assert(expected_m1==expected_m2).all()\n",
    "################################################################################################\n",
    "\n",
    "t2 = time.perf_counter() - t1\n",
    "print(\"Elapsed time: {}\".format(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(m1_input_val==m2_input_val).all()\n",
    "assert(expected_m1==expected_m2).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, el in expected_m1:\n",
    "    print(\"{}\\t{}\".formated(el, expected_m2[idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
