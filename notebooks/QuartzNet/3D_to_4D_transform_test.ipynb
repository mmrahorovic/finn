{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/tmp/quartznet.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f879d9df240>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get onnx file, run in terminal:\n",
    "# python setup.py test --addopts \"-k test_brevitas_quartznet\" \n",
    "import numpy as np\n",
    "from finn.util.visualization import showInNetron\n",
    "import onnx\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "\n",
    "file_name = '/tmp/quartznet.onnx'\n",
    "showInNetron(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/quartznet_modified.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f72f458e748>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from finn.transformation.general import RemoveUnusedTensors\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "#from finn.util.basic import *\n",
    "#from finn.custom_op import *\n",
    "from onnx import helper\n",
    "#import onnx\n",
    "\n",
    "model = ModelWrapper(file_name)\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "model.save(\"/tmp/quartznet_modified.onnx\")\n",
    "showInNetron(\"/tmp/quartznet_modified.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing quartznet before and after transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/quartznet_4d.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd7306f1400>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelWrapper(\"/tmp/quartznet_modified.onnx\")\n",
    "\n",
    "from finn.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors\n",
    "\n",
    "model = model.transform(Change3DTo4DTensors())\n",
    "model.save(\"/tmp/quartznet_4d.onnx\")\n",
    "showInNetron(\"/tmp/quartznet_4d.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.core.onnx_exec as oxe\n",
    "\n",
    "def make_unit_input(model):\n",
    "    \"\"\" Creates numpy array that matches the input tensor shape \"\"\"\n",
    "    i_shape = []\n",
    "    input_node = model.graph.input[0]\n",
    "    input_node_shape = input_node.type.tensor_type.shape.dim\n",
    "    input_node_name = input_node.name\n",
    "\n",
    "    for d in input_node_shape:\n",
    "        i_shape.append(d.dim_value)\n",
    "\n",
    "    i_val = np.ones(i_shape).astype(np.float32)\n",
    "\n",
    "    input_dict = {input_node_name: i_val}\n",
    "    \n",
    "    return input_dict\n",
    "\n",
    "def execute_unit_input_test(model):\n",
    "    \"\"\" Executes unit input test on the supplied model. Return value is the value of the output of the graph\"\"\"\n",
    "    output_node_name = model.graph.output[0].name\n",
    "    input_dict = make_unit_input(model)\n",
    "    output_dict = oxe.execute_onnx(model, input_dict)\n",
    "    expected = output_dict[output_node_name]\n",
    "    \n",
    "    return expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_unmodified = ModelWrapper(\"/tmp/quartznet.onnx\")\n",
    "expected_unmodified = execute_unit_input_test(model_unmodified)\n",
    "print(\"{}\".format(expected_unmodified))\n",
    "\n",
    "model_modified = ModelWrapper(\"/tmp/quartznet_4d.onnx\")\n",
    "expected_modified = execute_unit_input_test(model_modified)\n",
    "print(\"{}\".format(expected_modified))\n",
    "\n",
    "assert (expected_unmodified==expected_modified).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/4d_conversion_test_model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0e2c724a20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from finn.util.visualization import showInNetron\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "\n",
    "from finn.util.basic import *\n",
    "import onnx\n",
    "\n",
    "Mul1_node = onnx.helper.make_node(\n",
    "    \"Mul\",\n",
    "    inputs=['in1_mul1', 'in2_mul1'], #inputs\n",
    "    outputs=['out1_mul1'], #outputs\n",
    "    name='Mul1' #name\n",
    ")\n",
    "\n",
    "Conv1_node = onnx.helper.make_node(\n",
    "    \"Conv\",\n",
    "    inputs=['out1_mul1', 'in2_conv1'],\n",
    "    outputs=['out1_conv1'],\n",
    "    name='Conv1',\n",
    "    dilations=[1],\n",
    "    group=1,\n",
    "    kernel_shape=[1],\n",
    "    pads=[0,0],\n",
    "    strides=[1]\n",
    ")\n",
    "\n",
    "Add1_node = onnx.helper.make_node(\n",
    "    \"Add\",\n",
    "    inputs=['out1_conv1', 'in2_add1'],\n",
    "    outputs=['out1_add1'],\n",
    "    name='Add1'\n",
    ")\n",
    "\n",
    "Mul2_node = onnx.helper.make_node(\n",
    "    \"Mul\",\n",
    "    inputs=['out1_add1', 'in2_mul2'],\n",
    "    outputs=['out1_mul2'],\n",
    "    name='Mul2'\n",
    ")\n",
    "\n",
    "Transpose1_node = onnx.helper.make_node(\n",
    "    \"Transpose\",\n",
    "    inputs=['out1_mul2'],\n",
    "    outputs=['out1_transpose1'],\n",
    "    name='Transpose1',\n",
    "    perm=[0,2,1]\n",
    ")\n",
    "\n",
    "LogSoftmax1_node = onnx.helper.make_node(\n",
    "    \"LogSoftmax\",\n",
    "    inputs=['out1_transpose1'],\n",
    "    outputs=['out1_logsoftmax1'],\n",
    "    name='LogSoftmax1',\n",
    "    axis=2\n",
    ")\n",
    "\n",
    "ArgMax1_node = onnx.helper.make_node(\n",
    "    \"ArgMax\",\n",
    "    inputs=['out1_logsoftmax1'],\n",
    "    outputs=['out1_argmax1'],\n",
    "    name='ArgMax1',\n",
    "    axis=-1,\n",
    "    keepdims=0\n",
    ")\n",
    "\n",
    "# Inputs and outputs\n",
    "in1_mul1 = onnx.helper.make_tensor_value_info(\"in1_mul1\", onnx.TensorProto.FLOAT, [1, 1024, 128])\n",
    "#in2_mul1 = onnx.helper.make_tensor_value_info(\"in2_mul1\", onnx.TensorProto.FLOAT, [1])\n",
    "out1_argmax1 = onnx.helper.make_tensor_value_info(\"out1_argmax1\", onnx.TensorProto.INT64, [1, 128])\n",
    "\n",
    "# Value infos\n",
    "out1_mul1 = onnx.helper.make_tensor_value_info(\"out1_mul1\", onnx.TensorProto.FLOAT, [1, 1024, 128])\n",
    "out1_conv1 = onnx.helper.make_tensor_value_info(\"out1_conv1\", onnx.TensorProto.FLOAT, [1,29,128])\n",
    "out1_add1 = onnx.helper.make_tensor_value_info(\"out1_add1\", onnx.TensorProto.FLOAT, [1,29,128])\n",
    "out1_mul2 = onnx.helper.make_tensor_value_info(\"out1_mul2\", onnx.TensorProto.FLOAT, [1,29,128])\n",
    "out1_transpose1 = onnx.helper.make_tensor_value_info(\"out1_transpose1\", onnx.TensorProto.FLOAT, [1,128,29])\n",
    "out1_logsoftmax1 = onnx.helper.make_tensor_value_info(\"out1_logsoftmax1\", onnx.TensorProto.FLOAT, [1,128,29])\n",
    "\n",
    "# Initializers\n",
    "in2_mul1 = onnx.helper.make_tensor_value_info(\"in2_mul1\", onnx.TensorProto.FLOAT, [1])\n",
    "in2_conv1 = onnx.helper.make_tensor_value_info(\"in2_conv1\", onnx.TensorProto.FLOAT, [29,1024,1])\n",
    "in2_add1 = onnx.helper.make_tensor_value_info(\"in2_add1\", onnx.TensorProto.FLOAT,[1,29,1])\n",
    "in2_mul2 = onnx.helper.make_tensor_value_info(\"in2_mul2\", onnx.TensorProto.FLOAT, [1])\n",
    "           \n",
    "#initializer1_name = 'in2_mul1'\n",
    "#initializer1_shape = [1]\n",
    "#init_value1 = gen_finn_dt_tensor(DataType.FLOAT32, initializer1_shape)\n",
    "#model.set_initializer(initializer1_name, init_value1)\n",
    "#initializer2_name = 'in2_conv1'\n",
    "#initializer2_shape = [29,1024,1]\n",
    "#init_value2 = gen_finn_dt_tensor(DataType.FLOAT32, initializer2_shape)\n",
    "#model.set_initializer(initializer2_name, init_value2)\n",
    "#initializer3_name = 'in2_add1'\n",
    "#initializer3_shape = [1,29,1]\n",
    "#init_value3 = gen_finn_dt_tensor(DataType.FLOAT32, initializer3_shape)\n",
    "#model.set_initializer(initializer3_name, init_value3)\n",
    "#initializer4_name = 'in2_mul2'\n",
    "#initializer4_shape = [1]\n",
    "#init_value4 = gen_finn_dt_tensor(DataType.FLOAT32, initializer4_shape)\n",
    "#model.set_initializer(initializer4_name, init_value4)\n",
    "    \n",
    "graph = onnx.helper.make_graph(\n",
    "    nodes=[\n",
    "        Mul1_node,\n",
    "        Conv1_node,\n",
    "        Add1_node,\n",
    "        Mul2_node,\n",
    "        Transpose1_node,\n",
    "        LogSoftmax1_node,\n",
    "        ArgMax1_node\n",
    "    ],\n",
    "    name=\"4d_conversion_test_graph\",\n",
    "    inputs=[in1_mul1],\n",
    "    outputs=[out1_argmax1],\n",
    "    value_info=[\n",
    "        out1_mul1,\n",
    "        out1_conv1,\n",
    "        out1_add1,\n",
    "        out1_mul2,\n",
    "        out1_transpose1,\n",
    "        out1_logsoftmax1,\n",
    "        in2_mul1,\n",
    "        in2_conv1,\n",
    "        in2_add1,\n",
    "        in2_mul2\n",
    "    ]\n",
    ")\n",
    "\n",
    "#onnx_model = onnx.helper.make_model(graph, producer_name=\"4d_conversion_test-model\")\n",
    "#onnx.save(onnx_model, \"/tmp/4d_conversion_test_model.onnx\")\n",
    "#showInNetron(\"/tmp/4d_conversion_test_model.onnx\")\n",
    "\n",
    "#model = ModelWrapper(\"/tmp/4d_conversion_test_model.onnx\")\n",
    "onnx_model = onnx.helper.make_model(graph, producer_name=\"4d_conversion_test-model\")\n",
    "model = ModelWrapper(onnx_model)\n",
    "\n",
    "\n",
    "# Inputs\n",
    "def generate_random_input(model):\n",
    "    \"\"\" Creates numpy array that matches the input tensor shape \"\"\"\n",
    "    i_shape = []\n",
    "    input_dict={}\n",
    "    for i in range(len(model.graph.input)):\n",
    "        input_node = model.graph.input[i]\n",
    "        input_node_name = input_node.name\n",
    "        input_node_shape = model.get_tensor_shape(input_node_name)\n",
    "\n",
    "        i_val = gen_finn_dt_tensor(DataType.FLOAT32, input_node_shape)\n",
    "        #i_val = np.ones(i_shape).astype(np.float32)\n",
    "        input_dict[input_node_name] = i_val\n",
    "    return input_dict\n",
    "input_dict = generate_random_input(model)\n",
    "\n",
    "# Initializers\n",
    "def set_all_initializers(model):\n",
    "    for n in model.graph.node:\n",
    "        if len(n.input)>1:            \n",
    "            init_name = n.input[1]\n",
    "            init_shape = model.get_tensor_shape(init_name)\n",
    "            init_val = gen_finn_dt_tensor(DataType.FLOAT32, init_shape)\n",
    "            model.set_initializer(init_name, init_val)\n",
    "set_all_initializers(model)\n",
    "\n",
    "onnx.save(onnx_model, \"/tmp/4d_conversion_test_model.onnx\")\n",
    "showInNetron(\"/tmp/4d_conversion_test_model.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/4d_conversion_test_model.onnx' at http://0.0.0.0:8081\n",
      "(1, 128)\n",
      "[[ 1 11  2 28  1  5  7 15 15 10  3 20 24  2 12 20 11 26  8 20 10 10 20  7\n",
      "  17 18  4  7 27 15 13 23  1 14 23 15 28 23 24  3  9  4 12 16 22 23  4  7\n",
      "  16 26  1 28 25 10  0  4  2 10 15 18 20  7  0 28 22  4 20 15 11 18 21  3\n",
      "  15 11  9 23 25 15  3 27 16  0  2 28  7 20 11 20 13 10 14  2  7 19  5 23\n",
      "  14 11 17 13 18 14  4 10 15 15 16 25 14  5 11  4 15 18 26  7  4  3 20 13\n",
      "   6  5  7  6 18 14  8 21]]\n"
     ]
    }
   ],
   "source": [
    "import finn.core.onnx_exec as oxe\n",
    "\n",
    "model = ModelWrapper(\"/tmp/4d_conversion_test_model.onnx\")\n",
    "showInNetron(\"/tmp/4d_conversion_test_model.onnx\")\n",
    "output_node_name = model.graph.output[0].name\n",
    "output_dict = oxe.execute_onnx(model, input_dict, return_full_exec_context=True)\n",
    "expected = output_dict[output_node_name]\n",
    "\n",
    "print(\"{}\\n{}\".format(np.shape(expected),expected))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/4d_conversion_test_model_transformed.onnx' at http://0.0.0.0:8081\n",
      "(1, 128, 1)\n",
      "[[[ 1]\n",
      "  [11]\n",
      "  [ 2]\n",
      "  [28]\n",
      "  [ 1]\n",
      "  [ 5]\n",
      "  [ 7]\n",
      "  [15]\n",
      "  [15]\n",
      "  [10]\n",
      "  [ 3]\n",
      "  [20]\n",
      "  [24]\n",
      "  [ 2]\n",
      "  [12]\n",
      "  [20]\n",
      "  [11]\n",
      "  [26]\n",
      "  [ 8]\n",
      "  [20]\n",
      "  [10]\n",
      "  [10]\n",
      "  [20]\n",
      "  [ 7]\n",
      "  [17]\n",
      "  [18]\n",
      "  [ 4]\n",
      "  [ 7]\n",
      "  [27]\n",
      "  [15]\n",
      "  [13]\n",
      "  [23]\n",
      "  [ 1]\n",
      "  [14]\n",
      "  [23]\n",
      "  [15]\n",
      "  [28]\n",
      "  [23]\n",
      "  [24]\n",
      "  [ 3]\n",
      "  [ 9]\n",
      "  [ 4]\n",
      "  [12]\n",
      "  [16]\n",
      "  [22]\n",
      "  [23]\n",
      "  [ 4]\n",
      "  [ 7]\n",
      "  [16]\n",
      "  [26]\n",
      "  [ 1]\n",
      "  [28]\n",
      "  [25]\n",
      "  [10]\n",
      "  [ 0]\n",
      "  [ 4]\n",
      "  [ 2]\n",
      "  [10]\n",
      "  [15]\n",
      "  [18]\n",
      "  [20]\n",
      "  [ 7]\n",
      "  [ 0]\n",
      "  [28]\n",
      "  [22]\n",
      "  [ 4]\n",
      "  [20]\n",
      "  [15]\n",
      "  [11]\n",
      "  [18]\n",
      "  [21]\n",
      "  [ 3]\n",
      "  [15]\n",
      "  [11]\n",
      "  [ 9]\n",
      "  [23]\n",
      "  [25]\n",
      "  [15]\n",
      "  [ 3]\n",
      "  [27]\n",
      "  [16]\n",
      "  [ 0]\n",
      "  [ 2]\n",
      "  [28]\n",
      "  [ 7]\n",
      "  [20]\n",
      "  [11]\n",
      "  [20]\n",
      "  [13]\n",
      "  [10]\n",
      "  [14]\n",
      "  [ 2]\n",
      "  [ 7]\n",
      "  [19]\n",
      "  [ 5]\n",
      "  [23]\n",
      "  [14]\n",
      "  [11]\n",
      "  [17]\n",
      "  [13]\n",
      "  [18]\n",
      "  [14]\n",
      "  [ 4]\n",
      "  [10]\n",
      "  [15]\n",
      "  [15]\n",
      "  [16]\n",
      "  [25]\n",
      "  [14]\n",
      "  [ 5]\n",
      "  [11]\n",
      "  [ 4]\n",
      "  [15]\n",
      "  [18]\n",
      "  [26]\n",
      "  [ 7]\n",
      "  [ 4]\n",
      "  [ 3]\n",
      "  [20]\n",
      "  [13]\n",
      "  [ 6]\n",
      "  [ 5]\n",
      "  [ 7]\n",
      "  [ 6]\n",
      "  [18]\n",
      "  [14]\n",
      "  [ 8]\n",
      "  [21]]]\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors\n",
    "\n",
    "model = ModelWrapper(\"/tmp/4d_conversion_test_model.onnx\")\n",
    "model = model.transform(Change3DTo4DTensors())\n",
    "model.save(\"/tmp/4d_conversion_test_model_transformed.onnx\")\n",
    "showInNetron(\"/tmp/4d_conversion_test_model_transformed.onnx\")\n",
    "\n",
    "for k,v in input_dict.items():\n",
    "    old_in_name = k\n",
    "    old_in_val = v\n",
    "    old_shape = np.shape(v)\n",
    "    new_in_name = model.graph.input[0].name\n",
    "    new_shape = old_shape + (1,)\n",
    "\n",
    "new_in_val = np.reshape(v, new_shape)\n",
    "del input_dict[old_in_name]\n",
    "input_dict[new_in_name] = new_in_val\n",
    "\n",
    "output_node_name = model.graph.output[0].name\n",
    "output_dict = oxe.execute_onnx(model, input_dict, return_full_exec_context=True)\n",
    "expected2 = output_dict[output_node_name]\n",
    "\n",
    "print(\"{}\\n{}\".format(np.shape(expected2),expected2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "expected3 = np.reshape(expected2, np.shape(expected))\n",
    "print((expected==expected3).all())\n",
    "\n",
    "#assert(expected==expected2).all()\n",
    "\n",
    "#model.save(\"/tmp/4d_conversion_test_model_transformed.onnx\")\n",
    "#showInNetron(\"/tmp/4d_conversion_test_model_transformed.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisited version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnx\n",
    "\n",
    "import finn.core.onnx_exec as oxe\n",
    "from finn.core.datatype import DataType\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors\n",
    "from finn.util.basic import gen_finn_dt_tensor\n",
    "\n",
    "\n",
    "def generate_random_input(model):\n",
    "    \"\"\"\n",
    "    Creates input dictionary with a random numpy array\n",
    "    that matches the input tensor shape.\n",
    "    \"\"\"\n",
    "    input_dict = {}\n",
    "    for i in range(len(model.graph.input)):\n",
    "        input_node = model.graph.input[i]\n",
    "        input_node_name = input_node.name\n",
    "        input_node_shape = model.get_tensor_shape(input_node_name)\n",
    "        i_val = gen_finn_dt_tensor(DataType.FLOAT32, input_node_shape)\n",
    "        input_dict[input_node_name] = i_val\n",
    "    return input_dict\n",
    "\n",
    "\n",
    "def set_all_initializers(model):\n",
    "    \"\"\" Sets all initializers of the graph to a random value. \"\"\"\n",
    "    for n in model.graph.node:\n",
    "        if len(n.input) > 1:\n",
    "            init_name = n.input[1]\n",
    "            init_shape = model.get_tensor_shape(init_name)\n",
    "            init_val = gen_finn_dt_tensor(DataType.FLOAT32, init_shape)\n",
    "            model.set_initializer(init_name, init_val)\n",
    "\n",
    "\n",
    "def create_arbitrary_model(invalid=False):\n",
    "    \"\"\"\n",
    "    Creates arbitrary model for testing the 3D to 4D transform.\n",
    "    This model is based on a subpart of QuartzNet.\n",
    "    \"\"\"\n",
    "    \n",
    "    Mul1_node = onnx.helper.make_node(\n",
    "        \"Mul\",\n",
    "        inputs=[\"in1_mul1\", \"in2_mul1\"],  # inputs\n",
    "        outputs=[\"out1_mul1\"],  # outputs\n",
    "        name=\"Mul1\",  # name\n",
    "    )\n",
    "\n",
    "    Conv1_node = onnx.helper.make_node(\n",
    "        \"Conv\",\n",
    "        inputs=[\"out1_mul1\", \"in2_conv1\"],\n",
    "        outputs=[\"out1_conv1\"],\n",
    "        name=\"Conv1\",\n",
    "        dilations=[1],\n",
    "        group=1,\n",
    "        kernel_shape=[1],\n",
    "        pads=[0, 0],\n",
    "        strides=[1],\n",
    "    )\n",
    "    \n",
    "    if invalid is True: # To make the graph invalid, a ReLU node is added after the Conv node\n",
    "        Relu1_node = onnx.helper.make_node(\n",
    "            \"Relu\", inputs=[\"out1_conv1\"], outputs=[\"out1_relu1\"], name=\"Relu1\"\n",
    "        )\n",
    "        Add1_node = onnx.helper.make_node(\n",
    "            \"Add\", inputs=[\"out1_relu1\", \"in2_add1\"], outputs=[\"out1_add1\"], name=\"Add1\"\n",
    "        )\n",
    "    else:\n",
    "        Add1_node = onnx.helper.make_node(\n",
    "            \"Add\", inputs=[\"out1_conv1\", \"in2_add1\"], outputs=[\"out1_add1\"], name=\"Add1\"\n",
    "        )\n",
    "\n",
    "    Mul2_node = onnx.helper.make_node(\n",
    "        \"Mul\", inputs=[\"out1_add1\", \"in2_mul2\"], outputs=[\"out1_mul2\"], name=\"Mul2\"\n",
    "    )\n",
    "\n",
    "    Transpose1_node = onnx.helper.make_node(\n",
    "        \"Transpose\",\n",
    "        inputs=[\"out1_mul2\"],\n",
    "        outputs=[\"out1_transpose1\"],\n",
    "        name=\"Transpose1\",\n",
    "        perm=[0, 2, 1],\n",
    "    )\n",
    "\n",
    "    LogSoftmax1_node = onnx.helper.make_node(\n",
    "        \"LogSoftmax\",\n",
    "        inputs=[\"out1_transpose1\"],\n",
    "        outputs=[\"out1_logsoftmax1\"],\n",
    "        name=\"LogSoftmax1\",\n",
    "        axis=2,\n",
    "    )\n",
    "\n",
    "    ArgMax1_node = onnx.helper.make_node(\n",
    "        \"ArgMax\",\n",
    "        inputs=[\"out1_logsoftmax1\"],\n",
    "        outputs=[\"out1_argmax1\"],\n",
    "        name=\"ArgMax1\",\n",
    "        axis=-1,\n",
    "        keepdims=0,\n",
    "    )\n",
    "\n",
    "    # Inputs and outputs\n",
    "    in1_mul1 = onnx.helper.make_tensor_value_info(\n",
    "        \"in1_mul1\", onnx.TensorProto.FLOAT, [1, 1024, 128]\n",
    "    )\n",
    "    out1_argmax1 = onnx.helper.make_tensor_value_info(\n",
    "        \"out1_argmax1\", onnx.TensorProto.INT64, [1, 128]\n",
    "    )\n",
    "\n",
    "    # Value infos\n",
    "    out1_mul1 = onnx.helper.make_tensor_value_info(\n",
    "        \"out1_mul1\", onnx.TensorProto.FLOAT, [1, 1024, 128]\n",
    "    )\n",
    "    out1_conv1 = onnx.helper.make_tensor_value_info(\n",
    "        \"out1_conv1\", onnx.TensorProto.FLOAT, [1, 29, 128]\n",
    "    )\n",
    "    \n",
    "    if invalid is True:\n",
    "        out1_relu1 = onnx.helper.make_tensor_value_info(\n",
    "            \"out1_relu1\", onnx.TensorProto.FLOAT, [1, 29, 128]\n",
    "        )\n",
    "\n",
    "    out1_add1 = onnx.helper.make_tensor_value_info(\n",
    "        \"out1_add1\", onnx.TensorProto.FLOAT, [1, 29, 128]\n",
    "    )\n",
    "            \n",
    "    out1_mul2 = onnx.helper.make_tensor_value_info(\n",
    "        \"out1_mul2\", onnx.TensorProto.FLOAT, [1, 29, 128]\n",
    "    )\n",
    "    out1_transpose1 = onnx.helper.make_tensor_value_info(\n",
    "        \"out1_transpose1\", onnx.TensorProto.FLOAT, [1, 128, 29]\n",
    "    )\n",
    "    out1_logsoftmax1 = onnx.helper.make_tensor_value_info(\n",
    "        \"out1_logsoftmax1\", onnx.TensorProto.FLOAT, [1, 128, 29]\n",
    "    )\n",
    "\n",
    "    # Initializers\n",
    "    in2_mul1 = onnx.helper.make_tensor_value_info(\n",
    "        \"in2_mul1\", onnx.TensorProto.FLOAT, [1]\n",
    "    )\n",
    "    in2_conv1 = onnx.helper.make_tensor_value_info(\n",
    "        \"in2_conv1\", onnx.TensorProto.FLOAT, [29, 1024, 1]\n",
    "    )\n",
    "    in2_add1 = onnx.helper.make_tensor_value_info(\n",
    "        \"in2_add1\", onnx.TensorProto.FLOAT, [1, 29, 1]\n",
    "    )\n",
    "    in2_mul2 = onnx.helper.make_tensor_value_info(\n",
    "        \"in2_mul2\", onnx.TensorProto.FLOAT, [1]\n",
    "    )\n",
    "\n",
    "    list_of_nodes = [Mul1_node,\n",
    "            Conv1_node,\n",
    "            Add1_node,\n",
    "            Mul2_node,\n",
    "            Transpose1_node,\n",
    "            LogSoftmax1_node,\n",
    "            ArgMax1_node]\n",
    "    list_of_value_infos = [\n",
    "            out1_mul1,\n",
    "            out1_conv1,\n",
    "            out1_add1,\n",
    "            out1_mul2,\n",
    "            out1_transpose1,\n",
    "            out1_logsoftmax1,\n",
    "            in2_mul1,\n",
    "            in2_conv1,\n",
    "            in2_add1,\n",
    "            in2_mul2\n",
    "        ]\n",
    "    \n",
    "    if invalid is True:\n",
    "        list_of_nodes.insert(2, Relu1_node)\n",
    "        list_of_value_infos.append(out1_relu1)\n",
    "    \n",
    "    graph = onnx.helper.make_graph(\n",
    "            nodes=list_of_nodes,\n",
    "            name=\"4d_conversion_test_graph\",\n",
    "            inputs=[in1_mul1],\n",
    "            outputs=[out1_argmax1],\n",
    "            value_info=list_of_value_infos\n",
    "        )        \n",
    "    onnx_model = onnx.helper.make_model(\n",
    "        graph, producer_name=\"4d_conversion_test-model\"\n",
    "    )\n",
    "    model = ModelWrapper(onnx_model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def test_4d_conversion():\n",
    "    \"\"\"\n",
    "    Test for the 3D to 4D transformation with a valid graph.\n",
    "    \"\"\"\n",
    "    model = create_arbitrary_model(invalid=False)\n",
    "\n",
    "    # Inputs\n",
    "    input_dict = generate_random_input(model)\n",
    "\n",
    "    # Initializers\n",
    "    set_all_initializers(model)\n",
    "\n",
    "    # Comparing the outputs of the model before and after the transform\n",
    "    output_node_name = model.graph.output[0].name\n",
    "    output_dict = oxe.execute_onnx(model, input_dict, return_full_exec_context=True)\n",
    "    expected = output_dict[output_node_name]\n",
    "\n",
    "    model = model.transform(Change3DTo4DTensors())\n",
    "\n",
    "    for k, v in input_dict.items():\n",
    "        old_in_name = k\n",
    "        old_shape = np.shape(v)\n",
    "        new_in_name = model.graph.input[0].name\n",
    "        new_shape = old_shape + (1,)\n",
    "    new_in_val = np.reshape(v, new_shape)\n",
    "    del input_dict[old_in_name]\n",
    "    input_dict[new_in_name] = new_in_val\n",
    "\n",
    "    output_node_name = model.graph.output[0].name\n",
    "    output_dict = oxe.execute_onnx(model, input_dict, return_full_exec_context=True)\n",
    "    expected_modified = output_dict[output_node_name]\n",
    "\n",
    "    expected_modified = np.reshape(expected_modified, np.shape(expected))\n",
    "\n",
    "    assert (expected == expected_modified).all()\n",
    "\n",
    "\n",
    "def test_4d_conversion_invalid_nodes():\n",
    "    \"\"\"\n",
    "    Test for the 3D to 4D transformation when an invalid graph is supplied.\n",
    "    \"\"\"\n",
    "    model = create_arbitrary_model(invalid=True)\n",
    "\n",
    "    # Inputs\n",
    "    input_dict = generate_random_input(model)\n",
    "\n",
    "    # Initializers\n",
    "    set_all_initializers(model)\n",
    "\n",
    "    # Comparing the outputs of the model before and after the transform\n",
    "    output_node_name = model.graph.output[0].name\n",
    "    output_dict = oxe.execute_onnx(model, input_dict, return_full_exec_context=True)\n",
    "    expected = output_dict[output_node_name]\n",
    "\n",
    "    model = model.transform(Change3DTo4DTensors())\n",
    "\n",
    "    output_node_name = model.graph.output[0].name\n",
    "    output_dict = oxe.execute_onnx(model, input_dict, return_full_exec_context=True)\n",
    "    expected_modified = output_dict[output_node_name]\n",
    "\n",
    "    expected_modified = np.reshape(expected_modified, np.shape(expected))\n",
    "\n",
    "    assert (expected == expected_modified).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn-base/src/finn/transformation/change_3d_tensors_to_4d.py:82: UserWarning: Found invalid nodes in the graph: ['Relu']. Transformation has not been applied.\n",
      "  invalid_nodes\n"
     ]
    }
   ],
   "source": [
    "test_4d_conversion()\n",
    "test_4d_conversion_invalid_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/tmp/4d_conversion_test_model.onnx\")\n",
    "model = ModelWrapper(\"/tmp/4d_conversion_test_model.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code commented (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_3d_to_4d_tensors(model):\n",
    "#     \"\"\" Converts 3D tensors (input, value_info, output) to 4D tensors \"\"\"\n",
    "#     tensor_names = {}\n",
    "#     ## Inputs\n",
    "#     for t in model.graph.input:\n",
    "#         tensor_name = t.name\n",
    "#         tensor_type = t.type.tensor_type.elem_type\n",
    "#         tensor_shape = model.get_tensor_shape(tensor_name)\n",
    "#         tensor_names[tensor_name] = [tensor_type]\n",
    "#         tensor_names[tensor_name].append(tensor_shape)\n",
    "#\n",
    "#     ## Initializers\n",
    "#     initializer_names = []\n",
    "#     for i in model.graph.initializer:\n",
    "#         initializer_names.append(i.name)\n",
    "#\n",
    "#     ## Value infos\n",
    "#     for t in model.graph.value_info:\n",
    "#         tensor_name = t.name\n",
    "#         if tensor_name in initializer_names:\n",
    "#             continue\n",
    "#         else:\n",
    "#             tensor_type = t.type.tensor_type.elem_type\n",
    "#             tensor_shape = model.get_tensor_shape(tensor_name)\n",
    "#             tensor_names[tensor_name] = [tensor_type]\n",
    "#             tensor_names[tensor_name].append(tensor_shape)\n",
    "#\n",
    "#     ## Outputs\n",
    "#     for t in model.graph.output:\n",
    "#         tensor_name = t.name\n",
    "#         tensor_type = t.type.tensor_type.elem_type\n",
    "#         tensor_shape = model.get_tensor_shape(tensor_name)\n",
    "#         tensor_names[tensor_name] = [tensor_type]\n",
    "#         tensor_names[tensor_name].append(tensor_shape)\n",
    "#\n",
    "#     ## Find tensors that are the output of nodes that reduce the dimension\n",
    "#     tensors_reduced_dimension = []\n",
    "#     for n in model.graph.node:\n",
    "#         if n.op_type==\"ArgMax\":\n",
    "#             keep_dims = get_by_name(n.attribute, \"keepdims\", \"name\").i\n",
    "#             if keep_dims == 0:\n",
    "#                 node_out = n.output\n",
    "#                 for n_o in node_out:\n",
    "#                     tensors_reduced_dimension.append(n_o)\n",
    "#\n",
    "#     ## Change format of each value_info + input + output tensors\n",
    "#     for k, v in tensor_names.items():\n",
    "#         tensor_type = v[0]\n",
    "#         shape = v[1]\n",
    "#         ## Add extra dimension for tensors:\n",
    "#         # 1) Have 3 dimensions (NCH -> NCH1)\n",
    "#         # 2) Tensors following operations that reduce their dimension: {Argmax, ...}\n",
    "#         if len(shape)==3 or k in tensors_reduced_dimension:\n",
    "#             shape.append(1)\n",
    "#             model.set_tensor_shape(k, shape, tensor_type)\n",
    "#         else:\n",
    "#             continue\n",
    "#\n",
    "# def make_node_4d_compatible(model):\n",
    "#     \"\"\" Each node from the list of supported nodes is made compatible with 4D tensors\"\"\"\n",
    "#     for n in model.graph.node:\n",
    "#         node_op_type = n.op_type\n",
    "#         if node_op_type == \"Transpose\":\n",
    "#             perm = get_by_name(n.attribute,\"perm\", \"name\").ints\n",
    "#             if len(perm) == 3: # Meaning transpose was on 3D tensor\n",
    "#                 perm.append(3) # append 4th dimension\n",
    "#         elif node_op_type == \"ArgMax\" or node_op_type == \"LogSoftMax\":\n",
    "#             axis = get_by_name(n.attribute, \"axis\", \"name\")\n",
    "#             if axis.i == -1:\n",
    "#                 axis.i = 2 # argmax is now on the second-to-last axis\n",
    "#         elif node_op_type == \"Conv\":\n",
    "#             dilations = get_by_name(n.attribute, \"dilations\", \"name\").ints\n",
    "#             kernel_shape = get_by_name(n.attribute, \"kernel_shape\", \"name\").ints\n",
    "#             pads = get_by_name(n.attribute, \"pads\", \"name\").ints\n",
    "#             strides = get_by_name(n.attribute, \"strides\", \"name\").ints\n",
    "#             if len(dilations) == 1: # we must add another dimension to it\n",
    "#                 dilations.append(dilations[0]) # only equal dilation value along each spatial axis is supported\n",
    "#             if len(kernel_shape) == 1: # we must add another dimension to it\n",
    "#                 kernel_shape.append(1)\n",
    "#             if len(pads) == 2: # pads = ([x1_begin, x1_end] -->) [x1_begin, x2_begin, x1_end, x2_end]\n",
    "#                 pads.insert(1, 0)\n",
    "#                 pads.append(0)\n",
    "#             if len(strides) == 1: # strides = [stride_H, stride_W]\n",
    "#                 strides.append(1)\n",
    "#\n",
    "# def create_4d_initializers_conv_mul_add_node(model):\n",
    "#     \"\"\" Conv, Mul and Add nodes are made compatible with 4D input tensors \"\"\"\n",
    "#     initializers = {}\n",
    "#     for i in model.graph.initializer:\n",
    "#         init_name = i.name\n",
    "#         if \"Conv\" in init_name:\n",
    "#             init_dim = i.dims\n",
    "#             init_dtype = i.data_type\n",
    "#             initializers[init_name] = [init_dtype]\n",
    "#             initializers[init_name].append(init_dim)\n",
    "#         elif init_name[0:4] == \"Mul_\":\n",
    "#             init_dim = i.dims\n",
    "#             if len(i.dims) == 3:\n",
    "#                 init_dtype = i.data_type\n",
    "#                 initializers[init_name] = [init_dtype]\n",
    "#                 initializers[init_name].append(init_dim)\n",
    "#         elif \"Add\" in init_name:\n",
    "#             init_dim = i.dims\n",
    "#             if len(i.dims) == 3:\n",
    "#                 init_dtype = i.data_type\n",
    "#                 initializers[init_name] = [init_dtype]\n",
    "#                 initializers[init_name].append(init_dim)\n",
    "#         else:\n",
    "#             continue\n",
    "#\n",
    "#     for k, v in initializers.items():\n",
    "#         init_dtype = v[0]\n",
    "#         init_shape = v[1]\n",
    "#         if len(init_shape) == 3:\n",
    "#             # Change shape NCH -> NCH1\n",
    "#             init_shape.append(1)\n",
    "#             shape_init = model.get_initializer(k).shape\n",
    "#             model.set_tensor_shape(k, init_shape, init_dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
