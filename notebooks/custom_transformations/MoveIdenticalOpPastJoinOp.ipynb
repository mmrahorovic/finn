{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "comfortable-language",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_move_identical_op_past_join_op.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4b3dad6160>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from finn.util.visualization import showInNetron\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "import onnx\n",
    "\n",
    "Transpose1_node = onnx.helper.make_node(\n",
    "    \"Transpose\",\n",
    "    inputs = ['in_transpose1'],\n",
    "    outputs = ['out_transpose1'],\n",
    "    perm = [0, 3, 1, 2]\n",
    ")\n",
    "\n",
    "Transpose2_node = onnx.helper.make_node(\n",
    "    \"Transpose\",\n",
    "    inputs = ['in_transpose2'],\n",
    "    outputs = ['out_transpose2'],\n",
    "    perm = [0, 3, 1, 2]\n",
    ")\n",
    "\n",
    "Join1_node = onnx.helper.make_node(\n",
    "    \"Add\",\n",
    "    inputs = ['out_transpose1', 'out_transpose2'],\n",
    "    outputs = ['out_join1']\n",
    ")\n",
    "\n",
    "in_transpose1 = onnx.helper.make_tensor_value_info('in_transpose1', onnx.TensorProto.FLOAT, [1, 128, 1, 256])\n",
    "in_transpose2 = onnx.helper.make_tensor_value_info('in_transpose2', onnx.TensorProto.FLOAT, [1, 128, 1, 256])\n",
    "out_transpose1 = onnx.helper.make_tensor_value_info('out_transpose1', onnx.TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "out_transpose2 = onnx.helper.make_tensor_value_info('out_transpose2', onnx.TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "out_join1 = onnx.helper.make_tensor_value_info('out_join1', onnx.TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "\n",
    "graph = onnx.helper.make_graph(\n",
    "    nodes = [\n",
    "        Transpose1_node,\n",
    "        Transpose2_node,\n",
    "        Join1_node\n",
    "    ],\n",
    "    name = 'test_graph',\n",
    "    inputs = [in_transpose1, in_transpose2],\n",
    "    outputs = [out_join1],\n",
    "    value_info = [\n",
    "        out_transpose1,\n",
    "        out_transpose2,\n",
    "        out_join1\n",
    "    ]\n",
    ")\n",
    "\n",
    "onnx_model = onnx.helper.make_model(graph, producer_name='test_model')\n",
    "model = ModelWrapper(onnx_model)\n",
    "\n",
    "model.save(\"/tmp/test_move_identical_op_past_join_op.onnx\")\n",
    "showInNetron(\"/tmp/test_move_identical_op_past_join_op.onnx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "illegal-stanley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_move_identical_op_past_join_op_modified.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4b3c03fc18>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSPIRATION: MoveLinearPastEltwiseAdd\n",
    "\n",
    "import onnx\n",
    "from finn.transformation.general import SortGraph\n",
    "\n",
    "# Move identical operations on different branches past the common join node. Transformation should be applied when\n",
    "# the identical operations are changing the data layout. For linear operations, see the transformation MoveLinearPastEltwiseAdd\n",
    "# Specifically, this transformation matches and transforms the following patterns:\n",
    "# f(x) + f(y) -> f(x + y)\n",
    "# f(x) - f(y) -> f(x - y)\n",
    "# where f(.) is currently only supporting 'Transpose'\n",
    "\n",
    "model = ModelWrapper(\"/tmp/test_move_identical_op_past_join_op.onnx\")\n",
    "\n",
    "identical_op_list = ['Transpose']\n",
    "join_op_list = ['Add']\n",
    "\n",
    "graph = model.graph\n",
    "node_ind = 0\n",
    "graph_modified = False\n",
    "\n",
    "def move_node(graph, n, prod0, prod1, node_ind):\n",
    "    # found! move one of the identical_ops to output, remove the other one\n",
    "    identical_op0_in0 = prod0.input[0]\n",
    "    identical_op1_in0 = prod1.input[0]\n",
    "    add_in0 = n.input[0]\n",
    "    add_out = n.output[0]\n",
    "    \n",
    "    # Rewire\n",
    "    n.input[0] = identical_op0_in0 # CHECK\n",
    "    n.input[1] = identical_op1_in0 # CHECK\n",
    "    \n",
    "    # Now we create the new output tensor\n",
    "    # Output tensor of the join node must have the same shape as its input tensor (shape preserving)\n",
    "    new_shape = model.get_tensor_shape(identical_op0_in0)\n",
    "    # FINN datatype should be set to the tensor datatype of the output tensor of the add node\n",
    "    finn_data_type = model.get_tensor_datatype(add_out) \n",
    "    # ONNX datatype must be set to the tensor datatype of the output tensor of the add node\n",
    "    value_info_addout = model.get_tensor_valueinfo(add_out)\n",
    "    onnx_data_type = value_info_addout.type.tensor_type.elem_type\n",
    "    \n",
    "    # Set new tensor shape with appropriate ONNX and FINN datatypes.\n",
    "    model.set_tensor_shape(\n",
    "        tensor_name = add_in0,\n",
    "        tensor_shape = new_shape,\n",
    "        dtype = onnx_data_type\n",
    "    )\n",
    "    model.set_tensor_datatype(add_in0, finn_data_type)\n",
    "    \n",
    "    n.output[0] = add_in0 # CHECK\n",
    "    prod0.input[0] = add_in0 # CHECK\n",
    "    prod0.output[0] = add_out # CHECK\n",
    "    \n",
    "    graph.node.remove(prod1)\n",
    "    \n",
    "for n in model.graph.node:\n",
    "    node_ind += 1\n",
    "    if n.op_type in join_op_list and model.is_join_node(n):\n",
    "        in0 = n.input[0]\n",
    "        in1 = n.input[1]\n",
    "        if in0 is None or in1 is None:\n",
    "            continue\n",
    "        \n",
    "        prod0 = model.find_producer(in0)\n",
    "        prod1 = model.find_producer(in1)\n",
    "        if prod0 is None or prod1 is None or prod0==prod1: # is this needed?\n",
    "            continue\n",
    "        \n",
    "        identical_op = prod0.op_type == prod1.op_type\n",
    "        \n",
    "        if identical_op and prod0.op_type in identical_op_list:\n",
    "            # Currently, only transpose operation is supported. Adding additional op_types can be done by extending\n",
    "            # the if-branches below. \n",
    "            if prod0.op_type == 'Transpose':\n",
    "                move_node(graph, n, prod0, prod1, node_ind)\n",
    "                \n",
    "model = model.transform(SortGraph())\n",
    "                \n",
    "                \n",
    "model.save(\"/tmp/test_move_identical_op_past_join_op_modified.onnx\")\n",
    "showInNetron(\"/tmp/test_move_identical_op_past_join_op_modified.onnx\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "widespread-restaurant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from finn.util.basic import gen_finn_dt_tensor\n",
    "from finn.core.datatype import DataType\n",
    "import finn.core.onnx_exec as oxe\n",
    "\n",
    "model = ModelWrapper(\"/tmp/test_move_identical_op_past_join_op.onnx\")\n",
    "model_transformed = ModelWrapper(\"/tmp/test_move_identical_op_past_join_op_modified.onnx\")\n",
    "\n",
    "# Create input data\n",
    "input0_tensor_name = model.graph.input[0].name\n",
    "input1_tensor_name = model.graph.input[1].name\n",
    "\n",
    "# Note: it is assumed that both tensors have the same shape and data type\n",
    "input_shape = model.get_tensor_shape(input0_tensor_name)\n",
    "input_dtype = model.get_tensor_datatype(input0_tensor_name)\n",
    "input_val = gen_finn_dt_tensor(input_dtype, input_shape)\n",
    "input_dict = {}\n",
    "input_dict[input0_tensor_name] = input_val\n",
    "input_dict[input1_tensor_name] = input_val\n",
    "\n",
    "is_same = oxe.compare_execution(model, model_transformed, input_dict)\n",
    "\n",
    "print(is_same)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-bouquet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-headquarters",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.base import Transformation\n",
    "import onnx\n",
    "from finn.transformation.general import SortGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoveIdenticalOpPastJoinOp(Transformation):\n",
    "    \"\"\"\n",
    "    Move identical operations on different branches past the common join node.\n",
    "    Transformation should be applied when\n",
    "    the identical operations are changing the data layout. For linear operations, see the transformation MoveLinearPastEltwiseAdd\n",
    "    Specifically, this transformation matches and transforms the following patterns:\n",
    "    f(x) + f(y) -> f(x + y)\n",
    "    f(x) - f(y) -> f(x - y)\n",
    "    where f(.) is currently only supporting 'Transpose' \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, identical_op_list, join_node_list):\n",
    "        super().__init__()\n",
    "        self.ops_to_move = identical_op_list\n",
    "        self.join_node_op = join_node_list\n",
    "    \n",
    "    def move_node(graph, n, prod0, prod1, node_ind):\n",
    "            # found! move one of the identical_ops to output, remove the other one\n",
    "            identical_op0_in0 = prod0.input[0]\n",
    "            identical_op1_in0 = prod1.input[0]\n",
    "            add_in0 = n.input[0]\n",
    "            add_out = n.output[0]\n",
    "\n",
    "            # Rewire\n",
    "            n.input[0] = identical_op0_in0 # CHECK\n",
    "            n.input[1] = identical_op1_in0 # CHECK\n",
    "\n",
    "            # Now we create the new output tensor\n",
    "            # Output tensor of the join node must have the same shape as its input tensor (shape preserving)\n",
    "            new_shape = model.get_tensor_shape(identical_op0_in0)\n",
    "            # FINN datatype should be set to the tensor datatype of the output tensor of the add node\n",
    "            finn_data_type = model.get_tensor_datatype(add_out) \n",
    "            # ONNX datatype must be set to the tensor datatype of the output tensor of the add node\n",
    "            value_info_addout = model.get_tensor_valueinfo(add_out)\n",
    "            onnx_data_type = value_info_addout.type.tensor_type.elem_type\n",
    "\n",
    "            # Set new tensor shape with appropriate ONNX and FINN datatypes.\n",
    "            model.set_tensor_shape(\n",
    "                tensor_name = add_in0,\n",
    "                tensor_shape = new_shape,\n",
    "                dtype = onnx_data_type\n",
    "            )\n",
    "            model.set_tensor_datatype(add_in0, finn_data_type)\n",
    "\n",
    "            n.output[0] = add_in0 # CHECK\n",
    "            prod0.input[0] = add_in0 # CHECK\n",
    "            prod0.output[0] = add_out # CHECK\n",
    "\n",
    "            graph.node.remove(prod1)\n",
    "    \n",
    "    def apply(self, model):\n",
    "        graph = model.graph\n",
    "        graph_modified = False\n",
    "        for n in model.graph.node:\n",
    "            if n.op_type in self.join_node_op and model.is_join_node(n):\n",
    "                in0 = n.input[0]\n",
    "                in1 = n.input[1]\n",
    "                if in0 is None or in1 is None:\n",
    "                    continue\n",
    "\n",
    "                prod0 = model.find_producer(in0)\n",
    "                prod1 = model.find_producer(in1)\n",
    "                if prod0 is None or prod1 is None or prod0==prod1: # is this needed?\n",
    "                    continue\n",
    "\n",
    "                identical_op = prod0.op_type == prod1.op_type\n",
    "\n",
    "                if identical_op and prod0.op_type in self.ops_to_move:\n",
    "                    move_node(graph, n, prod0, prod1, node_ind)\n",
    "                    graph_modified = True\n",
    "\n",
    "        if graph_modified:\n",
    "            model = model.transform(SortGraph(), )\n",
    "\n",
    "\n",
    "        model.save(\"/tmp/test_move_identical_op_past_join_op_modified.onnx\")\n",
    "        showInNetron(\"/tmp/test_move_identical_op_past_join_op_modified.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(\"/tmp/test_move_identical_op_past_join_op.onnx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
