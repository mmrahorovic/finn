{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comfortable-language",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/tmp/test_move_identical_op_past_join_op.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc21814a2b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from finn.util.visualization import showInNetron\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "import onnx\n",
    "\n",
    "Transpose1_node = onnx.helper.make_node(\n",
    "    \"Transpose\",\n",
    "    inputs = ['in_transpose1'],\n",
    "    outputs = ['out_transpose1'],\n",
    "    perm = [0, 3, 1, 2]\n",
    ")\n",
    "\n",
    "Transpose2_node = onnx.helper.make_node(\n",
    "    \"Transpose\",\n",
    "    inputs = ['in_transpose2'],\n",
    "    outputs = ['out_transpose2'],\n",
    "    perm = [0, 3, 1, 2]\n",
    ")\n",
    "\n",
    "Join1_node = onnx.helper.make_node(\n",
    "    \"Add\",\n",
    "    inputs = ['out_transpose1', 'out_transpose2'],\n",
    "    outputs = ['out_join1']\n",
    ")\n",
    "\n",
    "in_transpose1 = onnx.helper.make_tensor_value_info('in_transpose1', onnx.TensorProto.FLOAT, [1, 128, 1, 256])\n",
    "in_transpose2 = onnx.helper.make_tensor_value_info('in_transpose2', onnx.TensorProto.FLOAT, [1, 128, 1, 256])\n",
    "out_transpose1 = onnx.helper.make_tensor_value_info('out_transpose1', onnx.TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "out_transpose2 = onnx.helper.make_tensor_value_info('out_transpose2', onnx.TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "out_join1 = onnx.helper.make_tensor_value_info('out_join1', onnx.TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "\n",
    "graph = onnx.helper.make_graph(\n",
    "    nodes = [\n",
    "        Transpose1_node,\n",
    "        Transpose2_node,\n",
    "        Join1_node\n",
    "    ],\n",
    "    name = 'test_graph',\n",
    "    inputs = [in_transpose1, in_transpose2],\n",
    "    outputs = [out_join1],\n",
    "    value_info = [\n",
    "        in_transpose1,\n",
    "        in_transpose2,\n",
    "        out_transpose1,\n",
    "        out_transpose2,\n",
    "        out_join1\n",
    "    ]\n",
    ")\n",
    "\n",
    "onnx_model = onnx.helper.make_model(graph, producer_name='test_model')\n",
    "model = ModelWrapper(onnx_model)\n",
    "\n",
    "model.save(\"/tmp/test_move_identical_op_past_join_op.onnx\")\n",
    "showInNetron(\"/tmp/test_move_identical_op_past_join_op.onnx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "illegal-stanley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_move_identical_op_past_join_op_modified.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc21814a278>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSPIRATION: MoveLinearPastEltwiseAdd\n",
    "\n",
    "import onnx\n",
    "from finn.transformation.general import SortGraph\n",
    "\n",
    "# Move identical operations on different branches past the common join node. Transformation should be applied when\n",
    "# the identical operations are changing the data layout. For linear operations, see the transformation MoveLinearPastEltwiseAdd\n",
    "# Specifically, this transformation matches and transforms the following patterns:\n",
    "# f(x) + f(y) -> f(x + y)\n",
    "# f(x) - f(y) -> f(x - y)\n",
    "# where f(.) is currently only supporting 'Transpose'\n",
    "\n",
    "model = ModelWrapper(\"/tmp/test_move_identical_op_past_join_op.onnx\")\n",
    "\n",
    "identical_op_list = ['Transpose']\n",
    "join_op_list = ['Add']\n",
    "\n",
    "graph = model.graph\n",
    "node_ind = 0\n",
    "graph_modified = False\n",
    "\n",
    "def move_node(graph, n, prod0, prod1, node_ind):\n",
    "    # found! move one of the identical_ops to output, remove the other one\n",
    "    identical_op0_in0 = prod0.input[0]\n",
    "    identical_op1_in0 = prod1.input[0]\n",
    "    add_in0 = n.input[0]\n",
    "    add_out = n.output[0]\n",
    "    \n",
    "    # Rewire\n",
    "    n.input[0] = identical_op0_in0 # CHECK\n",
    "    n.input[1] = identical_op1_in0 # CHECK\n",
    "    \n",
    "    # Now we create the new output tensor\n",
    "    # Output tensor of the join node must have the same shape as its input tensor (shape preserving)\n",
    "    new_shape = model.get_tensor_shape(identical_op0_in0)\n",
    "    # FINN datatype should be set to the tensor datatype of the output tensor of the add node\n",
    "    finn_data_type = model.get_tensor_datatype(add_out) \n",
    "    # ONNX datatype must be set to the tensor datatype of the output tensor of the add node\n",
    "    value_info_addout = model.get_tensor_valueinfo(add_out)\n",
    "    onnx_data_type = value_info_addout.type.tensor_type.elem_type\n",
    "    \n",
    "    # Set new tensor shape with appropriate ONNX and FINN datatypes.\n",
    "    model.set_tensor_shape(\n",
    "        tensor_name = add_in0,\n",
    "        tensor_shape = new_shape,\n",
    "        dtype = onnx_data_type\n",
    "    )\n",
    "    model.set_tensor_datatype(add_in0, finn_data_type)\n",
    "    \n",
    "    n.output[0] = add_in0 # CHECK\n",
    "    prod0.input[0] = add_in0 # CHECK\n",
    "    prod0.output[0] = add_out # CHECK\n",
    "    \n",
    "    graph.node.remove(prod1)\n",
    "    \n",
    "for n in model.graph.node:\n",
    "    node_ind += 1\n",
    "    if n.op_type in join_op_list and model.is_join_node(n):\n",
    "        in0 = n.input[0]\n",
    "        in1 = n.input[1]\n",
    "        if in0 is None or in1 is None:\n",
    "            continue\n",
    "        \n",
    "        prod0 = model.find_producer(in0)\n",
    "        prod1 = model.find_producer(in1)\n",
    "        if prod0 is None or prod1 is None or prod0==prod1: # is this needed?\n",
    "            continue\n",
    "        \n",
    "        identical_op = prod0.op_type == prod1.op_type\n",
    "        \n",
    "        if identical_op and prod0.op_type in identical_op_list:\n",
    "            # Currently, only transpose operation is supported. Adding additional op_types can be done by extending\n",
    "            # the if-branches below. \n",
    "            if prod0.op_type == 'Transpose':\n",
    "                move_node(graph, n, prod0, prod1, node_ind)\n",
    "                \n",
    "model = model.transform(SortGraph())\n",
    "                \n",
    "                \n",
    "model.save(\"/tmp/test_move_identical_op_past_join_op_modified.onnx\")\n",
    "showInNetron(\"/tmp/test_move_identical_op_past_join_op_modified.onnx\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "widespread-restaurant",
   "metadata": {},
   "outputs": [
    {
     "ename": "Fail",
     "evalue": "[ONNXRuntimeError] : 1 : FAIL : Error: Duplicate definition-site for (in_transpose1).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFail\u001b[0m                                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fa83b6dd9526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/tmp/test_move_identical_op_past_join_op.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/tmp/test_move_transpose_past_mt_modified.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mis_same\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moxe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#print(is_same)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn-base/src/finn/core/onnx_exec.py\u001b[0m in \u001b[0;36mcompare_execution\u001b[0;34m(model_a, model_b, input_dict, compare_fxn)\u001b[0m\n\u001b[1;32m    262\u001b[0m     compare_fxn should take in two tensors and return a Boolean\"\"\"\n\u001b[1;32m    263\u001b[0m     \u001b[0;31m# compare values from first output tensors produced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mres_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0mres_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompare_fxn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn-base/src/finn/core/onnx_exec.py\u001b[0m in \u001b[0;36mexecute_onnx\u001b[0;34m(model, input_dict, return_full_exec_context, start_node, end_node)\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 )\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mexecute_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_full_exec_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mget_sanitize_quant_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;31m# round output values to quantization annotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn-base/src/finn/core/onnx_exec.py\u001b[0m in \u001b[0;36mexecute_node\u001b[0;34m(node, context, graph, return_full_exec_context)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0moutput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/onnxruntime/capi/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path_or_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/onnxruntime/capi/session.py\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m(self, providers)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to load from type '{0}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path_or_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFail\u001b[0m: [ONNXRuntimeError] : 1 : FAIL : Error: Duplicate definition-site for (in_transpose1)."
     ]
    }
   ],
   "source": [
    "from finn.util.basic import gen_finn_dt_tensor\n",
    "from finn.core.datatype import DataType\n",
    "import finn.core.onnx_exec as oxe\n",
    "\n",
    "# Create input data\n",
    "input0_tensor_name = model.graph.input[0].name\n",
    "input1_tensor_name = model.graph.input[1].name\n",
    "\n",
    "# Note: it is assumed that both tensors have the same shape and data type\n",
    "input_shape = model.get_tensor_shape(input0_tensor_name)\n",
    "input_dtype = model.get_tensor_datatype(input0_tensor_name)\n",
    "input_val = gen_finn_dt_tensor(input_dtype, input_shape)\n",
    "input_dict = {}\n",
    "input_dict[input0_tensor_name] = input_val\n",
    "input_dict[input1_tensor_name] = input_val\n",
    "\n",
    "model = ModelWrapper(\"/tmp/test_move_identical_op_past_join_op.onnx\")\n",
    "model_transformed = ModelWrapper(\"/tmp/test_move_transpose_past_mt_modified.onnx\")\n",
    "is_same = oxe.compare_execution(model, model_transformed, input_dict)\n",
    "\n",
    "#print(is_same)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
