{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comfortable-language",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/tmp/test_move_identical_op_past_join_op.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8e44058400>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from finn.util.visualization import showInNetron\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "import onnx\n",
    "from finn.core.datatype import DataType\n",
    "\n",
    "Transpose1_node = onnx.helper.make_node(\n",
    "    \"Transpose\",\n",
    "    inputs = ['in_transpose1'],\n",
    "    outputs = ['out_transpose1'],\n",
    "    perm = [0, 3, 1, 2]\n",
    ")\n",
    "\n",
    "Transpose2_node = onnx.helper.make_node(\n",
    "    \"Transpose\",\n",
    "    inputs = ['in_transpose2'],\n",
    "    outputs = ['out_transpose2'],\n",
    "    perm = [0, 3, 1, 2]\n",
    ")\n",
    "\n",
    "Join1_node = onnx.helper.make_node(\n",
    "    \"Add\",\n",
    "    inputs = ['out_transpose1', 'out_transpose2'],\n",
    "    outputs = ['out_join1']\n",
    ")\n",
    "\n",
    "in_transpose1 = onnx.helper.make_tensor_value_info('in_transpose1', onnx.TensorProto.FLOAT, [1, 128, 1, 256])\n",
    "in_transpose2 = onnx.helper.make_tensor_value_info('in_transpose2', onnx.TensorProto.FLOAT, [1, 128, 1, 256])\n",
    "out_transpose1 = onnx.helper.make_tensor_value_info('out_transpose1', onnx.TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "out_transpose2 = onnx.helper.make_tensor_value_info('out_transpose2', onnx.TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "out_join1 = onnx.helper.make_tensor_value_info('out_join1', onnx.TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "\n",
    "graph = onnx.helper.make_graph(\n",
    "    nodes = [\n",
    "        Transpose1_node,\n",
    "        Transpose2_node,\n",
    "        Join1_node\n",
    "    ],\n",
    "    name = 'test_graph',\n",
    "    inputs = [in_transpose1, in_transpose2],\n",
    "    outputs = [out_join1],\n",
    "    value_info = [\n",
    "        out_transpose1,\n",
    "        out_transpose2\n",
    "    ]\n",
    ")\n",
    "\n",
    "onnx_model = onnx.helper.make_model(graph, producer_name='test_model')\n",
    "model = ModelWrapper(onnx_model)\n",
    "\n",
    "model.set_tensor_datatype('out_transpose1', DataType.UINT4)\n",
    "\n",
    "model.save(\"/tmp/test_move_identical_op_past_join_op.onnx\")\n",
    "showInNetron(\"/tmp/test_move_identical_op_past_join_op.onnx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "illegal-stanley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_move_identical_op_past_join_op_modified.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f81b84acf98>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSPIRATION: MoveLinearPastEltwiseAdd\n",
    "\n",
    "import onnx\n",
    "from finn.transformation.general import SortGraph\n",
    "\n",
    "# Move identical operations on different branches past the common join node. Transformation should be applied when\n",
    "# the identical operations are changing the data layout. For linear operations, see the transformation MoveLinearPastEltwiseAdd\n",
    "# Specifically, this transformation matches and transforms the following patterns:\n",
    "# f(x) + f(y) -> f(x + y)\n",
    "# f(x) - f(y) -> f(x - y)\n",
    "# where f(.) is currently only supporting 'Transpose'\n",
    "\n",
    "model = ModelWrapper(\"/tmp/test_move_identical_op_past_join_op.onnx\")\n",
    "\n",
    "identical_op_list = ['Transpose']\n",
    "join_op_list = ['Add']\n",
    "\n",
    "graph = model.graph\n",
    "node_ind = 0\n",
    "graph_modified = False\n",
    "\n",
    "def move_node(graph, n, prod0, prod1, node_ind):\n",
    "    # found! move one of the identical_ops to output, remove the other one\n",
    "    identical_op0_in0 = prod0.input[0]\n",
    "    identical_op1_in0 = prod1.input[0]\n",
    "    add_in0 = n.input[0]\n",
    "    add_out = n.output[0]\n",
    "    \n",
    "    # Rewire\n",
    "    n.input[0] = identical_op0_in0 # CHECK\n",
    "    n.input[1] = identical_op1_in0 # CHECK\n",
    "    \n",
    "    # Now we create the new output tensor\n",
    "    # Output tensor of the join node must have the same shape as its input tensor (shape preserving)\n",
    "    new_shape = model.get_tensor_shape(identical_op0_in0)\n",
    "    # FINN datatype should be set to the tensor datatype of the output tensor of the add node\n",
    "    finn_data_type = model.get_tensor_datatype(add_out) \n",
    "    # ONNX datatype must be set to the tensor datatype of the output tensor of the add node\n",
    "    value_info_addout = model.get_tensor_valueinfo(add_out)\n",
    "    onnx_data_type = value_info_addout.type.tensor_type.elem_type\n",
    "    \n",
    "    # Set new tensor shape with appropriate ONNX and FINN datatypes.\n",
    "    model.set_tensor_shape(\n",
    "        tensor_name = add_in0,\n",
    "        tensor_shape = new_shape,\n",
    "        dtype = onnx_data_type\n",
    "    )\n",
    "    model.set_tensor_datatype(add_in0, finn_data_type)\n",
    "    \n",
    "    n.output[0] = add_in0 # CHECK\n",
    "    prod0.input[0] = add_in0 # CHECK\n",
    "    prod0.output[0] = add_out # CHECK\n",
    "    \n",
    "    graph.node.remove(prod1)\n",
    "    \n",
    "for n in model.graph.node:\n",
    "    node_ind += 1\n",
    "    if n.op_type in join_op_list and model.is_join_node(n):\n",
    "        in0 = n.input[0]\n",
    "        in1 = n.input[1]\n",
    "        if in0 is None or in1 is None:\n",
    "            continue\n",
    "        \n",
    "        prod0 = model.find_producer(in0)\n",
    "        prod1 = model.find_producer(in1)\n",
    "        if prod0 is None or prod1 is None or prod0==prod1: # is this needed?\n",
    "            continue\n",
    "        \n",
    "        identical_op = prod0.op_type == prod1.op_type\n",
    "        \n",
    "        if identical_op and prod0.op_type in identical_op_list:\n",
    "            # Currently, only transpose operation is supported. Adding additional op_types can be done by extending\n",
    "            # the if-branches below. \n",
    "            if prod0.op_type == 'Transpose':\n",
    "                move_node(graph, n, prod0, prod1, node_ind)\n",
    "                \n",
    "model = model.transform(SortGraph())\n",
    "                \n",
    "                \n",
    "model.save(\"/tmp/test_move_identical_op_past_join_op_modified.onnx\")\n",
    "showInNetron(\"/tmp/test_move_identical_op_past_join_op_modified.onnx\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "widespread-restaurant",
   "metadata": {},
   "outputs": [
    {
     "ename": "Fail",
     "evalue": "[ONNXRuntimeError] : 1 : FAIL : Node: Output:out_transpose1 [ShapeInferenceError] Can't merge shape info. Both source and target dimension have values but they differ. Source=128 Target=256 Dimension=1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFail\u001b[0m                                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f5bb2e2a6248>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput1_tensor_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mis_same\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moxe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#for n in model_transformed.graph.input:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn-base/src/finn/core/onnx_exec.py\u001b[0m in \u001b[0;36mcompare_execution\u001b[0;34m(model_a, model_b, input_dict, compare_fxn)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;31m# compare values from first output tensors produced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0mres_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mres_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompare_fxn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn-base/src/finn/core/onnx_exec.py\u001b[0m in \u001b[0;36mexecute_onnx\u001b[0;34m(model, input_dict, return_full_exec_context, start_node, end_node)\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 )\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mexecute_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_full_exec_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mget_sanitize_quant_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;31m# round output values to quantization annotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn-base/src/finn/core/onnx_exec.py\u001b[0m in \u001b[0;36mexecute_node\u001b[0;34m(node, context, graph, return_full_exec_context)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0moutput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/onnxruntime/capi/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path_or_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/onnxruntime/capi/session.py\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m(self, providers)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to load from type '{0}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path_or_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFail\u001b[0m: [ONNXRuntimeError] : 1 : FAIL : Node: Output:out_transpose1 [ShapeInferenceError] Can't merge shape info. Both source and target dimension have values but they differ. Source=128 Target=256 Dimension=1"
     ]
    }
   ],
   "source": [
    "from finn.util.basic import gen_finn_dt_tensor\n",
    "from finn.core.datatype import DataType\n",
    "import finn.core.onnx_exec as oxe\n",
    "\n",
    "model = ModelWrapper(\"/tmp/test_move_identical_op_past_join_op.onnx\")\n",
    "model_transformed = ModelWrapper(\"/tmp/test_move_identical_op_past_join_op_modified.onnx\")\n",
    "\n",
    "# Create input data\n",
    "input0_tensor_name = model.graph.input[0].name\n",
    "input1_tensor_name = model.graph.input[1].name\n",
    "\n",
    "# Note: it is assumed that both tensors have the same shape and data type\n",
    "input_shape = model.get_tensor_shape(input0_tensor_name)\n",
    "input_dtype = model.get_tensor_datatype(input0_tensor_name)\n",
    "input_val = gen_finn_dt_tensor(input_dtype, input_shape)\n",
    "input_dict = {}\n",
    "input_dict[input0_tensor_name] = input_val\n",
    "input_dict[input1_tensor_name] = input_val\n",
    "\n",
    "is_same = oxe.compare_execution(model, model_transformed, input_dict)\n",
    "\n",
    "#for n in model_transformed.graph.input:\n",
    "#    print(n)\n",
    "\n",
    "print(is_same)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-bouquet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-headquarters",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-colonial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-characterization",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "electoral-chemical",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dimensional-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.base import Transformation\n",
    "import onnx\n",
    "from finn.transformation.general import SortGraph\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.util.visualization import showInNetron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "inside-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoveIdenticalOpPastJoinOp(Transformation):\n",
    "    \"\"\"\n",
    "    Move identical operations on different branches past the common join node.\n",
    "    Transformation should be applied when\n",
    "    the identical operations are changing the data layout. For linear operations, see the transformation MoveLinearPastEltwiseAdd\n",
    "    Specifically, this transformation matches and transforms the following patterns:\n",
    "    f(x) + f(y) -> f(x + y)\n",
    "    f(x) - f(y) -> f(x - y)\n",
    "    where f(.) is currently only supporting 'Transpose' \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, identical_op_list, join_node_list):\n",
    "        super().__init__()\n",
    "        self.ops_to_move = identical_op_list\n",
    "        self.join_node_op = join_node_list\n",
    "    \n",
    "    def move_node(self, model, n, prod0, prod1):\n",
    "            # Found! move one of the identical_ops to output, remove the other one\n",
    "            identical_op0_in0 = prod0.input[0]\n",
    "            identical_op1_in0 = prod1.input[0]\n",
    "            add_in0 = n.input[0]\n",
    "            add_out = n.output[0]\n",
    "\n",
    "            # Rewire\n",
    "            n.input[0] = identical_op0_in0 \n",
    "            n.input[1] = identical_op1_in0 \n",
    "\n",
    "            # Create the new output tensor\n",
    "            # Output tensor of the join node must have the same shape\n",
    "            # as its input tensor (shape preserving)\n",
    "            new_shape = model.get_tensor_shape(identical_op0_in0)\n",
    "            # FINN datatype should be set to the tensor datatype of the output tensor of the add node\n",
    "            #finn_data_type = model.get_tensor_datatype(add_out) \n",
    "            # ONNX datatype must be set to the tensor datatype of the output tensor of the add node\n",
    "            #value_info_addout = model.get_tensor_valueinfo(add_out)\n",
    "            #onnx_data_type = value_info_addout.type.tensor_type.elem_type\n",
    "\n",
    "            # Set new tensor shape with appropriate ONNX and FINN datatypes.\n",
    "            model.set_tensor_shape(\n",
    "                tensor_name = add_in0,\n",
    "                tensor_shape = new_shape\n",
    "            )\n",
    "            #model.set_tensor_datatype(add_in0, finn_data_type)\n",
    "\n",
    "            n.output[0] = add_in0\n",
    "            prod0.input[0] = add_in0 \n",
    "            prod0.output[0] = add_out\n",
    "\n",
    "            model.graph.node.remove(prod1)\n",
    "    \n",
    "    def apply(self, model):\n",
    "        graph = model.graph\n",
    "        graph_modified = False\n",
    "        for n in graph.node:\n",
    "            if n.op_type in self.join_node_op and model.is_join_node(n):\n",
    "                in0 = n.input[0]\n",
    "                in1 = n.input[1]\n",
    "                if in0 is None or in1 is None:\n",
    "                    continue\n",
    "\n",
    "                prod0 = model.find_producer(in0)\n",
    "                prod1 = model.find_producer(in1)\n",
    "                # checks if the join node is preceded by two different, but identical operations\n",
    "                if prod0==prod1:\n",
    "                    continue\n",
    "\n",
    "                identical_op = prod0.op_type == prod1.op_type\n",
    "\n",
    "                if identical_op and prod0.op_type in self.ops_to_move:\n",
    "                    self.move_node(model, n, prod0, prod1)\n",
    "                    graph_modified = True\n",
    "\n",
    "        if graph_modified:\n",
    "            model = model.transform(SortGraph(), make_deepcopy=False, cleanup=False)\n",
    "        \n",
    "        return (model, graph_modified)\n",
    "        \n",
    "class MoveTransposePastJoinAdd(MoveIdenticalOpPastJoinOp):\n",
    "    def __init__(self):\n",
    "        super().__init__([\"Transpose\"], [\"Add\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "speaking-corner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_move_identical_op_past_join_op_modified.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8e602d46d8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelWrapper(\"/tmp/test_move_identical_op_past_join_op.onnx\")\n",
    "\n",
    "model = model.transform(MoveTransposePastJoinAdd())\n",
    "\n",
    "model.save(\"/tmp/test_move_identical_op_past_join_op_modified.onnx\")\n",
    "showInNetron(\"/tmp/test_move_identical_op_past_join_op_modified.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-clark",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "expensive-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pytest\n",
    "import numpy as np\n",
    "\n",
    "from onnx import helper as oh\n",
    "from onnx import TensorProto\n",
    "\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "# from finn.transformation.streamline.reorder import MoveTransposePastFork\n",
    "from finn.util.basic import gen_finn_dt_tensor\n",
    "import finn.core.onnx_exec as oxe\n",
    "\n",
    "# perm = [0, 3, 1, 2]\n",
    "def create_model(perm):\n",
    "    if perm == [0, 3, 1, 2]:\n",
    "        in_shape = [1, 128, 1, 256]\n",
    "        out_shape = [1, 256, 128, 1]\n",
    "    if perm == [0, 2, 3, 1]:\n",
    "        in_shape = [1, 256, 128, 1]\n",
    "        out_shape = [1, 128, 1, 256]\n",
    "    \n",
    "    Transpose1_node = onnx.helper.make_node(\n",
    "        \"Transpose\",\n",
    "        inputs = ['in_transpose1'],\n",
    "        outputs = ['out_transpose1'],\n",
    "        perm = perm\n",
    "    )\n",
    "\n",
    "    Transpose2_node = onnx.helper.make_node(\n",
    "        \"Transpose\",\n",
    "        inputs = ['in_transpose2'],\n",
    "        outputs = ['out_transpose2'],\n",
    "        perm = perm\n",
    "    )\n",
    "\n",
    "    Join1_node = onnx.helper.make_node(\n",
    "        \"Add\",\n",
    "        inputs = ['out_transpose1', 'out_transpose2'],\n",
    "        outputs = ['out_join1']\n",
    "    )\n",
    "\n",
    "    in_transpose1 = onnx.helper.make_tensor_value_info('in_transpose1', onnx.TensorProto.FLOAT, in_shape)\n",
    "    in_transpose2 = onnx.helper.make_tensor_value_info('in_transpose2', onnx.TensorProto.FLOAT, in_shape)\n",
    "    out_transpose1 = onnx.helper.make_tensor_value_info('out_transpose1', onnx.TensorProto.FLOAT, out_shape)\n",
    "    out_transpose2 = onnx.helper.make_tensor_value_info('out_transpose2', onnx.TensorProto.FLOAT, out_shape)\n",
    "    out_join1 = onnx.helper.make_tensor_value_info('out_join1', onnx.TensorProto.FLOAT, out_shape)\n",
    "\n",
    "    graph = onnx.helper.make_graph(\n",
    "        nodes = [\n",
    "            Transpose1_node,\n",
    "            Transpose2_node,\n",
    "            Join1_node\n",
    "        ],\n",
    "        name = 'test_graph',\n",
    "        inputs = [in_transpose1, in_transpose2],\n",
    "        outputs = [out_join1],\n",
    "        value_info = [\n",
    "            out_transpose1,\n",
    "            out_transpose2,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    onnx_model = onnx.helper.make_model(graph, producer_name='test_model')\n",
    "    model = ModelWrapper(onnx_model)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Permutation of transpose node\n",
    "# @pytest.mark.parametrize(\"perm\", [[0, 3, 1, 2], [0, 2, 3, 1]])\n",
    "def test_move_identical_op_past_join_op(perm):\n",
    "    model = create_model(perm)\n",
    "    \n",
    "    # Create input data\n",
    "    input0_tensor_name = model.graph.input[0].name\n",
    "    input1_tensor_name = model.graph.input[1].name\n",
    "    \n",
    "    # Note: it is assumed that both tensors have the same shape and data type\n",
    "    input_shape = model.get_tensor_shape(input0_tensor_name)\n",
    "    input_dtype = model.get_tensor_datatype(input0_tensor_name)\n",
    "    input_val = gen_finn_dt_tensor(input_dtype, input_shape)\n",
    "    input_dict = {}\n",
    "    input_dict[input0_tensor_name] = input_val\n",
    "    input_dict[input1_tensor_name] = input_val\n",
    "    \n",
    "    model_transformed = model.transform(MoveTransposePastJoinAdd())\n",
    "    \n",
    "    assert oxe.compare_execution(model, model_transformed, input_dict)\n",
    "    \n",
    "    # Check if order changed\n",
    "    node0_input0_model = model.find_consumers(model.graph.input[0].name)[0].op_type\n",
    "    node1_input1_model = model.find_consumers(model.graph.input[1].name)[0].op_type\n",
    "    node0_input0_model_transformed = model_transformed.find_consumers(model_transformed.graph.input[0].name)[0].op_type\n",
    "    node1_input1_model_transformed = model_transformed.find_consumers(model_transformed.graph.input[1].name)[0].op_type\n",
    "    assert node0_input0_model != node0_input0_model_transformed\n",
    "    assert node1_input1_model != node1_input1_model_transformed\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "discrete-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_move_identical_op_past_join_op([0,3,1,2])\n",
    "test_move_identical_op_past_join_op([0,2,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-handling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
