{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "palestinian-melbourne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_extend_partition.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0e4c5f08d0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from onnx import helper as oh\n",
    "from onnx import TensorProto\n",
    "\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.core.datatype import DataType\n",
    "from finn.util.basic import gen_finn_dt_tensor\n",
    "import finn.core.onnx_exec as oxe\n",
    "\n",
    "\n",
    "MultiThreshold0_node = oh.make_node(\n",
    "    \"MultiThreshold\",\n",
    "    inputs = ['in1_multithreshold0', 'in2_multithreshold0'],\n",
    "    outputs = ['out_multithreshold0'],\n",
    "    name = 'MultiThreshold0',\n",
    "    domain = 'finn.custom_op.general',\n",
    "    out_dtype = 'UINT4',\n",
    ")\n",
    "\n",
    "Conv0_node = oh.make_node(\n",
    "    \"Conv\",\n",
    "    inputs = ['out_multithreshold0', 'in2_conv0'],\n",
    "    outputs = ['out_conv0'],\n",
    "    name = 'Conv0',\n",
    "    dilations = [1, 1],\n",
    "    group = 1,\n",
    "    kernel_shape = [1, 1],\n",
    "    pads = [0, 0, 0, 0],\n",
    "    strides = [1, 1]\n",
    ")\n",
    "\n",
    "Conv1_node = oh.make_node(\n",
    "    \"Conv\",\n",
    "    inputs = ['out_multithreshold0', 'in2_conv1'],\n",
    "    outputs = ['out_conv1'],\n",
    "    name = 'Conv1',\n",
    "    dilations = [1, 1],\n",
    "    group = 1,\n",
    "    kernel_shape = [1, 1],\n",
    "    pads = [0, 0, 0, 0],\n",
    "    strides = [1, 1]\n",
    ")\n",
    "\n",
    "MultiThreshold1_node = oh.make_node(\n",
    "    \"MultiThreshold\",\n",
    "    inputs = ['out_conv0', 'in2_multithreshold1'],\n",
    "    outputs = ['out_multithreshold1'],\n",
    "    name = 'MultiThreshold1',\n",
    "    domain = 'finn.custom_op.general',\n",
    "    out_dtype = 'UINT4'\n",
    ")\n",
    "\n",
    "MultiThreshold2_node = oh.make_node(\n",
    "    \"MultiThreshold\",\n",
    "    inputs = ['out_conv1', 'in2_multithreshold2'],\n",
    "    outputs = ['out_multithreshold2'],\n",
    "    name = 'MultiThreshold2',\n",
    "    domain = 'finn.custom_op.general',\n",
    "    out_dtype = 'UINT4'\n",
    ")\n",
    "\n",
    "Add0_node = oh.make_node(\n",
    "    \"Add\",\n",
    "    inputs = ['out_multithreshold1', 'out_multithreshold2'],\n",
    "    outputs = ['out_add0'],\n",
    "    name = 'Add0'\n",
    ")\n",
    "\n",
    "MultiThreshold3_node = oh.make_node(\n",
    "    \"MultiThreshold\",\n",
    "    inputs = ['out_add0', 'in2_multithreshold3'],\n",
    "    outputs = ['out_multithreshold3'],\n",
    "    name = 'MultiThreshold3',\n",
    "    domain = 'finn.custom_op.general',\n",
    "    out_dtype = 'UINT4'\n",
    ")\n",
    "\n",
    "Conv2_node = oh.make_node(\n",
    "    \"Conv\",\n",
    "    inputs = ['out_multithreshold3', 'in2_conv2'],\n",
    "    outputs = ['out_conv2'],\n",
    "    name = 'Conv2',\n",
    "    dilations = [1, 1],\n",
    "    group = 1,\n",
    "    kernel_shape = [1, 1],\n",
    "    pads = [0, 0, 0, 0],\n",
    "    strides = [1, 1]\n",
    ")\n",
    "\n",
    "Conv3_node = oh.make_node(\n",
    "    \"Conv\",\n",
    "    inputs = ['out_multithreshold3', 'in2_conv3'],\n",
    "    outputs = ['out_conv3'],\n",
    "    name = 'Conv3',\n",
    "    dilations = [1, 1],\n",
    "    group = 1,\n",
    "    kernel_shape = [1, 1],\n",
    "    pads = [0, 0, 0, 0],\n",
    "    strides = [1, 1]\n",
    ")\n",
    "\n",
    "MultiThreshold4_node = oh.make_node(\n",
    "    \"MultiThreshold\",\n",
    "    inputs = ['out_conv2', 'in2_multithreshold4'],\n",
    "    outputs = ['out_multithreshold4'],\n",
    "    name = 'MultiThreshold4',\n",
    "    domain = 'finn.custom_op.general',\n",
    "    out_dtype = 'UINT4'\n",
    ")\n",
    "\n",
    "MultiThreshold5_node = oh.make_node(\n",
    "    \"MultiThreshold\",\n",
    "    inputs = ['out_conv3', 'in2_multithreshold5'],\n",
    "    outputs = ['out_multithreshold5'],\n",
    "    name = 'MultiThreshold5',\n",
    "    domain = 'finn.custom_op.general',\n",
    "    out_dtype = 'UINT4'\n",
    ")\n",
    "\n",
    "Add1_node = oh.make_node(\n",
    "    \"Add\",\n",
    "    inputs = ['out_multithreshold4', 'out_multithreshold5'],\n",
    "    outputs = ['out_add1'],\n",
    "    name = 'Add1'\n",
    ")\n",
    "\n",
    "# Inputs/outputs (global)\n",
    "in1_multithreshold0 = oh.make_tensor_value_info('in1_multithreshold0', TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "out_add1 = oh.make_tensor_value_info('out_add1', TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "\n",
    "# Initializers\n",
    "in2_multithreshold0 = oh.make_tensor_value_info('in2_multithreshold0', TensorProto.FLOAT, [256, 15])\n",
    "in2_conv0 = oh.make_tensor_value_info('in2_conv0', TensorProto.FLOAT, [256, 256, 1, 1])\n",
    "in2_conv1 = oh.make_tensor_value_info('in2_conv1', TensorProto.FLOAT, [256, 256, 1 ,1])\n",
    "in2_multithreshold1 = oh.make_tensor_value_info('in2_multithreshold1', TensorProto.FLOAT, [256, 15])\n",
    "in2_multithreshold2 = oh.make_tensor_value_info('in2_multithreshold2', TensorProto.FLOAT, [256, 15])\n",
    "in2_multithreshold3 = oh.make_tensor_value_info('in2_multithreshold3', TensorProto.FLOAT, [256, 15])\n",
    "in2_conv2 = oh.make_tensor_value_info('in2_conv2', TensorProto.FLOAT, [256, 256, 1, 1])\n",
    "in2_conv3 = oh.make_tensor_value_info('in2_conv3', TensorProto.FLOAT, [256, 256, 1, 1])\n",
    "in2_multithreshold4 = oh.make_tensor_value_info('in2_multithreshold4', TensorProto.FLOAT, [256, 15])\n",
    "in2_multithreshold5 = oh.make_tensor_value_info('in2_multithreshold5', TensorProto.FLOAT, [256, 15])\n",
    "\n",
    "# Value_infos\n",
    "out_multithreshold0 = oh.make_tensor_value_info('out_multithreshold0', TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "out_conv0 = oh.make_tensor_value_info('out_conv0', TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "out_conv1 = oh.make_tensor_value_info('out_conv1', TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "out_multithreshold1 = oh.make_tensor_value_info('out_multithreshold1', TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "out_multithreshold2 = oh.make_tensor_value_info('out_multithreshold2', TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "out_add0 = oh.make_tensor_value_info('out_add0', TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "out_multithreshold3 = oh.make_tensor_value_info('out_multithreshold3', TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "out_conv2 = oh.make_tensor_value_info('out_conv2', TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "out_conv3 = oh.make_tensor_value_info('out_conv3', TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "out_multithreshold4 = oh.make_tensor_value_info('out_multithreshold4', TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "out_multithreshold5 = oh.make_tensor_value_info('out_multithreshold5', TensorProto.FLOAT, [1, 256, 128, 1])\n",
    "\n",
    "graph = oh.make_graph(\n",
    "    nodes = [\n",
    "        MultiThreshold0_node, \n",
    "        Conv0_node,\n",
    "        Conv1_node,\n",
    "        MultiThreshold1_node,\n",
    "        MultiThreshold2_node,\n",
    "        Add0_node,\n",
    "        MultiThreshold3_node,\n",
    "        Conv2_node,\n",
    "        Conv3_node,\n",
    "        MultiThreshold4_node,\n",
    "        MultiThreshold5_node,\n",
    "        Add1_node        \n",
    "    ],\n",
    "    name = \"test_graph\",\n",
    "    inputs = [in1_multithreshold0],\n",
    "    outputs = [out_add1],\n",
    "    value_info = [\n",
    "        in2_multithreshold0,\n",
    "        in2_conv0,\n",
    "        in2_conv1,\n",
    "        in2_multithreshold1,\n",
    "        in2_multithreshold2,\n",
    "        in2_multithreshold3,\n",
    "        in2_conv2,\n",
    "        in2_conv3,\n",
    "        in2_multithreshold4,\n",
    "        in2_multithreshold5,\n",
    "        out_multithreshold0,\n",
    "        out_conv0,\n",
    "        out_conv1,\n",
    "        out_multithreshold1,\n",
    "        out_multithreshold2,\n",
    "        out_add0,\n",
    "        out_multithreshold3,\n",
    "        out_conv2,\n",
    "        out_conv3,\n",
    "        out_multithreshold4,\n",
    "        out_multithreshold5\n",
    "    ]\n",
    ")\n",
    "\n",
    "onnx_model = oh.make_model(graph, producer_name = \"test_model\")\n",
    "model = ModelWrapper(onnx_model)\n",
    "\n",
    "model.set_tensor_datatype('in2_conv0', DataType.INT4)\n",
    "model.set_tensor_datatype('in2_conv1', DataType.INT4)\n",
    "model.set_tensor_datatype('in2_conv2', DataType.INT4)\n",
    "model.set_tensor_datatype('in2_conv3', DataType.INT4)\n",
    "\n",
    "mt_weights = np.random.randint(low=-1000, high=1000, size=[6, 256, 15])\n",
    "mt_weights = np.sort(mt_weights, 2)\n",
    "for i in range(0,6):\n",
    "    model.set_initializer('in2_multithreshold'+str(i), mt_weights[i])\n",
    "\n",
    "conv_weights = np.random.randint(low=-8, high=7, size=[4, 256, 256, 1, 1]).astype(np.float32)    \n",
    "for i in range(0,4):\n",
    "    model.set_initializer('in2_conv'+str(i), conv_weights[i])\n",
    "    \n",
    "model.save(\"/tmp/test_extend_partition.onnx\")\n",
    "from finn.util.visualization import showInNetron\n",
    "showInNetron(\"/tmp/test_extend_partition.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "known-optimum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_extend_partition_partitioned.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0e4f8c4518>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Partition the graph first\n",
    "from finn.transformation.create_generic_partitions import PartitionFromDict\n",
    "\n",
    "model = ModelWrapper(\"/tmp/test_extend_partition.onnx\")\n",
    "\n",
    "partitionings = {0: range(0, 6), 1: range(6, 12)}\n",
    "\n",
    "model = model.transform(PartitionFromDict(partitionings))\n",
    "\n",
    "model.save(\"/tmp/test_extend_partition_partitioned.onnx\")\n",
    "\n",
    "showInNetron(\"/tmp/test_extend_partition_partitioned.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-criterion",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "endless-crown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_extend_partition_undo.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0eac7ecb38>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.basic import get_by_name\n",
    "\n",
    "model = ModelWrapper(\"/tmp/test_extend_partition_partitioned.onnx\")\n",
    "\n",
    "partitions_to_expand = [0,1]\n",
    "\n",
    "# Get information about partitions\n",
    "node_ind = 0\n",
    "\n",
    "partition_node_ind = [ind for ind,n in enumerate(model.graph.node) if n.op_type=='GenericPartition']\n",
    "\n",
    "nodes = [n for n in model.graph.node]\n",
    "\n",
    "for n in nodes:\n",
    "    if n.op_type == 'GenericPartition' and node_ind in partitions_to_expand:\n",
    "        path_to_model = get_by_name(n.attribute, 'model', 'name').s.decode('utf-8')\n",
    "        model_partition = ModelWrapper(path_to_model)\n",
    "\n",
    "        # Append nodes\n",
    "        for partition_node in model_partition.graph.node:\n",
    "            model.graph.node.append(partition_node)\n",
    "\n",
    "        # Append value infos\n",
    "        partition_valueinfos = [x.name for x in model_partition.graph.value_info]\n",
    "        for vi_name in partition_valueinfos:\n",
    "            vi = model_partition.get_tensor_valueinfo(vi_name)\n",
    "            model.graph.value_info.append(vi)\n",
    "\n",
    "        # Append initializers\n",
    "        partition_initializers = [x for x in model_partition.graph.initializer]\n",
    "        for i in partition_initializers:\n",
    "            model.graph.initializer.append(i)\n",
    "\n",
    "        # Append tensor annotation\n",
    "        partition_annotations = [x for x in model_partition.graph.quantization_annotation]\n",
    "        for a in partition_annotations:\n",
    "            model.graph.quantization_annotation.append(a)\n",
    "\n",
    "        model.graph.node.remove(n)\n",
    "                \n",
    "    node_ind += 1\n",
    "\n",
    "from finn.transformation.general import SortGraph\n",
    "model = model.transform(SortGraph())\n",
    "\n",
    "model.save(\"/tmp/test_extend_partition_undo.onnx\")\n",
    "\n",
    "showInNetron(\"/tmp/test_extend_partition_undo.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "pending-worry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_extend_partition_undo.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0e4f81a240>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.basic import get_by_name\n",
    "from finn.transformation.general import SortGraph\n",
    "\n",
    "model = ModelWrapper(\"/tmp/test_extend_partition_partitioned.onnx\")\n",
    "graph = model.graph\n",
    "partitions_to_expand = [0,1]\n",
    "\n",
    "partition_node_ind = {ind: n for ind,n in enumerate(model.graph.node) if n.op_type=='GenericPartition'}\n",
    "\n",
    "for k, v in partition_node_ind.items():\n",
    "    if k in partitions_to_expand:\n",
    "        path_to_model = get_by_name(v.attribute, 'model', 'name').s.decode('utf-8')\n",
    "        model_partition = ModelWrapper(path_to_model)\n",
    "        \n",
    "        # Append nodes\n",
    "        for partition_node in model_partition.graph.node:\n",
    "            graph.node.append(partition_node)\n",
    "            \n",
    "        # Append value infos\n",
    "        partition_valueinfos = [x.name for x in model_partition.graph.value_info]\n",
    "        for vi_name in partition_valueinfos:\n",
    "            vi = model_partition.get_tensor_valueinfo(vi_name)\n",
    "            graph.value_info.append(vi)\n",
    "\n",
    "        # Append initializers\n",
    "        partition_initializers = [x for x in model_partition.graph.initializer]\n",
    "        for i in partition_initializers:\n",
    "            graph.initializer.append(i)\n",
    "\n",
    "        # Append tensor annotation\n",
    "        partition_annotations = [x for x in model_partition.graph.quantization_annotation]\n",
    "        for a in partition_annotations:\n",
    "            graph.quantization_annotation.append(a)\n",
    "\n",
    "        graph.node.remove(v)\n",
    "        graph_modified = True\n",
    "        \n",
    "if graph_modified:\n",
    "    model = model.transform(SortGraph())\n",
    "\n",
    "model.save(\"/tmp/test_extend_partition_undo.onnx\")\n",
    "\n",
    "showInNetron(\"/tmp/test_extend_partition_undo.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-tenant",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "relative-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.core.onnx_exec as oxe\n",
    "\n",
    "# Partitioned model\n",
    "model = ModelWrapper(\"/tmp/test_extend_partition_partitioned.onnx\")\n",
    "\n",
    "# Create input data\n",
    "input0_tensor_name = model.graph.input[0].name\n",
    "\n",
    "input_shape = model.get_tensor_shape(input0_tensor_name)\n",
    "input_dtype = model.get_tensor_datatype(input0_tensor_name)\n",
    "input_val = gen_finn_dt_tensor(input_dtype, input_shape)\n",
    "input_dict = {}\n",
    "input_dict[input0_tensor_name] = input_val\n",
    "\n",
    "# Unpacked model\n",
    "#model_transformed = model.transform(MoveTransposePastMultiThreshold())\n",
    "model_transformed = ModelWrapper(\"/tmp/test_extend_partition_undo.onnx\")\n",
    "\n",
    "assert oxe.compare_execution(model, model_transformed, input_dict)\n",
    "\n",
    "# Check if data_types are retained\n",
    "for n in model_transformed.graph.node:\n",
    "    if n.op_type==\"Conv\":\n",
    "        assert model_transformed.get_tensor_datatype(n.input[1])==DataType.INT4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-communication",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-baltimore",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2020, Xilinx\n",
    "# All rights reserved.\n",
    "#\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "# * Redistributions of source code must retain the above copyright notice, this\n",
    "#   list of conditions and the following disclaimer.\n",
    "#\n",
    "# * Redistributions in binary form must reproduce the above copyright notice,\n",
    "#   this list of conditions and the following disclaimer in the documentation\n",
    "#   and/or other materials provided with the distribution.\n",
    "#\n",
    "# * Neither the name of FINN nor the names of its\n",
    "#   contributors may be used to endorse or promote products derived from\n",
    "#   this software without specific prior written permission.\n",
    "#\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
    "# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
    "# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "from finn.transformation.base import Transformation\n",
    "from finn.util.basic import get_by_name\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.general import SortGraph\n",
    "\n",
    "class UnfoldPartitions(Transformation):\n",
    "    \"\"\"Unfolds GenericPartition type nodes by inserting the graph pointed to by\n",
    "     the model attribute.\n",
    "     Argument 0: unfolding_index\n",
    "     * List that contains the node indices of the GenericPartition nodes\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, unfolding_index):\n",
    "        super().__init__()\n",
    "        self.unfolding_index = unfolding_index\n",
    "\n",
    "    def apply(self, model):\n",
    "        graph = model.graph\n",
    "        graph_modified = False\n",
    "\n",
    "        partition_nodes_dict = {ind: n for ind, n in enumerate(graph.node) if n.op_type == 'GenericPartition'}\n",
    "\n",
    "        for k, v in partition_nodes_dict.items():\n",
    "            if k in self.unfolding_index:\n",
    "                path_to_model = get_by_name(v.attribute, 'model', 'name').s.decode('utf-8')\n",
    "                model_partition = ModelWrapper(path_to_model)\n",
    "\n",
    "                # Append nodes\n",
    "                for partition_node in model_partition.graph.node:\n",
    "                    graph.node.append(partition_node)\n",
    "\n",
    "                # Append value infos\n",
    "                partition_valueinfos = [x.name for x in model_partition.graph.value_info]\n",
    "                for vi_name in partition_valueinfos:\n",
    "                    vi = model_partition.get_tensor_valueinfo(vi_name)\n",
    "                    graph.value_info.append(vi)\n",
    "\n",
    "                # Append initializers\n",
    "                partition_initializers = [x for x in model_partition.graph.initializer]\n",
    "                for i in partition_initializers:\n",
    "                    graph.initializer.append(i)\n",
    "\n",
    "                # Append tensor annotations, except for the input/output tensors\n",
    "                # as these will be retained in the 'upper' model\n",
    "                # after partitioning.\n",
    "                in_out_names = [x.name for x in model_partition.graph.input]\n",
    "                in_out_names += [x.name for x in model_partition.graph.output]\n",
    "                partition_annotations = [x for x in model_partition.graph.quantization_annotation if x.tensor_name not in in_out_names]\n",
    "                for a in partition_annotations:\n",
    "                    graph.quantization_annotation.append(a)\n",
    "\n",
    "                graph.node.remove(v)\n",
    "                graph_modified = True\n",
    "\n",
    "        if graph_modified:\n",
    "            model = model.transform(SortGraph())\n",
    "\n",
    "        return (model, graph_modified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-fetish",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
