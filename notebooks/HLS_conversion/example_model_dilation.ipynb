{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "931\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnx\n",
    "from finn.core.datatype import DataType\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "\n",
    "model = ModelWrapper(\"/tmp/quartznet.onnx\")\n",
    "count=0\n",
    "for n in model.graph.node:\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_model_dilations.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f73e424f160>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnx\n",
    "from finn.core.datatype import DataType\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.util.visualization import showInNetron\n",
    "from finn.transformation.general import GiveRandomTensorNames, GiveReadableTensorNames\n",
    "\n",
    "Conv1_node = onnx.helper.make_node(\n",
    "    \"Conv\",\n",
    "    inputs=['in1_conv1', 'in2_conv1'],\n",
    "    outputs=['out1_conv1'],\n",
    "    name=\"Conv1\",\n",
    "    dilations=[2],\n",
    "    group=512,\n",
    "    kernel_shape=[87],\n",
    "    pads=[86, 86],\n",
    "    strides=[1]\n",
    ")\n",
    "\n",
    "in1_conv1 = onnx.helper.make_tensor_value_info(\"in1_conv1\", onnx.TensorProto.FLOAT, [1, 512, 128])\n",
    "in2_conv1 = onnx.helper.make_tensor_value_info(\"in2_conv1\", onnx.TensorProto.FLOAT, [512, 1, 87])\n",
    "out1_conv1 = onnx.helper.make_tensor_value_info(\"out1_conv1\", onnx.TensorProto.FLOAT, [1, 512, 128])\n",
    "\n",
    "graph = onnx.helper.make_graph(\n",
    "    nodes=[Conv1_node],\n",
    "    name=\"test_graph\",\n",
    "    inputs=[in1_conv1],\n",
    "    outputs=[out1_conv1],\n",
    "    value_info=[in2_conv1]\n",
    ")\n",
    "\n",
    "def set_all_initializers(model, value):\n",
    "    \"\"\" Sets weight values of the conv to 'value'. \"\"\"\n",
    "    for n in model.graph.node:\n",
    "        if len(n.input) > 1:\n",
    "            init_name = n.input[1]\n",
    "            model.set_initializer(init_name, value)\n",
    "\n",
    "onnx_model = onnx.helper.make_model(graph, producer_name=\"test_graph-model\")\n",
    "model = ModelWrapper(onnx_model)\n",
    "\n",
    "# Initialize appropriately\n",
    "model.set_tensor_datatype('in2_conv1', DataType.INT4)        \n",
    "weight_values = np.load('/tmp/weight_values.npy')\n",
    "set_all_initializers(model, weight_values)\n",
    "\n",
    "model = model.transform(GiveRandomTensorNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model.save(\"/tmp/test_model_dilations.onnx\")\n",
    "\n",
    "showInNetron(\"/tmp/test_model_dilations.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_model_dilations_lowered.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f73e424f278>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors\n",
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from finn.transformation.general import GiveUniqueNodeNames, GiveRandomTensorNames, GiveReadableTensorNames\n",
    "\n",
    "model = ModelWrapper(\"/tmp/test_model_dilations.onnx\")\n",
    "model = model.transform(Change3DTo4DTensors())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveRandomTensorNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model.save(\"/tmp/test_model_dilations_lowered.onnx\")\n",
    "\n",
    "showInNetron(\"/tmp/test_model_dilations_lowered.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \"Im2Col_0_out0\"\n",
      "input: \"MatMul_0_param0\"\n",
      "output: \"MatMul_0_out0\"\n",
      "name: \"MatMul_0\"\n",
      "op_type: \"MatMul\"\n",
      "\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(\"/tmp/test_model_dilations_lowered.onnx\")\n",
    "\n",
    "for n in model.graph.node:\n",
    "    if n.op_type=='MatMul':\n",
    "        print(n)\n",
    "        weight_im2col = model.get_initializer(\"MatMul_0_param0\")\n",
    "print(type(weight_im2col))\n",
    "\n",
    "np.save(\"/tmp/weight_values_matmul.npy\", weight_im2col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and obtaining output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.core.onnx_exec as oxe\n",
    "from finn.util.basic import gen_finn_dt_tensor\n",
    "import random\n",
    "\n",
    "def generate_random_input(model, randomize, value=[]):\n",
    "        \"\"\" Creates input dictionary with a random numpy array that matches the input tensor shape \"\"\"\n",
    "        i_shape = []\n",
    "        input_dict={}\n",
    "        \n",
    "        if randomize is True:\n",
    "            for i in range(len(model.graph.input)):\n",
    "                input_node = model.graph.input[i]\n",
    "                input_node_name = input_node.name\n",
    "                input_node_shape = model.get_tensor_shape(input_node_name)\n",
    "                i_val = gen_finn_dt_tensor(DataType.FLOAT32, input_node_shape)\n",
    "                input_dict[input_node_name] = i_val\n",
    "            return input_dict\n",
    "        else:\n",
    "            for i in range(len(model.graph.input)):\n",
    "                input_node = model.graph.input[i]\n",
    "                input_node_name = input_node.name\n",
    "                input_dict[input_node_name] = value\n",
    "            return input_dict\n",
    "\n",
    "        \n",
    "global_in = []\n",
    "global_out = []\n",
    "im2col_in = []\n",
    "im2col_out = []\n",
    "model1 = ModelWrapper(\"/tmp/test_model_dilations.onnx\")\n",
    "model2 = ModelWrapper(\"/tmp/test_model_dilations_lowered.onnx\")\n",
    "\n",
    "original_out = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    in_val1 = np.random.randint(-1000,1000,[1,512,128]).astype(np.float32)    \n",
    "    in_val2 = np.reshape(in_val1, np.shape(in_val1)+(1,))\n",
    "    \n",
    "    input_dict1 = generate_random_input(model1, False, in_val1)\n",
    "    input_dict2 = generate_random_input(model2, False, in_val2)\n",
    "    \n",
    "    output_node_name1 = model1.graph.output[0].name\n",
    "    output_node_name2 = model2.graph.output[0].name\n",
    "    \n",
    "    output_dict1 = oxe.execute_onnx(model1, input_dict1, return_full_exec_context=True)\n",
    "    output_dict2 = oxe.execute_onnx(model2, input_dict2, return_full_exec_context=True)\n",
    "    \n",
    "    expected1 = output_dict1[output_node_name1]\n",
    "    expected2 = output_dict2[output_node_name2]\n",
    "        \n",
    "    global_in.append(in_val2)\n",
    "    global_out.append(expected2)\n",
    "    im2col_in.append(output_dict2[\"Transpose_0_out0\"])\n",
    "    im2col_out.append(output_dict2[\"Im2Col_0_out0\"])\n",
    "    \n",
    "    original_out.append(expected1)\n",
    "    \n",
    "\n",
    "np.save(\"/tmp/global_in.npy\", global_in)\n",
    "np.save(\"/tmp/global_out.npy\", global_out)\n",
    "np.save(\"/tmp/im2col_in.npy\", im2col_in)\n",
    "np.save(\"/tmp/im2col_out.npy\", im2col_out)\n",
    "np.save(\"/tmp/original_out.npy\", original_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "original_output = np.load(\"/tmp/original_out.npy\")\n",
    "lowered_output = np.load(\"/tmp/global_out.npy\")\n",
    "\n",
    "for i in range(np.shape(original_output)[0]):\n",
    "    out1 = original_output[i]\n",
    "    out2 = lowered_output[i]\n",
    "    \n",
    "    out1 = np.reshape(out1, np.shape(out2))\n",
    "    \n",
    "    print(np.array_equal(out1,out2))\n",
    "    \n",
    "np.save(\"/tmp/global_out.npy\",lowered_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(3, 1, 512, 128, 1)\n",
      "(1, 512, 128, 1)\t(1, 512, 128, 1)\n",
      "True\n",
      "(1, 512, 128, 1)\n",
      "862.0000000000\n",
      "862.0000000000\n",
      "global_in\t(1, 512, 128, 1)\n",
      "global_out\t(1, 512, 128, 1)\n",
      "MatMul_0_param0\t(44544, 512)\n",
      "Transpose_0_out0\t(1, 128, 1, 512)\n",
      "Im2Col_0_out0\t(1, 128, 1, 44544)\n",
      "MatMul_0_out0\t(1, 128, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "input_dict1_val = input_dict1['in1_conv1']\n",
    "input_dict2_val = input_dict2['global_in']\n",
    "input_dict2_val = np.reshape(input_dict2_val, np.shape(input_dict1_val))\n",
    "\n",
    "is_eq = np.array_equal(input_dict1_val, input_dict2_val)\n",
    "print(is_eq)\n",
    "\n",
    "expected2 = np.load(\"/tmp/test_output_values.npy\")\n",
    "print(np.shape(expected2))\n",
    "expected2 = expected2[0]\n",
    "expected1 = np.reshape(expected1, np.shape(expected2))\n",
    "\n",
    "print(\"{}\\t{}\".format(np.shape(expected1),np.shape(expected2)))\n",
    "is_eq = np.array_equal(expected1, expected2)\n",
    "print(is_eq)\n",
    "\n",
    "print(np.shape(expected2))\n",
    "\n",
    "print(\"{:.10f}\".format(expected1[0][0][0][0]))\n",
    "print(\"{:.10f}\".format(expected2[0][0][0][0]))\n",
    "\n",
    "for k,v in output_dict2.items():\n",
    "    print(\"{}\\t{}\".format(k,np.shape(v)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
