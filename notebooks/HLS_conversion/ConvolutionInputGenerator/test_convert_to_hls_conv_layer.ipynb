{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "frank-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx import TensorProto, helper\n",
    "import numpy as np\n",
    "\n",
    "from finn.core.datatype import DataType\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "from finn.transformation.general import GiveUniqueNodeNames\n",
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "\n",
    "from finn.transformation.fpgadataflow.prepare_ip import PrepareIP\n",
    "from finn.transformation.fpgadataflow.prepare_rtlsim import PrepareRTLSim\n",
    "from finn.transformation.fpgadataflow.hlssynth_ip import HLSSynthIP\n",
    "import finn.core.onnx_exec as oxe\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.util.basic import gen_finn_dt_tensor\n",
    "import finn.transformation.fpgadataflow.convert_to_hls_layers as to_hls\n",
    "\n",
    "from finn.transformation.fpgadataflow.prepare_cppsim import PrepareCppSim\n",
    "from finn.transformation.fpgadataflow.compile_cppsim import CompileCppSim\n",
    "from finn.transformation.fpgadataflow.set_exec_mode import SetExecMode\n",
    "from finn.custom_op.general.im2col import compute_conv_output_dim\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "from finn.analysis.fpgadataflow.exp_cycles_per_layer import exp_cycles_per_layer\n",
    "\n",
    "\n",
    "def test_convert_to_hls_conv_layer(conv_config, depthwise, exec_mode):\n",
    "    kernel_size, stride, pad, is_square_input = conv_config\n",
    "    np.random.seed(0)\n",
    "    idt = DataType.UINT4\n",
    "\n",
    "    in_chn = 16\n",
    "    k_h, k_w = kernel_size\n",
    "    stride_h, stride_w = stride\n",
    "    pad_h = pad[0] + pad[2]\n",
    "    pad_w = pad[1] + pad[3]\n",
    "\n",
    "    if is_square_input:\n",
    "        in_feature_dim_h, in_feature_dim_w = [7, 7]\n",
    "    else:\n",
    "        in_feature_dim_h, in_feature_dim_w = [9, 7]\n",
    "    \n",
    "    if depthwise is True:\n",
    "        group = out_chn = in_chn\n",
    "        conv_param_shape = [out_chn, 1, k_h, k_w]\n",
    "    else:\n",
    "        group = 1\n",
    "        out_chn = 20\n",
    "        conv_param_shape = [out_chn, in_chn, k_h, k_w]\n",
    "\n",
    "    out_feature_dim_h = compute_conv_output_dim(\n",
    "        in_feature_dim_h, k_h, stride_h, pad_h\n",
    "    )\n",
    "    out_feature_dim_w = compute_conv_output_dim(\n",
    "        in_feature_dim_w, k_w, stride_w, pad_w\n",
    "    )\n",
    "\n",
    "    input_shape = [1, in_chn, in_feature_dim_h, in_feature_dim_w]\n",
    "    output_shape = [1, out_chn, out_feature_dim_h, out_feature_dim_w]\n",
    "\n",
    "    conv_weight_dt = DataType.UINT4\n",
    "\n",
    "    conv_config = {}\n",
    "    conv_config[\"dilations\"] = [1, 1]\n",
    "    conv_config[\"group\"] = group\n",
    "    conv_config[\"kernel_shape\"] = [k_h, k_w]\n",
    "    conv_config[\"pads\"] = pad\n",
    "    conv_config[\"strides\"] = [stride_h, stride_w]\n",
    "\n",
    "    top_in = helper.make_tensor_value_info(\"top_in\", TensorProto.FLOAT, input_shape)\n",
    "    top_out = helper.make_tensor_value_info(\"top_out\", TensorProto.FLOAT, output_shape)\n",
    "    value_info = [\n",
    "        helper.make_tensor_value_info(\"p1\", TensorProto.FLOAT, conv_param_shape)\n",
    "    ]\n",
    "\n",
    "    modelproto = helper.make_model(\n",
    "        helper.make_graph(\n",
    "            name=\"conv_test\",\n",
    "            inputs=[top_in],\n",
    "            outputs=[top_out],\n",
    "            value_info=value_info,\n",
    "            nodes=[\n",
    "                helper.make_node(\"Conv\", [\"top_in\", \"p1\"], [\"top_out\"], **conv_config)\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model = ModelWrapper(modelproto)\n",
    "    model.set_tensor_datatype(\"top_in\", idt)\n",
    "    model.set_tensor_datatype(\"top_out\", idt)\n",
    "    model.set_tensor_datatype(\"p1\", conv_weight_dt)\n",
    "    model.set_initializer(\"p1\", gen_finn_dt_tensor(conv_weight_dt, conv_param_shape))\n",
    "\n",
    "    model = model.transform(InferShapes())\n",
    "    model = model.transform(InferDataTypes())\n",
    "    \n",
    "    model.save(\"/tmp/test_original_model.onnx\")\n",
    "\n",
    "    new_model = model.transform(LowerConvsToMatMul())\n",
    "    new_model = new_model.transform(to_hls.InferConvInpGen())\n",
    "    if depthwise is True:\n",
    "        new_model = new_model.transform(to_hls.InferVVAU())\n",
    "    else:\n",
    "        new_model = new_model.transform(to_hls.InferQuantizedStreamingFCLayer())\n",
    "        fc_node = new_model.get_nodes_by_op_type(\"StreamingFCLayer_Batch\")[0]\n",
    "        fc_inst = getCustomOp(fc_node)\n",
    "        mw = fc_inst.get_nodeattr(\"MW\")\n",
    "        mh = fc_inst.get_nodeattr(\"MH\")\n",
    "        pe_cands = list(filter(lambda x: mh % x == 0, range(2, mh + 1)))\n",
    "        simd_cands = list(filter(lambda x: mw % x == 0, range(2, mw + 1)))\n",
    "        fc_inst.set_nodeattr(\"PE\", pe_cands[0])\n",
    "        fc_inst.set_nodeattr(\"SIMD\", simd_cands[0])\n",
    "\n",
    "    new_model = new_model.transform(GiveUniqueNodeNames())\n",
    "    new_model = new_model.transform(InferShapes())\n",
    "    new_model = new_model.transform(InferDataTypes())\n",
    "\n",
    "    if exec_mode == \"cppsim\":\n",
    "        new_model = new_model.transform(PrepareCppSim())\n",
    "        new_model = new_model.transform(CompileCppSim())\n",
    "        new_model = new_model.transform(SetExecMode(\"cppsim\"))\n",
    "    elif exec_mode == \"rtlsim\":\n",
    "        new_model = new_model.transform(SetExecMode(\"rtlsim\"))\n",
    "        new_model = new_model.transform(GiveUniqueNodeNames())\n",
    "        new_model = new_model.transform(PrepareIP(\"xc7z020clg400-1\", 5))\n",
    "        new_model = new_model.transform(HLSSynthIP())\n",
    "        new_model = new_model.transform(PrepareRTLSim())\n",
    "    else:\n",
    "        raise Exception(\"Unknown exec_mode\")\n",
    "        \n",
    "    x = gen_finn_dt_tensor(idt, input_shape)\n",
    "    inp_dict = {model.graph.input[0].name: x}\n",
    "    \n",
    "    output_model = oxe.execute_onnx(model, inp_dict, return_full_exec_context=False)[model.graph.output[0].name]\n",
    "    output_newmodel = oxe.execute_onnx(new_model, inp_dict, return_full_exec_context=False)[new_model.graph.output[0].name]\n",
    "    return output_model, output_newmodel\n",
    "    #assert oxe.compare_execution(model, new_model, inp_dict)\n",
    "    \n",
    "    new_model.save(\"/tmp/test_transformed_model.onnx\")\n",
    "    \n",
    "    if (k_h==k_w==1) and (stride_h > 1 or stride_w > 1) and (pad == 0):\n",
    "        assert new_model.graph.node[1].op_type == \"DownSampler\"\n",
    "        if exec_mode == \"rtlsim\":\n",
    "            node = new_model.get_nodes_by_op_type(\"DownSampler\")[0]\n",
    "            inst = getCustomOp(node)\n",
    "            cycles_rtlsim = inst.get_nodeattr(\"cycles_rtlsim\")\n",
    "            exp_cycles_dict = new_model.analysis(exp_cycles_per_layer)\n",
    "            exp_cycles = exp_cycles_dict[node.name]\n",
    "            assert np.isclose(exp_cycles, cycles_rtlsim, atol=11)\n",
    "            assert exp_cycles != 0\n",
    "\n",
    "    if pad_h == 1 and pad_w == 1:\n",
    "        padding_node = new_model.get_nodes_by_op_type(\"FMPadding_Batch\")[0]\n",
    "        padding_inst = getCustomOp(padding_node)\n",
    "        assert padding_inst.get_nodeattr(\"SIMD\") == in_chn\n",
    "\n",
    "    if depthwise is True and exec_mode == \"rtlsim\":\n",
    "        node = new_model.get_nodes_by_op_type(\"Vector_Vector_Activate_Batch\")[0]\n",
    "        inst = getCustomOp(node)\n",
    "        cycles_rtlsim = inst.get_nodeattr(\"cycles_rtlsim\")\n",
    "        exp_cycles_dict = new_model.analysis(exp_cycles_per_layer)\n",
    "        exp_cycles = exp_cycles_dict[node.name]\n",
    "        assert np.isclose(exp_cycles, cycles_rtlsim, atol=11)\n",
    "        assert exp_cycles != 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pretty-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_config:\n",
    "#[kernel_size_h, kernel_size_w]\n",
    "#[stride_h, stride_w]\n",
    "#[pad_H_begin, pad_W_begin, pad_H_end, pad_W_end]\n",
    "#is_sqaure_input\n",
    "conv_config = [([1, 1], [2, 2], [0, 0, 0, 0], True),\n",
    "               ([1, 1], [3, 3], [0, 0, 0, 0], True),\n",
    "               ([3, 3], [2, 2], [1, 1, 1, 1], True),\n",
    "               ([3, 3], [1, 1], [0, 0, 0, 0], True),\n",
    "               ([3, 3], [1, 1], [1, 1, 1, 1], True),\n",
    "               ([5, 5], [2, 2], [1, 1, 1, 1], True),\n",
    "               ([3, 2], [2, 2], [1, 1, 1, 1], False),\n",
    "               ([3, 3], [1, 1], [0, 0, 0, 0], False)\n",
    "              ]\n",
    "\n",
    "depthwise = [False, True]\n",
    "exec_mode = [\"cppsim\", \"rtlsim\"]\n",
    "\n",
    "\n",
    "\n",
    "output_model, output_newmodel = test_convert_to_hls_conv_layer(conv_config[-1], depthwise[1], exec_mode[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "flexible-middle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FMPadding_Batch_0': 86, 'ConvolutionInputGenerator_0': 176, 'Vector_Vector_Activate_Batch_0': 150}\n",
      "-----\n",
      "\n",
      "{'FMPadding_Batch_0': {'BRAM_18K': '0', 'FF': '94', 'LUT': '279', 'DSP48E': '0', 'URAM': '0'}, 'ConvolutionInputGenerator_0': {'BRAM_18K': '0', 'FF': '1212', 'LUT': '1754', 'DSP48E': '0', 'URAM': '0'}, 'Vector_Vector_Activate_Batch_0': {'BRAM_18K': '0', 'FF': '982', 'LUT': '1507', 'DSP48E': '0', 'URAM': '0'}}\n",
      "-----\n",
      "\n",
      "{'FMPadding_Batch_0': {'BRAM_18K': 0, 'BRAM_efficiency': 1, 'LUT': 0, 'URAM': 0, 'URAM_efficiency': 1, 'DSP': 0}, 'ConvolutionInputGenerator_0': {'BRAM_18K': 0, 'BRAM_efficiency': 1, 'LUT': 620, 'URAM': 0, 'URAM_efficiency': 1, 'DSP': 0}, 'Vector_Vector_Activate_Batch_0': {'BRAM_18K': 0, 'BRAM_efficiency': 1, 'LUT': 997, 'URAM': 0, 'URAM_efficiency': 1, 'DSP': 0}}\n"
     ]
    }
   ],
   "source": [
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.util.basic import get_by_name\n",
    "from finn.analysis.fpgadataflow.hls_synth_res_estimation import hls_synth_res_estimation\n",
    "from finn.analysis.fpgadataflow.res_estimation import res_estimation\n",
    "\n",
    "model = ModelWrapper(\"/tmp/test_transformed_model.onnx\")\n",
    "\n",
    "cycles_dict = {}\n",
    "for n in model.graph.node:\n",
    "    #print(n)\n",
    "    backend = get_by_name(n.attribute, \"backend\", \"name\")\n",
    "    if backend is not None:\n",
    "        is_fpgadataflow_node = backend.s.decode('utf-8')==\"fpgadataflow\"\n",
    "        if is_fpgadataflow_node:\n",
    "            inst = getCustomOp(n)\n",
    "            cycles_rtlsim = inst.get_nodeattr(\"cycles_rtlsim\")\n",
    "            cycles_dict[n.name] = cycles_rtlsim\n",
    "\n",
    "print(cycles_dict)\n",
    "print(\"-----\\n\")\n",
    "            \n",
    "hls_synth_resources = model.analysis(hls_synth_res_estimation)\n",
    "expected_resources = model.analysis(res_estimation)\n",
    "\n",
    "print(hls_synth_resources)\n",
    "print(\"-----\\n\")\n",
    "print(expected_resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "green-retention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/tmp/test_original_model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd7cc1990f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(\"/tmp/test_original_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "detailed-springfield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_transformed_model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd7bc8dedd8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(\"/tmp/test_transformed_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-differential",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
