{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "unlike-indication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 2)\n",
      "[[[-1. -2.]\n",
      "  [ 5. -6.]]\n",
      "\n",
      " [[ 0.  2.]\n",
      "  [ 1. -7.]]\n",
      "\n",
      " [[ 4.  1.]\n",
      "  [-1. -5.]]]\n",
      "-------------------------------\n",
      "(3, 3, 2, 2)\n",
      "[[[[-1. -2.]\n",
      "   [ 5. -6.]]\n",
      "\n",
      "  [[ 0.  0.]\n",
      "   [ 0.  0.]]\n",
      "\n",
      "  [[ 0.  0.]\n",
      "   [ 0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  0.]\n",
      "   [ 0.  0.]]\n",
      "\n",
      "  [[ 0.  2.]\n",
      "   [ 1. -7.]]\n",
      "\n",
      "  [[ 0.  0.]\n",
      "   [ 0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  0.]\n",
      "   [ 0.  0.]]\n",
      "\n",
      "  [[ 0.  0.]\n",
      "   [ 0.  0.]]\n",
      "\n",
      "  [[ 4.  1.]\n",
      "   [-1. -5.]]]]\n",
      "-------------------------------\n",
      "(3, 12)\n",
      "[[-1.  0.  0. -2.  0.  0.  5.  0.  0. -6.  0.  0.]\n",
      " [ 0.  0.  0.  0.  2.  0.  0.  1.  0.  0. -7.  0.]\n",
      " [ 0.  0.  4.  0.  0.  1.  0.  0. -1.  0.  0. -5.]]\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "def __print_shape(x):\n",
    "    print(\"{}\\n{}\".format(np.shape(x), x))\n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "\n",
    "def __infer_sparse_weight_tensor(W_conv, k, channels):\n",
    "    __print_shape(W_conv)\n",
    "    W_sparse = np.zeros((channels, channels, k, k))\n",
    "    for ch in range(channels):\n",
    "        W_sparse[ch][ch] = W_conv[ch]\n",
    "    W_conv = W_sparse.astype(np.float32)\n",
    "    __print_shape(W_conv)\n",
    "    W_matmul = W_conv.transpose(0, 2, 3, 1)\n",
    "    W_matmul = W_matmul.reshape(channels, channels*k*k)\n",
    "    __print_shape(W_matmul)\n",
    "    W_matmul = W_matmul.T\n",
    "        \n",
    "k = 2\n",
    "channels = 3\n",
    "W_conv = gen_finn_dt_tensor(wdt, (channels, k, k))\n",
    "W_onnx = __infer_sparse_weight_tensor(W_conv, k, channels) # [k*k*channels, channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "static-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from onnx import TensorProto, helper\n",
    "\n",
    "import finn.core.onnx_exec as oxe\n",
    "from finn.core.datatype import DataType\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.util.basic import gen_finn_dt_tensor, calculate_signed_dot_prod_range\n",
    "from finn.transformation.fpgadataflow.set_exec_mode import SetExecMode\n",
    "from finn.transformation.fpgadataflow.prepare_cppsim import PrepareCppSim\n",
    "from finn.transformation.fpgadataflow.compile_cppsim import CompileCppSim\n",
    "from finn.custom_op.general.multithreshold import multithreshold\n",
    "\n",
    "\n",
    "# Notes:\n",
    "# Bipolar datatype not supported/tested\n",
    "# resType \"lut\" only tested (because inferVVAU has this attribute fixed)\n",
    "\n",
    "def __infer_sparse_weight_tensor(W_conv, k_h, k_w, channels):\n",
    "    #__print_shape(W_conv)\n",
    "    W_sparse = np.zeros((channels, channels, k_h, k_w))\n",
    "    for ch in range(channels):\n",
    "        W_sparse[ch][ch] = W_conv[ch][0]\n",
    "    W_conv = W_sparse.astype(np.float32)\n",
    "    #__print_shape(W_conv)\n",
    "    W_matmul = W_conv.transpose(0, 2, 3, 1)\n",
    "    W_matmul = W_matmul.reshape(channels, channels*k_h*k_w)\n",
    "    #__print_shape(W_matmul)\n",
    "    W_matmul = W_matmul.T\n",
    "    \n",
    "    return W_matmul\n",
    "\n",
    "def  __infer_dense_weight_tensor(W, k, channels):\n",
    "    \"\"\" Weight matrix W has a shape of (k*k*channels, channels). This function\n",
    "    reverses the process of creating the weight matrix and returns as result a\n",
    "    dense weight tensor of shape (channels, 1, k, k)\n",
    "    \"\"\"\n",
    "    W = W.T\n",
    "    W = W.reshape(channels, k, k, channels)\n",
    "    W = W.transpose(0,3,1,2)\n",
    "    w_tensor = np.zeros((channels, 1, k, k))\n",
    "    for ch in range(channels):\n",
    "        w_tensor[ch][0] = W[ch][ch]\n",
    "    return w_tensor\n",
    "\n",
    "def __calculate_dot_prod_range(dt_a, dt_b, len):\n",
    "    \"\"\"Returns the (min,max) values a dot product between two unsigned vectors of\n",
    "    types dt_a and dt_b of len elements can take.\"\"\"\n",
    "\n",
    "    min_prod = 2 ** 30\n",
    "    max_prod = -(2 ** 31)\n",
    "    for a_val in [dt_a.min(), dt_a.max()]:\n",
    "        for b_val in [dt_b.min(), dt_b.max()]:\n",
    "            prod = a_val * b_val * len\n",
    "            if prod < min_prod:\n",
    "                min_prod = prod\n",
    "            if prod > max_prod:\n",
    "                max_prod = prod\n",
    "    return (min_prod, max_prod)\n",
    "\n",
    "\n",
    "def make_single_vvau_modelwrapper(W, pe, k_h, k_w, channels, dim_h, dim_w, wdt, idt, odt, T=None, tdt=None):\n",
    "    in_shape = [1, dim_h, dim_w, k_h*k_w*channels] # [N, H, W, K*K*CH]\n",
    "    out_shape = [1, dim_h, dim_w, channels] # [N, H, W, OFM_CH] (OFM_CH=IFM_CH because depthwise convolution)\n",
    "        \n",
    "    inp = helper.make_tensor_value_info(\"inp\", TensorProto.FLOAT, in_shape)\n",
    "    outp = helper.make_tensor_value_info(\"outp\", TensorProto.FLOAT, out_shape)\n",
    "    \n",
    "    if T is not None:\n",
    "        no_act = 0\n",
    "        node_inp_list = [\"inp\", \"weights\", \"thresh\"]\n",
    "        actval = odt.min()\n",
    "    else:\n",
    "        no_act = 1\n",
    "        node_inp_list = [\"inp\", \"weights\"]\n",
    "        actval = 0\n",
    "    \n",
    "    VVAU_node = helper.make_node(\n",
    "        \"Vector_Vector_Activate_Batch\",\n",
    "        node_inp_list,\n",
    "        [\"outp\"],\n",
    "        domain=\"finn.custom_op.fpgadataflow\",\n",
    "        backend=\"fpgadataflow\",\n",
    "        PE=pe,\n",
    "        Dim=[dim_h, dim_w],\n",
    "        Channels=channels,\n",
    "        Kernel=[k_h, k_w],\n",
    "        resType=\"lut\",\n",
    "        ActVal=actval,\n",
    "        inputDataType=idt.name,\n",
    "        weightDataType=wdt.name,\n",
    "        outputDataType=odt.name,\n",
    "        noActivation=no_act   \n",
    "    )\n",
    "    \n",
    "    graph = helper.make_graph(\n",
    "        nodes=[VVAU_node],\n",
    "        name=\"vvau_graph\",\n",
    "        inputs=[inp],\n",
    "        outputs=[outp]\n",
    "    )\n",
    "    \n",
    "    model = helper.make_model(graph, producer_name=\"vvau-model\")\n",
    "    model = ModelWrapper(model)\n",
    "    \n",
    "    model.set_tensor_datatype(\"inp\", idt)\n",
    "    model.set_tensor_datatype(\"outp\", odt)\n",
    "    model.set_tensor_datatype(\"weights\", wdt)\n",
    "    \n",
    "    model.set_initializer(\"weights\", W)\n",
    "    model.set_tensor_shape(\"weights\", (channels, 1, k_h, k_w))\n",
    "    \n",
    "    if T is not None:\n",
    "        model.set_tensor_datatype(\"thresh\", tdt)\n",
    "        model.set_initializer(\"thresh\", T)\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "def prepare_inputs(input_tensor):\n",
    "    return {\"inp\": input_tensor}\n",
    "\n",
    "\n",
    "def test_fpgadataflow_vvau_cppsim(idt, wdt, act, pe, dim, k, channels):\n",
    "    [dim_h, dim_w] = dim\n",
    "    [k_h, k_w] = k\n",
    "    \n",
    "    if (channels%pe!=0):\n",
    "        pytest.skip(\"Requirement Channels divisable by PE is violated.\")\n",
    "    \n",
    "    W = gen_finn_dt_tensor(wdt, (channels, 1, k_h, k_w)) # [channels, 1, k, k]\n",
    "    W_onnx = __infer_sparse_weight_tensor(W, k_h, k_w, channels) # [k*k*channels, channels]\n",
    "    \n",
    "    x = gen_finn_dt_tensor(idt, (1, dim_h, dim_w, k_h*k_w*channels))\n",
    "    x_vvau = x.reshape(1, dim_h, dim_w, k_h * k_w, channels // pe, pe)\n",
    "    x_vvau = x_vvau.transpose(0, 1, 2, 4, 3, 5)\n",
    "    x_vvau = x_vvau.reshape(1, dim_h, dim_w, channels * k_h * k_w)\n",
    "            \n",
    "    if act is None:\n",
    "        T = None\n",
    "        tdt = None\n",
    "        odt = DataType.INT32\n",
    "    else:\n",
    "        odt = act\n",
    "        (min_v, max_v) = __calculate_dot_prod_range(idt, wdt, k_h*k_w*channels)\n",
    "        n_steps = act.get_num_possible_values()-1\n",
    "        T = np.random.randint(min_v, max_v-1, (channels, n_steps)).astype(np.float32)\n",
    "        T = np.sort(T, axis=1)\n",
    "        tdt = DataType.INT32\n",
    "        \n",
    "    model = make_single_vvau_modelwrapper(W, pe, k_h, k_w, channels, dim_h, dim_w, wdt, idt, odt, T, tdt)\n",
    "    \n",
    "    model.save(\"/tmp/test_vvau.onnx\")\n",
    "\n",
    "    model = model.transform(SetExecMode(\"cppsim\"))\n",
    "    model = model.transform(PrepareCppSim())\n",
    "    model = model.transform(CompileCppSim())\n",
    "    model.save(\"/tmp/test_vvau_compiled.onnx\")\n",
    "    \n",
    "    input_dict = prepare_inputs(x_vvau)\n",
    "    \n",
    "    # Calculate output\n",
    "    y = np.matmul(x, W_onnx) # y is in [N, H, W, C] format\n",
    "    if T is not None:\n",
    "        # Reshape Y, as multithreshold expects y to be in [N, C, H, W] format\n",
    "        y = np.transpose(y, (0, 3, 1, 2))\n",
    "        y = multithreshold(y, T)\n",
    "        y = np.transpose(y, (0, 2, 3, 1))\n",
    "        y += act.min() \n",
    "    y_expected=y\n",
    "    \n",
    "    y_produced = oxe.execute_onnx(model, input_dict, return_full_exec_context=False)[\"outp\"]\n",
    "    \n",
    "    assert ((y_produced==y_expected).all()), \"Cppsim failed!\"\n",
    "    \n",
    "    return x, x_vvau, W_onnx, W, y_expected, y_produced\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "treated-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "idt = DataType.UINT4 # DataType.UINT4, DataType.UINT8 (in graph)\n",
    "wdt = DataType.INT4\n",
    "#act = DataType.INT4\n",
    "act = [DataType.UINT4, None]\n",
    "dim = [14,4]\n",
    "k = [4,2]\n",
    "channels = 3\n",
    "pe = 3\n",
    "\n",
    "#dim = 5\n",
    "#k = 3\n",
    "#channels = 16\n",
    "#pe = 16\n",
    "#idt = DataType.UINT4\n",
    "#act = None\n",
    "#wdt = DataType.UINT4\n",
    "\n",
    "# Seems to work when channels=1\n",
    "\n",
    "x, x_vvau, W_onnx, W, y_expected, y_produced = test_fpgadataflow_vvau_cppsim(idt, wdt, act[0], pe, dim, k, channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "western-conclusion",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]]\n",
      "\n",
      "  [[ 5. 11.  7.]\n",
      "   [ 5. 10.  7.]\n",
      "   [ 5. 10.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]]\n",
      "\n",
      "  [[ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 10.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]]\n",
      "\n",
      "  [[ 5. 10.  8.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 10.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 10.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]]\n",
      "\n",
      "  [[ 5. 11.  7.]\n",
      "   [ 5. 10.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]]\n",
      "\n",
      "  [[ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 10.  7.]]\n",
      "\n",
      "  [[ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]]\n",
      "\n",
      "  [[ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 10.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 10.  7.]]\n",
      "\n",
      "  [[ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]]\n",
      "\n",
      "  [[ 5. 10.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]]]]\n"
     ]
    }
   ],
   "source": [
    "#print(x)\n",
    "#print(W_onnx)\n",
    "print(y_expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "durable-drunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]]\n",
      "\n",
      "  [[ 5. 11.  7.]\n",
      "   [ 5. 10.  7.]\n",
      "   [ 5. 10.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]]\n",
      "\n",
      "  [[ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 10.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]]\n",
      "\n",
      "  [[ 5. 10.  8.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 10.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 10.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]]\n",
      "\n",
      "  [[ 5. 11.  7.]\n",
      "   [ 5. 10.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]]\n",
      "\n",
      "  [[ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 10.  7.]]\n",
      "\n",
      "  [[ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]]\n",
      "\n",
      "  [[ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 10.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 10.  7.]]\n",
      "\n",
      "  [[ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]]\n",
      "\n",
      "  [[ 5. 10.  7.]\n",
      "   [ 5. 11.  8.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]\n",
      "   [ 5. 11.  7.]]]]\n"
     ]
    }
   ],
   "source": [
    "#print(x)\n",
    "#print(W)\n",
    "print(y_produced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "manufactured-lying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/tmp/test_vvau.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f7465a52cc0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(\"/tmp/test_vvau.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "threaded-mailman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_vvau_compiled.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f74c43cd0f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(\"/tmp/test_vvau_compiled.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-blame",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
