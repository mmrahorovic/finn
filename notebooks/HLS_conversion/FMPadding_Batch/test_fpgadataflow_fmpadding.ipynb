{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "preliminary-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from onnx import TensorProto, helper\n",
    "from finn.core.datatype import DataType\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.util.basic import gen_finn_dt_tensor\n",
    "import finn.core.onnx_exec as oxe\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.fpgadataflow.set_exec_mode import SetExecMode\n",
    "from finn.transformation.general import GiveUniqueNodeNames\n",
    "from finn.transformation.fpgadataflow.prepare_cppsim import PrepareCppSim\n",
    "from finn.transformation.fpgadataflow.compile_cppsim import CompileCppSim\n",
    "from finn.transformation.fpgadataflow.prepare_ip import PrepareIP\n",
    "from finn.transformation.fpgadataflow.hlssynth_ip import HLSSynthIP\n",
    "from finn.transformation.fpgadataflow.prepare_rtlsim import PrepareRTLSim\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "from finn.analysis.fpgadataflow.exp_cycles_per_layer import exp_cycles_per_layer\n",
    "\n",
    "from finn.util.basic import pynq_part_map\n",
    "\n",
    "test_pynq_board = os.getenv(\"PYNQ_BOARD\", default=\"Pynq-Z1\")\n",
    "test_fpga_part = pynq_part_map[test_pynq_board]\n",
    "target_clk_ns = 10\n",
    "\n",
    "\n",
    "def make_single_fmpadding_modelwrapper(idim, padding, num_ch, simd, idt, pad_style):\n",
    "    pad_h = padding[0]+padding[2]\n",
    "    pad_w = padding[1]+padding[3]\n",
    "    idim_h = idim[0]\n",
    "    idim_w = idim[1]\n",
    "    \n",
    "    assert pad_style == 2, \"only pad_style == 2 supported in hlslib\"\n",
    "    assert(pad_h > 0 or pad_w > 0), \"Output dim should be greater than input dim\"\n",
    "    odim_h = idim_h + pad_h\n",
    "    odim_w = idim_w + pad_w\n",
    "\n",
    "    inp = helper.make_tensor_value_info(\n",
    "        \"inp\", TensorProto.FLOAT, [1, idim_h, idim_w, num_ch]\n",
    "    )\n",
    "    outp = helper.make_tensor_value_info(\n",
    "        \"outp\", TensorProto.FLOAT, [1, odim_h, odim_w, num_ch]\n",
    "    )\n",
    "\n",
    "    FMPadding = helper.make_node(\n",
    "        \"FMPadding_Batch\",\n",
    "        [\"inp\"],\n",
    "        [\"outp\"],\n",
    "        domain=\"finn.custom_op.fpgadataflow\",\n",
    "        backend=\"fpgadataflow\",\n",
    "        ImgDim=idim,\n",
    "        Padding=padding,\n",
    "        NumChannels=num_ch,\n",
    "        inputDataType=str(idt.name),\n",
    "        PaddingStyle=pad_style,\n",
    "        numInputVectors=1,\n",
    "        SIMD=simd,\n",
    "    )\n",
    "\n",
    "    graph = helper.make_graph(\n",
    "        nodes=[FMPadding], name=\"fmpadding_graph\", inputs=[inp], outputs=[outp]\n",
    "    )\n",
    "\n",
    "    model = helper.make_model(graph, producer_name=\"fmpadding-model\")\n",
    "    model = ModelWrapper(model)\n",
    "\n",
    "    model.set_tensor_datatype(\"inp\", idt)\n",
    "    model.set_tensor_datatype(\"outp\", idt)\n",
    "\n",
    "    model.save(\"/tmp/test_fmpadding.onnx\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_fpgadataflow_fmpadding(idim, pad, num_ch, simd, pad_style, idt, mode):\n",
    "    if num_ch % simd != 0:\n",
    "        pytest.skip(\" num_ch % simd != 0, skipping\")\n",
    "        \n",
    "    idim_h = idim[0]\n",
    "    idim_w = idim[1]\n",
    "    pad_h = pad[0]+pad[2]\n",
    "    pad_w = pad[1]+pad[3]\n",
    "    # generate input data\n",
    "    x = gen_finn_dt_tensor(idt, [1, idim_h, idim_w, num_ch])\n",
    "    input_dict = {\"inp\": x}\n",
    "    odim_h = idim_h + pad_h\n",
    "    odim_w = idim_w + pad_w\n",
    "\n",
    "    model = make_single_fmpadding_modelwrapper(idim, pad, num_ch, simd, idt, pad_style)\n",
    "    model = model.transform(InferShapes())\n",
    "    model = model.transform(SetExecMode(mode))\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    if mode == \"cppsim\":\n",
    "        model = model.transform(PrepareCppSim())\n",
    "        model = model.transform(CompileCppSim())\n",
    "        model.save(\"/tmp/test_fmpadding_compiled.onnx\")\n",
    "    elif mode == \"rtlsim\":\n",
    "        model = model.transform(PrepareIP(test_fpga_part, target_clk_ns))\n",
    "        model = model.transform(HLSSynthIP())\n",
    "        model = model.transform(PrepareRTLSim())\n",
    "    y_produced = oxe.execute_onnx(model, input_dict)[\"outp\"]\n",
    "    expected_oshape = (1, odim_h, odim_w, num_ch)\n",
    "    assert y_produced.shape == expected_oshape\n",
    "\n",
    "    # calculate reference\n",
    "    # calculate correct pad according to parameters\n",
    "    if pad_style == 2:\n",
    "        if pad_h % 2 == 0:\n",
    "            pad_up = pad_h // 2\n",
    "        else:\n",
    "            pad_up = pad_h // 2 + 1\n",
    "        if pad_w % 2 == 0:\n",
    "            pad_left = pad_w // 2\n",
    "        else:\n",
    "            pad_left = pad_w // 2 + 1\n",
    "    else:\n",
    "        pad_up = pad_h // 2\n",
    "        pad_left = pad_w // 2\n",
    "\n",
    "    pad_down = pad_h - pad_up\n",
    "    pad_right = pad_w - pad_left\n",
    "\n",
    "    y_expected = np.pad(\n",
    "        x, ((0, 0), (pad_up, pad_down), (pad_left, pad_right), (0, 0)), \"constant\"\n",
    "    )\n",
    "\n",
    "    assert (y_produced == y_expected).all()\n",
    "\n",
    "    if mode == \"rtlsim\":\n",
    "        node = model.get_nodes_by_op_type(\"FMPadding_Batch\")[0]\n",
    "        inst = getCustomOp(node)\n",
    "        cycles_rtlsim = inst.get_nodeattr(\"cycles_rtlsim\")\n",
    "        exp_cycles_dict = model.analysis(exp_cycles_per_layer)\n",
    "        exp_cycles = exp_cycles_dict[node.name]\n",
    "        print(\"Exp: {}\\nRTL_sim: {}\".format(exp_cycles, cycles_rtlsim))\n",
    "        assert np.isclose(exp_cycles, cycles_rtlsim, atol=10)\n",
    "        assert exp_cycles != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "annoying-speech",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%Warning-STMTDLY: /tmp/finn_dev_mirza/code_gen_ipgen_FMPadding_Batch_0_wfgty2q_/project_FMPadding_Batch_0/sol1/impl/verilog//FMPadding_Batch_0_FMPadding_Batch.v:62: Unsupported: Ignoring delay on this delayed statement.\n",
      "%Warning-STMTDLY: Use \"/* verilator lint_off STMTDLY */\" and lint_on around source to disable this message.\n",
      "%Warning-STMTDLY: /tmp/finn_dev_mirza/code_gen_ipgen_FMPadding_Batch_0_wfgty2q_/project_FMPadding_Batch_0/sol1/impl/verilog//FMPadding_Batch_0_FMPadding_Batch.v:63: Unsupported: Ignoring delay on this delayed statement.\n",
      "%Warning-STMTDLY: /tmp/finn_dev_mirza/code_gen_ipgen_FMPadding_Batch_0_wfgty2q_/project_FMPadding_Batch_0/sol1/impl/verilog//FMPadding_Batch_0_FMPadding_Batch_0.v:65: Unsupported: Ignoring delay on this delayed statement.\n",
      "%Warning-STMTDLY: /tmp/finn_dev_mirza/code_gen_ipgen_FMPadding_Batch_0_wfgty2q_/project_FMPadding_Batch_0/sol1/impl/verilog//FMPadding_Batch_0_FMPadding_Batch_0.v:66: Unsupported: Ignoring delay on this delayed statement.\n",
      "%Warning-STMTDLY: /tmp/finn_dev_mirza/code_gen_ipgen_FMPadding_Batch_0_wfgty2q_/project_FMPadding_Batch_0/sol1/impl/verilog//FMPadding_Batch_0_FMPadding.v:135: Unsupported: Ignoring delay on this delayed statement.\n",
      "%Warning-STMTDLY: /tmp/finn_dev_mirza/code_gen_ipgen_FMPadding_Batch_0_wfgty2q_/project_FMPadding_Batch_0/sol1/impl/verilog//FMPadding_Batch_0_FMPadding.v:136: Unsupported: Ignoring delay on this delayed statement.\n",
      "%Warning-STMTDLY: /tmp/finn_dev_mirza/code_gen_ipgen_FMPadding_Batch_0_wfgty2q_/project_FMPadding_Batch_0/sol1/impl/verilog//FMPadding_Batch_0_FMPadding.v:137: Unsupported: Ignoring delay on this delayed statement.\n",
      "%Warning-WIDTH: /tmp/finn_dev_mirza/code_gen_ipgen_FMPadding_Batch_0_wfgty2q_/project_FMPadding_Batch_0/sol1/impl/verilog//FMPadding_Batch_0_FMPadding.v:369: Operator ASSIGN expects 3 bits on the Assign RHS, but Assign RHS's CONST '?32?bxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx' generates 32 bits.\n",
      "%Warning-WIDTH: /tmp/finn_dev_mirza/code_gen_ipgen_FMPadding_Batch_0_wfgty2q_/project_FMPadding_Batch_0/sol1/impl/verilog//FMPadding_Batch_0_FMPadding.v:424: Operator ASSIGNW expects 2 bits on the Assign RHS, but Assign RHS's CONST '?32?bxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx' generates 32 bits.\n",
      "%Warning-WIDTH: /tmp/finn_dev_mirza/code_gen_ipgen_FMPadding_Batch_0_wfgty2q_/project_FMPadding_Batch_0/sol1/impl/verilog//FMPadding_Batch_0_FMPadding.v:498: Operator ASSIGNW expects 8 bits on the Assign RHS, but Assign RHS's VARREF 'ap_phi_mux_tmp_V_phi_fu_142_p6' generates 2 bits.\n",
      "%Warning-WIDTH: /tmp/finn_dev_mirza/code_gen_ipgen_FMPadding_Batch_0_wfgty2q_/project_FMPadding_Batch_0/sol1/impl/verilog//FMPadding_Batch_0_FMPadding_Batch.v:150: Operator ASSIGN expects 2 bits on the Assign RHS, but Assign RHS's CONST '?32?bxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx' generates 32 bits.\n",
      "%Warning-WIDTH: /tmp/finn_dev_mirza/code_gen_ipgen_FMPadding_Batch_0_wfgty2q_/project_FMPadding_Batch_0/sol1/impl/verilog//FMPadding_Batch_0_FMPadding_Batch_0.v:171: Operator ASSIGN expects 4 bits on the Assign RHS, but Assign RHS's CONST '?32?bxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx' generates 32 bits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Entering directory '/tmp/finn_dev_mirza/pyverilator_FMPadding_Batch_0_nexofxdf'\n",
      "g++  -I.  -MMD -I/usr/share/verilator/include -I/usr/share/verilator/include/vltstd -DVL_PRINTF=printf -DVM_TRACE=1 -DVM_COVERAGE=0 -Wno-char-subscripts -Wno-parentheses-equality -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable     -fPIC --std=c++11   -c -o pyverilator_wrapper.o /tmp/finn_dev_mirza/pyverilator_FMPadding_Batch_0_nexofxdf/pyverilator_wrapper.cpp\n",
      "g++  -I.  -MMD -I/usr/share/verilator/include -I/usr/share/verilator/include/vltstd -DVL_PRINTF=printf -DVM_TRACE=1 -DVM_COVERAGE=0 -Wno-char-subscripts -Wno-parentheses-equality -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable     -fPIC --std=c++11   -c -o verilated.o /usr/share/verilator/include/verilated.cpp\n",
      "g++  -I.  -MMD -I/usr/share/verilator/include -I/usr/share/verilator/include/vltstd -DVL_PRINTF=printf -DVM_TRACE=1 -DVM_COVERAGE=0 -Wno-char-subscripts -Wno-parentheses-equality -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable     -fPIC --std=c++11   -c -o verilated_vcd_c.o /usr/share/verilator/include/verilated_vcd_c.cpp\n",
      "/usr/bin/perl /usr/share/verilator/bin/verilator_includer -DVL_INCLUDE_OPT=include VFMPadding_Batch_0_FMPadding_Batch_0.cpp > VFMPadding_Batch_0_FMPadding_Batch_0__ALLcls.cpp\n",
      "g++  -I.  -MMD -I/usr/share/verilator/include -I/usr/share/verilator/include/vltstd -DVL_PRINTF=printf -DVM_TRACE=1 -DVM_COVERAGE=0 -Wno-char-subscripts -Wno-parentheses-equality -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable     -fPIC --std=c++11   -c -o VFMPadding_Batch_0_FMPadding_Batch_0__ALLcls.o VFMPadding_Batch_0_FMPadding_Batch_0__ALLcls.cpp\n",
      "/usr/bin/perl /usr/share/verilator/bin/verilator_includer -DVL_INCLUDE_OPT=include VFMPadding_Batch_0_FMPadding_Batch_0__Trace.cpp VFMPadding_Batch_0_FMPadding_Batch_0__Syms.cpp VFMPadding_Batch_0_FMPadding_Batch_0__Trace__Slow.cpp > VFMPadding_Batch_0_FMPadding_Batch_0__ALLsup.cpp\n",
      "g++  -I.  -MMD -I/usr/share/verilator/include -I/usr/share/verilator/include/vltstd -DVL_PRINTF=printf -DVM_TRACE=1 -DVM_COVERAGE=0 -Wno-char-subscripts -Wno-parentheses-equality -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable     -fPIC --std=c++11   -c -o VFMPadding_Batch_0_FMPadding_Batch_0__ALLsup.o VFMPadding_Batch_0_FMPadding_Batch_0__ALLsup.cpp\n",
      "      Archiving VFMPadding_Batch_0_FMPadding_Batch_0__ALL.a ...\n",
      "ar r VFMPadding_Batch_0_FMPadding_Batch_0__ALL.a VFMPadding_Batch_0_FMPadding_Batch_0__ALLcls.o VFMPadding_Batch_0_FMPadding_Batch_0__ALLsup.o\n",
      "ranlib VFMPadding_Batch_0_FMPadding_Batch_0__ALL.a\n",
      "g++ -fPIC -shared pyverilator_wrapper.o verilated.o verilated_vcd_c.o VFMPadding_Batch_0_FMPadding_Batch_0__ALL.a    -o VFMPadding_Batch_0_FMPadding_Batch_0 -lm -lstdc++  2>&1 | c++filt\n",
      "make: Leaving directory '/tmp/finn_dev_mirza/pyverilator_FMPadding_Batch_0_nexofxdf'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ar: creating VFMPadding_Batch_0_FMPadding_Batch_0__ALL.a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp:200\n",
      "RTL_sim205\n"
     ]
    }
   ],
   "source": [
    "# input image dimension\n",
    "idim = [[8, 8]]\n",
    "# number of rows and number of cols to add\n",
    "pad = [[1, 1, 1, 1], [1, 1, 2, 2]] #(Total pad)\n",
    "# number of channels\n",
    "num_ch = [2, 4]\n",
    "# Input parallelism\n",
    "simd = [1, 2]\n",
    "# PaddingStyle: selects behavior when (odim-idim)%2 != 0\n",
    "pad_style = [2]\n",
    "# FINN input datatype\n",
    "idt = [DataType.INT2, DataType.INT4]\n",
    "# execution mode\n",
    "mode = [\"cppsim\", \"rtlsim\"]\n",
    "\n",
    "test_fpgadataflow_fmpadding(idim[0], pad[0], num_ch[0], simd[0], pad_style[0], idt[0], mode[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rational-brazilian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/tmp/test_fmpadding.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f38ef48f358>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(\"/tmp/test_fmpadding.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "necessary-tulsa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_fmpadding_compiled.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f38ef48f2e8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(\"/tmp/test_fmpadding_compiled.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-actress",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
