{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "integral-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2020, Xilinx\n",
    "# All rights reserved.\n",
    "#\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "# * Redistributions of source code must retain the above copyright notice, this\n",
    "#   list of conditions and the following disclaimer.\n",
    "#\n",
    "# * Redistributions in binary form must reproduce the above copyright notice,\n",
    "#   this list of conditions and the following disclaimer in the documentation\n",
    "#   and/or other materials provided with the distribution.\n",
    "#\n",
    "# * Neither the name of FINN nor the names of its\n",
    "#   contributors may be used to endorse or promote products derived from\n",
    "#   this software without specific prior written permission.\n",
    "#\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
    "# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
    "# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "from onnx import TensorProto, helper\n",
    "import numpy as np\n",
    "import pytest\n",
    "\n",
    "from finn.core.datatype import DataType\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "from finn.transformation.general import GiveUniqueNodeNames\n",
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "\n",
    "from finn.transformation.fpgadataflow.prepare_ip import PrepareIP\n",
    "from finn.transformation.fpgadataflow.prepare_rtlsim import PrepareRTLSim\n",
    "from finn.transformation.fpgadataflow.hlssynth_ip import HLSSynthIP\n",
    "import finn.core.onnx_exec as oxe\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.util.basic import gen_finn_dt_tensor\n",
    "import finn.transformation.fpgadataflow.convert_to_hls_layers as to_hls\n",
    "\n",
    "from finn.transformation.fpgadataflow.prepare_cppsim import PrepareCppSim\n",
    "from finn.transformation.fpgadataflow.compile_cppsim import CompileCppSim\n",
    "from finn.transformation.fpgadataflow.set_exec_mode import SetExecMode\n",
    "from finn.custom_op.general.im2col import compute_conv_output_dim\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "from finn.analysis.fpgadataflow.exp_cycles_per_layer import exp_cycles_per_layer\n",
    "\n",
    "# conv_config: \n",
    "# [pad_h_begin, pad_w_begin, pad_h_end, pad_w_end]\n",
    "# [kernel_size_h, kernel_size_w]\n",
    "# [stride_h, stride_w]\n",
    "# [dilation_h, dilation_w]\n",
    "#@pytest.mark.parametrize(\n",
    "#    \"conv_config\", [#([1, 1], [2, 2], [0, 0, 0, 0], True),\n",
    "#                   #([1, 1], [3, 3], [0, 0, 0, 0], True),\n",
    "#                   #([3, 3], [2, 2], [1, 1, 1, 1], True),\n",
    "#                   #([3, 3], [1, 1], [0, 0, 0, 0], True),\n",
    "#                   #([3, 3], [1, 1], [1, 1, 1, 1], True),\n",
    "#                   #([5, 5], [2, 2], [1, 1, 1, 1], True),\n",
    "#                   #([1, 1], [2, 2], [0, 0, 0, 0], False), DownSampler does not support non-square inputs\n",
    "#                   #([1, 1], [3, 3], [0, 0, 0, 0], False), DownSample does not support non-square inputs\n",
    "#                   ([3, 2], [2, 2], [1, 1, 1, 1], False),\n",
    "#                   #([3, 2], [1, 1], [0, 0, 0, 0], False),\n",
    "#                   #([3, 2], [1, 1], [1, 1, 1, 1], False),\n",
    "#                   #([5, 3], [2, 2], [1, 1, 1, 1], False)\n",
    "#              ]\n",
    "#)\n",
    "#@pytest.mark.parametrize(\"depthwise\", [False, True])\n",
    "#@pytest.mark.parametrize(\"exec_mode\", [\"cppsim\", \"rtlsim\"])\n",
    "#@pytest.mark.slow\n",
    "#@pytest.mark.vivado\n",
    "def test_convert_to_hls_conv_layer(conv_config, depthwise, exec_mode):\n",
    "    #ifm_dim, kernel_size, stride, pad = conv_config\n",
    "    pad, kernel_size, stride, dilation = conv_config\n",
    "    np.random.seed(0)\n",
    "    idt = DataType.UINT4\n",
    "\n",
    "    in_feature_dim_h, in_feature_dim_w = [10, 1]\n",
    "    in_chn = 16\n",
    "    \n",
    "    k_h, k_w = kernel_size\n",
    "    stride_h, stride_w = stride\n",
    "    dilation_h, dilation_w = dilation\n",
    "    pad_h = pad[0] + pad[2]\n",
    "    pad_w = pad[1] + pad[3]\n",
    "\n",
    "    if depthwise is True:\n",
    "        group = out_chn = in_chn\n",
    "        conv_param_shape = [out_chn, 1, k_h, k_w]\n",
    "    else:\n",
    "        group = 1\n",
    "        out_chn = 20\n",
    "        conv_param_shape = [out_chn, in_chn, k_h, k_w]\n",
    "\n",
    "    out_feature_dim_h = compute_conv_output_dim(\n",
    "        in_feature_dim_h, k_h, stride_h, pad_h, dilation_h\n",
    "    )\n",
    "    out_feature_dim_w = compute_conv_output_dim(\n",
    "        in_feature_dim_w, k_w, stride_w, pad_w, dilation_w\n",
    "    )\n",
    "\n",
    "    input_shape = [1, in_chn, in_feature_dim_h, in_feature_dim_w]\n",
    "    output_shape = [1, out_chn, out_feature_dim_h, out_feature_dim_w]\n",
    "\n",
    "    conv_weight_dt = DataType.UINT4\n",
    "\n",
    "    conv_config = {}\n",
    "    conv_config[\"dilations\"] = [dilation_h, dilation_w]\n",
    "    conv_config[\"group\"] = group\n",
    "    conv_config[\"kernel_shape\"] = [k_h, k_w]\n",
    "    conv_config[\"pads\"] = pad\n",
    "    conv_config[\"strides\"] = [stride_h, stride_w]\n",
    "\n",
    "    top_in = helper.make_tensor_value_info(\"top_in\", TensorProto.FLOAT, input_shape)\n",
    "    top_out = helper.make_tensor_value_info(\"top_out\", TensorProto.FLOAT, output_shape)\n",
    "    value_info = [\n",
    "        helper.make_tensor_value_info(\"p1\", TensorProto.FLOAT, conv_param_shape)\n",
    "    ]\n",
    "\n",
    "    modelproto = helper.make_model(\n",
    "        helper.make_graph(\n",
    "            name=\"conv_test\",\n",
    "            inputs=[top_in],\n",
    "            outputs=[top_out],\n",
    "            value_info=value_info,\n",
    "            nodes=[\n",
    "                helper.make_node(\"Conv\", [\"top_in\", \"p1\"], [\"top_out\"], **conv_config)\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model = ModelWrapper(modelproto)\n",
    "    model.set_tensor_datatype(\"top_in\", idt)\n",
    "    model.set_tensor_datatype(\"top_out\", idt)\n",
    "    model.set_tensor_datatype(\"p1\", conv_weight_dt)\n",
    "    model.set_initializer(\"p1\", gen_finn_dt_tensor(conv_weight_dt, conv_param_shape))\n",
    "\n",
    "    model = model.transform(InferShapes())\n",
    "    model = model.transform(InferDataTypes())\n",
    "    \n",
    "    model.save(\"/tmp/test_convert_to_hls_1d.onnx\")\n",
    "\n",
    "    new_model = model.transform(LowerConvsToMatMul())\n",
    "    new_model = new_model.transform(to_hls.InferConvInpGen())\n",
    "    if depthwise is True:\n",
    "        new_model = new_model.transform(to_hls.InferVVAU())\n",
    "    else:\n",
    "        new_model = new_model.transform(to_hls.InferQuantizedStreamingFCLayer())\n",
    "        fc_node = new_model.get_nodes_by_op_type(\"StreamingFCLayer_Batch\")[0]\n",
    "        fc_inst = getCustomOp(fc_node)\n",
    "        mw = fc_inst.get_nodeattr(\"MW\")\n",
    "        mh = fc_inst.get_nodeattr(\"MH\")\n",
    "        pe_cands = list(filter(lambda x: mh % x == 0, range(2, mh + 1)))\n",
    "        simd_cands = list(filter(lambda x: mw % x == 0, range(2, mw + 1)))\n",
    "        fc_inst.set_nodeattr(\"PE\", pe_cands[0])\n",
    "        fc_inst.set_nodeattr(\"SIMD\", simd_cands[0])\n",
    "\n",
    "    new_model = new_model.transform(GiveUniqueNodeNames())\n",
    "    new_model = new_model.transform(InferShapes())\n",
    "    new_model = new_model.transform(InferDataTypes())\n",
    "\n",
    "    if exec_mode == \"cppsim\":\n",
    "        new_model = new_model.transform(PrepareCppSim())\n",
    "        new_model = new_model.transform(CompileCppSim())\n",
    "        new_model = new_model.transform(SetExecMode(\"cppsim\"))\n",
    "    elif exec_mode == \"rtlsim\":\n",
    "        new_model = new_model.transform(SetExecMode(\"rtlsim\"))\n",
    "        new_model = new_model.transform(GiveUniqueNodeNames())\n",
    "        new_model = new_model.transform(PrepareIP(\"xc7z020clg400-1\", 5))\n",
    "        new_model = new_model.transform(HLSSynthIP())\n",
    "        new_model = new_model.transform(PrepareRTLSim())\n",
    "    else:\n",
    "        raise Exception(\"Unknown exec_mode\")\n",
    "    \n",
    "    new_model.save(\"/tmp/test_convert_to_hls_1d_compiled.onnx\")\n",
    "\n",
    "    x = gen_finn_dt_tensor(idt, input_shape)\n",
    "    inp_dict = {model.graph.input[0].name: x}\n",
    "    assert oxe.compare_execution(model, new_model, inp_dict)\n",
    "    if (k_h==k_w==1) and (stride_h > 1 or stride_w > 1) and (pad == 0):\n",
    "        assert new_model.graph.node[1].op_type == \"DownSampler\"\n",
    "        if exec_mode == \"rtlsim\":\n",
    "            node = new_model.get_nodes_by_op_type(\"DownSampler\")[0]\n",
    "            inst = getCustomOp(node)\n",
    "            cycles_rtlsim = inst.get_nodeattr(\"cycles_rtlsim\")\n",
    "            exp_cycles_dict = new_model.analysis(exp_cycles_per_layer)\n",
    "            exp_cycles = exp_cycles_dict[node.name]\n",
    "            assert np.isclose(exp_cycles, cycles_rtlsim, atol=11)\n",
    "            assert exp_cycles != 0\n",
    "\n",
    "    if pad_h == 1 and pad_w == 1:\n",
    "        padding_node = new_model.get_nodes_by_op_type(\"FMPadding_Batch\")[0]\n",
    "        padding_inst = getCustomOp(padding_node)\n",
    "        assert padding_inst.get_nodeattr(\"SIMD\") == in_chn\n",
    "\n",
    "    if depthwise is True and exec_mode == \"rtlsim\":\n",
    "        node = new_model.get_nodes_by_op_type(\"Vector_Vector_Activate_Batch\")[0]\n",
    "        inst = getCustomOp(node)\n",
    "        cycles_rtlsim = inst.get_nodeattr(\"cycles_rtlsim\")\n",
    "        exp_cycles_dict = new_model.analysis(exp_cycles_per_layer)\n",
    "        exp_cycles = exp_cycles_dict[node.name]\n",
    "        assert np.isclose(exp_cycles, cycles_rtlsim, atol=11)\n",
    "        assert exp_cycles != 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "significant-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_config: \n",
    "# [pad_h_begin, pad_w_begin, pad_h_end, pad_w_end]\n",
    "# [kernel_size_h, kernel_size_w]\n",
    "# [stride_h, stride_w]\n",
    "# [dilation_h, dilation_w]\n",
    "\n",
    "conv_config1 = [[0, 0, 0, 0], [4, 1], [1, 1], [1, 1]]\n",
    "conv_config2 = [[1, 0, 1, 0], [4, 1], [1, 1], [1, 1]]\n",
    "conv_config3 = [[1, 0, 1, 0], [4, 1], [2, 1], [1, 1]]\n",
    "conv_config4 = [[1, 0, 1, 0], [4, 1], [1, 1], [2, 1]]\n",
    "\n",
    "depthwise = [False, True]\n",
    "\n",
    "exec_mode = ['cppsim', 'rtlsim']\n",
    "\n",
    "test_convert_to_hls_conv_layer(conv_config4, depthwise[0], exec_mode[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "analyzed-still",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_convert_to_hls_1d.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4ee7b1e860>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(\"/tmp/test_convert_to_hls_1d.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "invisible-uncertainty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_convert_to_hls_1d_compiled.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4ee7ad7198>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(\"/tmp/test_convert_to_hls_1d_compiled.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-diameter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
