{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abroad-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from onnx import TensorProto, helper\n",
    "\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "import finn.core.onnx_exec as oxe\n",
    "import finn.custom_op.general.xnorpopcount as xp\n",
    "from finn.analysis.fpgadataflow.hls_synth_res_estimation import hls_synth_res_estimation\n",
    "from finn.core.datatype import DataType\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.custom_op.general.multithreshold import multithreshold\n",
    "from finn.transformation.fpgadataflow.prepare_ip import PrepareIP\n",
    "from finn.transformation.fpgadataflow.prepare_cppsim import PrepareCppSim\n",
    "from finn.transformation.fpgadataflow.compile_cppsim import CompileCppSim\n",
    "from finn.transformation.fpgadataflow.hlssynth_ip import HLSSynthIP\n",
    "from finn.transformation.fpgadataflow.set_exec_mode import SetExecMode\n",
    "from finn.transformation.general import GiveUniqueNodeNames\n",
    "from finn.transformation.fpgadataflow.prepare_rtlsim import PrepareRTLSim\n",
    "from finn.util.basic import calculate_signed_dot_prod_range, gen_finn_dt_tensor\n",
    "from finn.analysis.fpgadataflow.exp_cycles_per_layer import exp_cycles_per_layer\n",
    "\n",
    "\n",
    "def make_single_fclayer_modelwrapper(W, pe, simd, wdt, idt, odt, T=None, tdt=None):\n",
    "    mw = W.shape[0]\n",
    "    mh = W.shape[1]\n",
    "    assert mh % pe == 0\n",
    "    assert mw % simd == 0\n",
    "\n",
    "    # there are two ways to implement bipolar weights and inputs for\n",
    "    # StreamingFC:\n",
    "    # - specify their datatypes as such\n",
    "    # - specify their datatypes as BINARY as use binaryXnorMode\n",
    "    if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "        # we'll internally convert weights/inputs to binary and specify the\n",
    "        # datatypes as such, and also set the binaryXnorMode attribute to 1\n",
    "        export_wdt = DataType.BINARY\n",
    "        export_idt = DataType.BINARY\n",
    "        binary_xnor_mode = 1\n",
    "    else:\n",
    "        export_wdt = wdt\n",
    "        export_idt = idt\n",
    "        binary_xnor_mode = 0\n",
    "\n",
    "    inp = helper.make_tensor_value_info(\"inp\", TensorProto.FLOAT, [1, mw])\n",
    "    outp = helper.make_tensor_value_info(\"outp\", TensorProto.FLOAT, [1, mh])\n",
    "    if T is not None:\n",
    "        no_act = 0\n",
    "        node_inp_list = [\"inp\", \"weights\", \"thresh\"]\n",
    "        if odt == DataType.BIPOLAR:\n",
    "            actval = 0\n",
    "        else:\n",
    "            actval = odt.min()\n",
    "    else:\n",
    "        # no thresholds\n",
    "        node_inp_list = [\"inp\", \"weights\"]\n",
    "        actval = 0\n",
    "        no_act = 1\n",
    "    FCLayer_node = helper.make_node(\n",
    "        \"StreamingFCLayer_Batch\",\n",
    "        node_inp_list,\n",
    "        [\"outp\"],\n",
    "        domain=\"finn.custom_op.fpgadataflow\",\n",
    "        backend=\"fpgadataflow\",\n",
    "        MW=mw,\n",
    "        MH=mh,\n",
    "        SIMD=simd,\n",
    "        PE=pe,\n",
    "        inputDataType=export_idt.name,\n",
    "        weightDataType=export_wdt.name,\n",
    "        outputDataType=odt.name,\n",
    "        ActVal=actval,\n",
    "        binaryXnorMode=binary_xnor_mode,\n",
    "        noActivation=no_act,\n",
    "    )\n",
    "    graph = helper.make_graph(\n",
    "        nodes=[FCLayer_node], name=\"fclayer_graph\", inputs=[inp], outputs=[outp]\n",
    "    )\n",
    "\n",
    "    model = helper.make_model(graph, producer_name=\"fclayer-model\")\n",
    "    model = ModelWrapper(model)\n",
    "\n",
    "    model.set_tensor_datatype(\"inp\", idt)\n",
    "    model.set_tensor_datatype(\"outp\", odt)\n",
    "    model.set_tensor_datatype(\"weights\", wdt)\n",
    "    if binary_xnor_mode:\n",
    "        # convert bipolar to binary\n",
    "        model.set_initializer(\"weights\", (W + 1) / 2)\n",
    "    else:\n",
    "        model.set_initializer(\"weights\", W)\n",
    "    if T is not None:\n",
    "        model.set_tensor_datatype(\"thresh\", tdt)\n",
    "        model.set_initializer(\"thresh\", T)\n",
    "        \n",
    "    model.save(\"/tmp/test_fclayer.onnx\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def prepare_inputs(input_tensor, idt, wdt):\n",
    "    if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "        # convert bipolar to binary\n",
    "        return {\"inp\": (input_tensor + 1) / 2}\n",
    "    else:\n",
    "        return {\"inp\": input_tensor}\n",
    "\n",
    "\n",
    "def test_fpgadataflow_fclayer_cppsim(mem_mode, idt, wdt, act, nf, sf, mw, mh):\n",
    "    if nf == -1:\n",
    "        nf = mh\n",
    "    if sf == -1:\n",
    "        sf = mw\n",
    "    pe = mh // nf\n",
    "    simd = mw // sf\n",
    "    assert mh % pe == 0\n",
    "    assert mw % sf == 0\n",
    "    # generate weights\n",
    "    W = gen_finn_dt_tensor(wdt, (mw, mh))\n",
    "    # generate input data\n",
    "    x = gen_finn_dt_tensor(idt, (1, mw))\n",
    "    if act is None:\n",
    "        # no activation, produce accumulators\n",
    "        T = None\n",
    "        tdt = None\n",
    "        if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "            odt = DataType.UINT32\n",
    "        else:\n",
    "            odt = DataType.INT32\n",
    "    else:\n",
    "        odt = act\n",
    "        (min, max) = calculate_signed_dot_prod_range(idt, wdt, mw)\n",
    "        n_steps = act.get_num_possible_values() - 1\n",
    "        T = np.random.randint(min, max - 1, (mh, n_steps)).astype(np.float32)\n",
    "        # provide non-decreasing thresholds\n",
    "        T = np.sort(T, axis=1)\n",
    "        # generate thresholds for activation\n",
    "        if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "            tdt = DataType.UINT32\n",
    "            # bias thresholds to be positive\n",
    "            T = np.ceil((T + mw) / 2)\n",
    "            assert (T >= 0).all()\n",
    "        else:\n",
    "            tdt = DataType.INT32\n",
    "    model = make_single_fclayer_modelwrapper(W, pe, simd, wdt, idt, odt, T, tdt)\n",
    "    for node in model.graph.node:\n",
    "        # lookup op_type in registry of CustomOps\n",
    "        inst = getCustomOp(node)\n",
    "        inst.set_nodeattr(\"mem_mode\", mem_mode)\n",
    "    model = model.transform(SetExecMode(\"cppsim\"))\n",
    "    model = model.transform(PrepareCppSim())\n",
    "    model = model.transform(CompileCppSim())\n",
    "    model.save(\"/tmp/test_fclayer_compiled.onnx\")\n",
    "    # prepare input data\n",
    "    input_dict = prepare_inputs(x, idt, wdt)\n",
    "    if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "        # convert inputs to binary and use xnorpopcountmatmul\n",
    "        y = xp.xnorpopcountmatmul((x + 1) / 2, (W + 1) / 2)\n",
    "    else:\n",
    "        y = np.matmul(x, W)\n",
    "    if T is not None:\n",
    "        y = multithreshold(y, T)\n",
    "        if act == DataType.BIPOLAR:\n",
    "            # binary to bipolar\n",
    "            y = 2 * y - 1\n",
    "        else:\n",
    "            # signed offset\n",
    "            y += act.min()\n",
    "    oshape = model.get_tensor_shape(\"outp\")\n",
    "    y_expected = y.reshape(oshape)\n",
    "    # execute model\n",
    "    y_produced = oxe.execute_onnx(model, input_dict)[\"outp\"]\n",
    "\n",
    "    y_produced = y_produced.reshape(y_expected.shape)\n",
    "\n",
    "    assert (y_produced == y_expected).all(), \"cppsim failed\"\n",
    "\n",
    "\n",
    "def test_fpgadataflow_fclayer_rtlsim(mem_mode, idt, wdt, act, nf, sf, mw, mh):\n",
    "    if nf == -1:\n",
    "        nf = mh\n",
    "    if sf == -1:\n",
    "        sf = mw\n",
    "    pe = mh // nf\n",
    "    simd = mw // sf\n",
    "    assert mh % pe == 0\n",
    "    assert mw % sf == 0\n",
    "    # generate weights\n",
    "    W = gen_finn_dt_tensor(wdt, (mw, mh))\n",
    "    # generate input data\n",
    "    x = gen_finn_dt_tensor(idt, (1, mw))\n",
    "    if act is None:\n",
    "        # no activation, produce accumulators\n",
    "        T = None\n",
    "        tdt = None\n",
    "        if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "            odt = DataType.UINT32\n",
    "        else:\n",
    "            odt = DataType.INT32\n",
    "    else:\n",
    "        odt = act\n",
    "        (min, max) = calculate_signed_dot_prod_range(idt, wdt, mw)\n",
    "        n_steps = act.get_num_possible_values() - 1\n",
    "        T = np.random.randint(min, max - 1, (mh, n_steps)).astype(np.float32)\n",
    "        # provide non-decreasing thresholds\n",
    "        T = np.sort(T, axis=1)\n",
    "        # generate thresholds for activation\n",
    "        if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "            tdt = DataType.UINT32\n",
    "            # bias thresholds to be positive\n",
    "            T = np.ceil((T + mw) / 2)\n",
    "            assert (T >= 0).all()\n",
    "        else:\n",
    "            tdt = DataType.INT32\n",
    "    model = make_single_fclayer_modelwrapper(W, pe, simd, wdt, idt, odt, T, tdt)\n",
    "    for node in model.graph.node:\n",
    "        # lookup op_type in registry of CustomOps\n",
    "        inst = getCustomOp(node)\n",
    "        inst.set_nodeattr(\"mem_mode\", mem_mode)\n",
    "\n",
    "    # prepare input data\n",
    "    input_dict = prepare_inputs(x, idt, wdt)\n",
    "    if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "        # convert inputs to binary and use xnorpopcountmatmul\n",
    "        y = xp.xnorpopcountmatmul((x + 1) / 2, (W + 1) / 2)\n",
    "    else:\n",
    "        y = np.matmul(x, W)\n",
    "    if T is not None:\n",
    "        y = multithreshold(y, T)\n",
    "        if act == DataType.BIPOLAR:\n",
    "            # binary to bipolar\n",
    "            y = 2 * y - 1\n",
    "        else:\n",
    "            # signed offset\n",
    "            y += act.min()\n",
    "    oshape = model.get_tensor_shape(\"outp\")\n",
    "    y_expected = y.reshape(oshape)\n",
    "    # TODO split up into several dependent tests -- need to check how this\n",
    "    # works for parametrized tests...\n",
    "    model = model.transform(SetExecMode(\"rtlsim\"))\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    model = model.transform(PrepareIP(\"xc7z020clg400-1\", 5))\n",
    "    model = model.transform(HLSSynthIP())\n",
    "    model = model.transform(PrepareRTLSim())\n",
    "    y_produced = oxe.execute_onnx(model, input_dict)[\"outp\"]\n",
    "    assert (y_produced.reshape(y_expected.shape) == y_expected).all(), \"rtlsim failed\"\n",
    "\n",
    "    hls_synt_res_est = model.analysis(hls_synth_res_estimation)\n",
    "    assert \"StreamingFCLayer_Batch_0\" in hls_synt_res_est\n",
    "\n",
    "    node = model.get_nodes_by_op_type(\"StreamingFCLayer_Batch\")[0]\n",
    "    inst = getCustomOp(node)\n",
    "    cycles_rtlsim = inst.get_nodeattr(\"cycles_rtlsim\")\n",
    "    exp_cycles_dict = model.analysis(exp_cycles_per_layer)\n",
    "    exp_cycles = exp_cycles_dict[node.name]\n",
    "    assert np.isclose(exp_cycles, cycles_rtlsim, atol=15)\n",
    "    assert exp_cycles != 0\n",
    "\n",
    "\n",
    "def test_fpgadataflow_fclayer_large_depth_decoupled_mode_rtlsim(\n",
    "    mem_mode, idt, wdt, act, nf, sf, mw, mh\n",
    "):\n",
    "    if nf == -1:\n",
    "        nf = mh\n",
    "    if sf == -1:\n",
    "        sf = mw\n",
    "    pe = mh // nf\n",
    "    simd = mw // sf\n",
    "    assert mh % pe == 0\n",
    "    assert mw % sf == 0\n",
    "    # generate weights\n",
    "    W = gen_finn_dt_tensor(wdt, (mw, mh))\n",
    "    # generate input data\n",
    "    x = gen_finn_dt_tensor(idt, (1, mw))\n",
    "    if act is None:\n",
    "        # no activation, produce accumulators\n",
    "        T = None\n",
    "        tdt = None\n",
    "        if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "            odt = DataType.UINT32\n",
    "        else:\n",
    "            odt = DataType.INT32\n",
    "    else:\n",
    "        odt = act\n",
    "        (min, max) = calculate_signed_dot_prod_range(idt, wdt, mw)\n",
    "        n_steps = act.get_num_possible_values() - 1\n",
    "        T = np.random.randint(min, max - 1, (mh, n_steps)).astype(np.float32)\n",
    "        # provide non-decreasing thresholds\n",
    "        T = np.sort(T, axis=1)\n",
    "        # generate thresholds for activation\n",
    "        if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "            tdt = DataType.UINT32\n",
    "            # bias thresholds to be positive\n",
    "            T = np.ceil((T + mw) / 2)\n",
    "            assert (T >= 0).all()\n",
    "        else:\n",
    "            tdt = DataType.INT32\n",
    "    model = make_single_fclayer_modelwrapper(W, pe, simd, wdt, idt, odt, T, tdt)\n",
    "    for node in model.graph.node:\n",
    "        # lookup op_type in registry of CustomOps\n",
    "        inst = getCustomOp(node)\n",
    "        inst.set_nodeattr(\"mem_mode\", mem_mode)\n",
    "\n",
    "    # prepare input data\n",
    "    input_dict = prepare_inputs(x, idt, wdt)\n",
    "    if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "        # convert inputs to binary and use xnorpopcountmatmul\n",
    "        y = xp.xnorpopcountmatmul((x + 1) / 2, (W + 1) / 2)\n",
    "    else:\n",
    "        y = np.matmul(x, W)\n",
    "    if T is not None:\n",
    "        y = multithreshold(y, T)\n",
    "        if act == DataType.BIPOLAR:\n",
    "            # binary to bipolar\n",
    "            y = 2 * y - 1\n",
    "        else:\n",
    "            # signed offset\n",
    "            y += act.min()\n",
    "    oshape = model.get_tensor_shape(\"outp\")\n",
    "    y_expected = y.reshape(oshape)\n",
    "    # TODO split up into several dependent tests -- need to check how this\n",
    "    # works for parametrized tests...\n",
    "    model = model.transform(SetExecMode(\"rtlsim\"))\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    model = model.transform(PrepareIP(\"xc7z020clg400-1\", 5))\n",
    "    model = model.transform(HLSSynthIP())\n",
    "    model = model.transform(PrepareRTLSim())\n",
    "    y_produced = oxe.execute_onnx(model, input_dict)[\"outp\"]\n",
    "    assert (y_produced.reshape(y_expected.shape) == y_expected).all(), \"rtlsim failed\"\n",
    "\n",
    "    hls_synt_res_est = model.analysis(hls_synth_res_estimation)\n",
    "    assert \"StreamingFCLayer_Batch_0\" in hls_synt_res_est\n",
    "\n",
    "    node = model.get_nodes_by_op_type(\"StreamingFCLayer_Batch\")[0]\n",
    "    inst = getCustomOp(node)\n",
    "    cycles_rtlsim = inst.get_nodeattr(\"cycles_rtlsim\")\n",
    "    exp_cycles_dict = model.analysis(exp_cycles_per_layer)\n",
    "    exp_cycles = exp_cycles_dict[node.name]\n",
    "    assert np.isclose(exp_cycles, cycles_rtlsim, atol=15)\n",
    "    assert exp_cycles != 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "objective-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mem_mode: const or decoupled\n",
    "mem_mode = [\"const\", \"decoupled\", \"external\"]\n",
    "# activation: None or DataType\n",
    "act = [None, DataType.BIPOLAR, DataType.INT4]\n",
    "# weight datatype\n",
    "wdt = [DataType.BIPOLAR, DataType.INT4]\n",
    "# input datatype\n",
    "idt = [DataType.BIPOLAR, DataType.INT4]\n",
    "# neuron folding, -1 is maximum possible\n",
    "nf = [-1, 2, 1]\n",
    "# synapse folding, -1 is maximum possible\n",
    "sf = [-1, 2, 1]\n",
    "# HLS matrix width (input features)\n",
    "mw = [16]\n",
    "# HLS matrix height (output features)\n",
    "mh = [16]\n",
    "test_fpgadataflow_fclayer_cppsim(mem_mode[1], idt[1], wdt[1], act[1], nf[1], sf[1], mw[0], mh[0])\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "### RTL SIM\n",
    "###\n",
    "\n",
    "# mem_mode: const or decoupled\n",
    "mem_mode = [\"const\", \"decoupled\", \"external\"]\n",
    "# activation: None or DataType\n",
    "act = [None, DataType.BIPOLAR, DataType.INT4]\n",
    "# weight datatype\n",
    "wdt = [DataType.BIPOLAR, DataType.INT4]\n",
    "# input datatype\n",
    "idt = [DataType.BIPOLAR, DataType.INT4]\n",
    "# neuron folding, -1 is maximum possible\n",
    "nf = [-1, 2, 1]\n",
    "# synapse folding, -1 is maximum possible\n",
    "sf = [-1, 2, 1]\n",
    "# HLS matrix width (input features)\n",
    "mw = [16]\n",
    "# HLS matrix height (output features)\n",
    "mh = [16]\n",
    "#test_fpgadataflow_fclayer_rtlsim(mem_mode, idt, wdt, act, nf, sf, mw, mh)\n",
    "\n",
    "\n",
    "# mem_mode: const or decoupled\n",
    "mem_mode = [\"decoupled\"]\n",
    "# activation: None or DataType\n",
    "act = [DataType.INT4]\n",
    "# weight datatype\n",
    "wdt = [DataType.INT4]\n",
    "# input datatype\n",
    "idt = [DataType.INT4]\n",
    "# neuron folding, -1 is maximum possible\n",
    "nf = [-1]\n",
    "# synapse folding, -1 is maximum possible\n",
    "sf = [-1]\n",
    "# HLS matrix width (input features)\n",
    "mw = [128]\n",
    "# HLS matrix height (output features)\n",
    "mh = [128]\n",
    "#test_fpgadataflow_fclayer_large_depth_decoupled_mode_rtlsim(mem_mode, idt, wdt, act, nf, sf, mw, mh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "surprising-nelson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_fclayer.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f55a1ff5fd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(\"/tmp/test_fclayer.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dedicated-increase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/test_fclayer_compiled.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f55c0190cf8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(\"/tmp/test_fclayer_compiled.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-variance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
