{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6868826d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import pytest\n",
    "import numpy as np\n",
    "\n",
    "import finn.core.onnx_exec as oxe\n",
    "from finn.transformation.fold_constants import FoldConstants\n",
    "from finn.transformation.general import RemoveStaticGraphInputs\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "#import brevitas_examples.speech_to_text as stt\n",
    "\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "from finn.util.test import (\n",
    "    load_test_checkpoint_or_skip\n",
    ")\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.core.datatype import DataType\n",
    "from finn.util.basic import get_by_name\n",
    "\n",
    "from finn.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors\n",
    "from finn.transformation.general import (\n",
    "    GiveUniqueNodeNames,\n",
    "    GiveRandomTensorNames,\n",
    "    GiveReadableTensorNames,\n",
    "    GiveUniqueParameterTensors\n",
    ")\n",
    "from finn.transformation.batchnorm_to_affine import BatchNormToAffine\n",
    "from finn.transformation.streamline.reorder import (\n",
    "    MoveAddPastMul,\n",
    "    MoveAddPastConv,\n",
    "    MoveMulPastFork,\n",
    "    MoveScalarMulPastConv,\n",
    "    MoveMulPastDWConv,\n",
    "    MoveLinearPastEltwiseAdd\n",
    ")\n",
    "from finn.transformation.streamline.collapse_repeated import(\n",
    "    CollapseRepeatedAdd,\n",
    "    CollapseRepeatedMul\n",
    ")\n",
    "from finn.transformation.streamline.absorb import(\n",
    "    AbsorbAddIntoMultiThreshold,\n",
    "    AbsorbMulIntoMultiThreshold,\n",
    "    FactorOutMulSignMagnitude,\n",
    "    Absorb1BitMulIntoConv,\n",
    "    AbsorbSignBiasIntoMultiThreshold\n",
    ")\n",
    "from finn.transformation.streamline.round_thresholds import RoundAndClipThresholds\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "from finn.transformation.create_generic_partitions import PartitionFromDict\n",
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from finn.transformation.streamline.absorb import AbsorbTransposeIntoMultiThreshold\n",
    "from finn.transformation.streamline.reorder import (\n",
    "    MoveTransposePastMultiThreshold,\n",
    "    MoveTransposePastJoinAdd,\n",
    "    MoveTransposeBeforeFork\n",
    ")\n",
    "from finn.transformation.extend_partition import ExtendPartition\n",
    "import finn.transformation.fpgadataflow.convert_to_hls_layers as to_hls\n",
    "from finn.transformation.fpgadataflow.synth_ooc import SynthOutOfContext\n",
    "from finn.transformation.fpgadataflow.insert_dwc import InsertDWC\n",
    "from finn.transformation.fpgadataflow.insert_fifo import InsertFIFO\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import CreateDataflowPartition\n",
    "from finn.transformation.fpgadataflow.prepare_cppsim import PrepareCppSim\n",
    "from finn.transformation.fpgadataflow.compile_cppsim import CompileCppSim\n",
    "from finn.transformation.fpgadataflow.set_exec_mode import SetExecMode\n",
    "from finn.transformation.fpgadataflow.prepare_ip import PrepareIP\n",
    "from finn.transformation.fpgadataflow.hlssynth_ip import HLSSynthIP\n",
    "from finn.transformation.fpgadataflow.replace_verilog_relpaths import (\n",
    "    ReplaceVerilogRelPaths,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.annotate_resources import AnnotateResources\n",
    "from finn.transformation.fpgadataflow.set_folding import SetFolding\n",
    "from finn.util.basic import alveo_part_map, alveo_default_platform\n",
    "from finn.util.config import extract_model_config_to_json\n",
    "from finn.transformation.fpgadataflow.set_fifo_depths import (\n",
    "    InsertAndSetFIFODepths,\n",
    "    RemoveShallowFIFOs\n",
    ")\n",
    "from finn.transformation.fpgadataflow.create_stitched_ip import CreateStitchedIP\n",
    "from finn.transformation.fpgadataflow.annotate_cycles import AnnotateCycles\n",
    "from finn.analysis.fpgadataflow.exp_cycles_per_layer import exp_cycles_per_layer\n",
    "from finn.analysis.fpgadataflow.res_estimation import (\n",
    "    res_estimation,\n",
    "    res_estimation_complete\n",
    ")\n",
    "from finn.analysis.fpgadataflow.op_and_param_counts import (\n",
    "    aggregate_dict_keys,\n",
    "    op_and_param_counts\n",
    ")\n",
    "from finn.analysis.fpgadataflow.dataflow_performance import dataflow_performance\n",
    "from finn.analysis.fpgadataflow.hls_synth_res_estimation import hls_synth_res_estimation\n",
    "from finn.transformation.fpgadataflow.prepare_rtlsim import PrepareRTLSim\n",
    "from finn.core.throughput_test import throughput_test_rtlsim\n",
    "from copy import deepcopy\n",
    "from finn.transformation.fpgadataflow.vitis_build import (\n",
    "    VitisOptStrategy,\n",
    "    VitisBuild\n",
    ")\n",
    "from finn.transformation.general import ApplyConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f22ec5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataflow_partition0_6ozjxmlt\t\t    end2end_quartznet_streamline.onnx\r\n",
      "dataflow_partition0_w509dzku\t\t    end2end_quartznet_tidy.onnx\r\n",
      "dataflow_partition1_2uh492jg\t\t    folding_config.json\r\n",
      "dataflow_partition2_i_cp5_2l\t\t    folding_config_fifos.json\r\n",
      "end2end_quartznet_dataflow_partition.onnx   librispeech_data\r\n",
      "end2end_quartznet_export_dev.onnx\t    outputs_test.npy\r\n",
      "end2end_quartznet_fifos.onnx\t\t    partitioning_lowering\r\n",
      "end2end_quartznet_folded.onnx\t\t    partitioning_repartition\r\n",
      "end2end_quartznet_hls_layers.onnx\t    qce_alveo_v2\r\n",
      "end2end_quartznet_lowered.onnx\t\t    qce_alveo_v2.zip\r\n",
      "end2end_quartznet_lowered_partitioned.onnx  vitis_link_proj_qce_alveo_v2.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /workspace/results/syn_baseline_v2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a1dc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quartznet.py  quartznet_val.py\ttime_cpu_bs_100.npy  time_cpu_bs_250.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls /workspace/results/brevitas_benchmark/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f572f66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 2)\n",
      "26.63143563270569\n",
      "1496.0341720581055\n",
      "1.980140209197998\n",
      "1524.6822412014008\n"
     ]
    }
   ],
   "source": [
    "a = np.load(\"/workspace/results/brevitas_benchmark/time_cpu_bs_100.npy\", allow_pickle=True)\n",
    "\n",
    "print(np.shape(a))\n",
    "#print(a)\n",
    "pre_process = 0\n",
    "qn = 0\n",
    "decoder = 0\n",
    "total = 0\n",
    "for i in range(29):\n",
    "    batch = a[i][:]\n",
    "    total = total + batch[0]\n",
    "    pre_process = pre_process + batch[1][0]\n",
    "    qn = qn + batch[1][1]\n",
    "    decoder = decoder + batch[1][2]\n",
    "\n",
    "print(pre_process)\n",
    "print(qn)\n",
    "print(decoder)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff8633f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/workspace/results/temp/end2end_quartznet_fifos.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe2c9e87c88>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(\"/workspace/results/temp/end2end_quartznet_fifos.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "663c968a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/workspace/results/syn_optimized_buffer/end2end_quartznet_bitfile.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe3708a7780>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(\"/workspace/results/syn_optimized_buffer/end2end_quartznet_bitfile.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b155e64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/workspace/results/syn_baseline_v2/end2end_quartznet_export_dev.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe388cf7400>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(\"/workspace/results/syn_baseline_v2/end2end_quartznet_export_dev.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c60e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(\"/workspace/results/syn_baseline_v2/end2end_quartznet_export_dev.onnx\")\n",
    "\n",
    "model = model.transform(Change3DTo4DTensors())\n",
    "# Absorb sign bias from export into MultiThreshold node\n",
    "model = model.transform(AbsorbSignBiasIntoMultiThreshold())\n",
    "# Collapse BatchNorm to Add and Mul\n",
    "model = model.transform(BatchNormToAffine())\n",
    "# Group multiplications\n",
    "model = model.transform(MoveMulPastFork())\n",
    "model = model.transform(MoveScalarMulPastConv())\n",
    "model = model.transform(MoveMulPastDWConv())\n",
    "# Move Mul/Add past join node\n",
    "model = model.transform(MoveLinearPastEltwiseAdd())\n",
    "# Collapes additions & multiplications\n",
    "model = model.transform(CollapseRepeatedAdd())\n",
    "model = model.transform(CollapseRepeatedMul())\n",
    "# Absorb Add/Mul into multithreshold\n",
    "model = model.transform(AbsorbAddIntoMultiThreshold())\n",
    "model = model.transform(FactorOutMulSignMagnitude())\n",
    "model = model.transform(Absorb1BitMulIntoConv())\n",
    "model = model.transform(AbsorbMulIntoMultiThreshold())\n",
    "\n",
    "# Ensure thresholds are integers\n",
    "## Add quantization annotation to ensure RoundAndClipThresholds works\n",
    "global_input_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_input_name, DataType.INT8)\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RoundAndClipThresholds())\n",
    "\n",
    "# Remove floating point scalar multiplication before argmax\n",
    "mul_nodes = [x for x in model.graph.node if (x.op_type==\"Mul\")]\n",
    "for n_mul in mul_nodes:\n",
    "    input_mul = n_mul.input[0]\n",
    "    node_after_mul = model.find_consumer(n_mul.output[0])\n",
    "    node_after_mul.input[0] = input_mul\n",
    "    model.graph.node.remove(n_mul)\n",
    "\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveRandomTensorNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(GiveUniqueParameterTensors())\n",
    "\n",
    "model.save(\"/tmp/model1.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1452ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/model1.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f17957cb6a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(\"/tmp/model1.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb4ac6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(\"/tmp/model1.onnx\")\n",
    "partitionings = {1: range(2, 75),\n",
    "                2: range(75, 147),\n",
    "                3: range(147, 219),\n",
    "                4: range(219, 291),\n",
    "                5: range(291, 363),\n",
    "                6: range(363, 375)}\n",
    "model = model.transform(PartitionFromDict(partitionings))\n",
    "\n",
    "idx=0\n",
    "for n in model.graph.node:\n",
    "    if n.op_type==\"GenericPartition\":\n",
    "        path_to_partition = get_by_name(n.attribute, \"model\", \"name\").s.decode('utf-8')\n",
    "        model_partition = ModelWrapper(path_to_partition)\n",
    "        # Lowering\n",
    "        model_partition = model_partition.transform(LowerConvsToMatMul())\n",
    "        # Absorb transpose node\n",
    "        model_partition = model_partition.transform(AbsorbTransposeIntoMultiThreshold())\n",
    "        # Reorder remaining transpose nodes\n",
    "        model_partition = model_partition.transform(MoveTransposePastMultiThreshold())\n",
    "        model_partition = model_partition.transform(MoveTransposePastJoinAdd())\n",
    "        model_partition = model_partition.transform(MoveTransposeBeforeFork())\n",
    "\n",
    "        model_partition.save(path_to_partition)\n",
    "        \n",
    "        idx+=1\n",
    "        if idx==2:\n",
    "            break\n",
    "        \n",
    "model.save(\"/tmp/model2.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa4d0a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/model2.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f17944aa358>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(\"/tmp/model2.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8279ab7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/finn_dev_mirza/partitioning_hiptu4p7/partition_2.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f17944aa080>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(\"/tmp/finn_dev_mirza/partitioning_hiptu4p7/partition_2.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
