{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "045c055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from onnx import TensorProto, helper\n",
    "\n",
    "import finn.core.onnx_exec as oxe\n",
    "from finn.analysis.fpgadataflow.hls_synth_res_estimation import hls_synth_res_estimation\n",
    "from finn.core.datatype import DataType\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.custom_op.general.multithreshold import multithreshold\n",
    "from finn.transformation.fpgadataflow.prepare_ip import PrepareIP\n",
    "from finn.transformation.fpgadataflow.prepare_cppsim import PrepareCppSim\n",
    "from finn.transformation.fpgadataflow.compile_cppsim import CompileCppSim\n",
    "from finn.transformation.fpgadataflow.hlssynth_ip import HLSSynthIP\n",
    "from finn.transformation.fpgadataflow.set_exec_mode import SetExecMode\n",
    "from finn.transformation.general import GiveUniqueNodeNames\n",
    "from finn.transformation.fpgadataflow.prepare_rtlsim import PrepareRTLSim\n",
    "from finn.util.basic import gen_finn_dt_tensor\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "from finn.analysis.fpgadataflow.exp_cycles_per_layer import exp_cycles_per_layer\n",
    "import os\n",
    "from finn.util.pyverilator import axilite_read, axilite_write\n",
    "from finn.transformation.fpgadataflow.create_stitched_ip import CreateStitchedIP\n",
    "from finn.core.rtlsim_exec import rtlsim_exec\n",
    "import finn.core.data_layout as DataLayout\n",
    "import finn.transformation.fpgadataflow .convert_to_hls_layers as to_hls\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.infer_data_layouts import InferDataLayouts\n",
    "\n",
    "test_fpga_part = \"xc7z020clg400-1\"\n",
    "target_clk_ns = 5\n",
    "\n",
    "\n",
    "def make_single_thresholding_onnx(T, idt, odt, wdt):\n",
    "    NumChannels = T.shape[0]\n",
    "    out_bias = float(odt.min())\n",
    "    \n",
    "    inp = helper.make_tensor_value_info(\n",
    "        \"inp\", TensorProto.FLOAT, [1, NumChannels, 128, 1]\n",
    "    )\n",
    "    outp = helper.make_tensor_value_info(\n",
    "        \"outp\", TensorProto.FLOAT, [1, NumChannels, 128, 1]\n",
    "    )\n",
    "\n",
    "    mt_node = helper.make_node(\n",
    "        \"MultiThreshold\",\n",
    "        [\"inp\", \"thresh\"],\n",
    "        [\"outp\"],\n",
    "        domain=\"finn.custom_op.general\",\n",
    "        out_bias=out_bias,\n",
    "        out_dtype=\"INT8\",\n",
    "        data_layout=\"NCHW\"\n",
    "    )\n",
    "    graph = helper.make_graph(\n",
    "        nodes=[mt_node], name=\"mt_graph\", inputs=[inp], outputs=[outp]\n",
    "    )\n",
    "\n",
    "    model = helper.make_model(graph, producer_name=\"mtnode-model\")\n",
    "    model = ModelWrapper(model)\n",
    "\n",
    "    model.set_tensor_datatype(\"inp\", idt)\n",
    "    model.set_tensor_datatype(\"outp\", odt)\n",
    "    model.set_tensor_datatype(\"thres\", idt)\n",
    "    \n",
    "    model.set_initializer(\"thresh\", T)\n",
    "    model.set_tensor_shape(\"thresh\", T.shape)\n",
    "    model.set_tensor_layout(\"inp\", DataLayout.NCHW)\n",
    "    \n",
    "    model = model.transform(InferShapes())\n",
    "\n",
    "    return model\n",
    "\n",
    "def make_single_thresholding_modelwrapper(T, pe, idt, odt, actval, mem_mode):\n",
    "    NumChannels = T.shape[0]\n",
    "\n",
    "    inp = helper.make_tensor_value_info(\"inp\", TensorProto.FLOAT, [1, 128, 1, NumChannels])\n",
    "    outp = helper.make_tensor_value_info(\"outp\", TensorProto.FLOAT, [1, 128, 1, NumChannels])\n",
    "    \n",
    "    node_inp_list = [\"inp\", \"thresh\"]\n",
    "\n",
    "    Thresholding_node = helper.make_node(\n",
    "        \"Thresholding_Batch\",\n",
    "        node_inp_list,\n",
    "        [\"outp\"],\n",
    "        domain=\"finn.custom_op.fpgadataflow\",\n",
    "        backend=\"fpgadataflow\",\n",
    "        NumChannels=NumChannels,\n",
    "        PE=pe,\n",
    "        numSteps=T.shape[1],\n",
    "        inputDataType=idt.name,\n",
    "        weightDataType=idt.name,  # will be set by MinimizeAccumulatorWidth\n",
    "        outputDataType=odt.name,\n",
    "        ActVal=actval,\n",
    "        mem_mode=mem_mode,\n",
    "        numInputVectors=(1,128,1)\n",
    "    )\n",
    "    graph = helper.make_graph(\n",
    "        nodes=[Thresholding_node],\n",
    "        name=\"thresholding_graph\",\n",
    "        inputs=[inp],\n",
    "        outputs=[outp],\n",
    "    )\n",
    "\n",
    "    model = helper.make_model(graph, producer_name=\"thresholding-model\")\n",
    "    model = ModelWrapper(model)\n",
    "\n",
    "    model.set_tensor_datatype(\"inp\", idt)\n",
    "    model.set_tensor_datatype(\"outp\", odt)\n",
    "\n",
    "    model.set_tensor_datatype(\"thresh\", idt)\n",
    "    model.set_initializer(\"thresh\", T)\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "def test_fpgadataflow_thresholding(idt, act, nf, ich, exec_mode, mem_mode):\n",
    "    if nf == -1:\n",
    "        nf = ich\n",
    "    pe = ich // nf\n",
    "    assert ich % pe == 0\n",
    "\n",
    "    # generate input data\n",
    "    x = gen_finn_dt_tensor(idt, (1, 128, 1, ich))\n",
    "\n",
    "    odt = act\n",
    "    n_steps = act.get_num_possible_values() - 1\n",
    "    T = np.random.randint(idt.min(), idt.max() + 1, (ich, n_steps)).astype(np.float32)\n",
    "    # make the vivado_hls threshold bug appear (incorrect rtlsim result when first\n",
    "    # threshold of first channel is zero, while using BIPOLAR output)\n",
    "    if act == DataType.BIPOLAR:\n",
    "        T[0][0] = 0\n",
    "    # provide non-decreasing thresholds\n",
    "    T = np.sort(T, axis=1)\n",
    "\n",
    "    if odt == DataType.BIPOLAR:\n",
    "        actval = 0\n",
    "    else:\n",
    "        actval = odt.min()\n",
    "\n",
    "    model = make_single_thresholding_modelwrapper(T, pe, idt, odt, actval, mem_mode)\n",
    "    model.save(\"/tmp/fpgadataflow_threshold.onnx\")\n",
    "    \n",
    "    if exec_mode == \"cppsim\":\n",
    "        model = model.transform(PrepareCppSim())\n",
    "        model = model.transform(CompileCppSim())\n",
    "        model = model.transform(SetExecMode(\"cppsim\"))\n",
    "    elif exec_mode == \"rtlsim\":\n",
    "        model = model.transform(SetExecMode(\"rtlsim\"))\n",
    "        model = model.transform(GiveUniqueNodeNames())\n",
    "        model = model.transform(PrepareIP(test_fpga_part, target_clk_ns))\n",
    "        model = model.transform(HLSSynthIP())\n",
    "        model = model.transform(PrepareRTLSim())\n",
    "    else:\n",
    "        raise Exception(\"Unknown exec_mode\")\n",
    "\n",
    "    model.save(\"/tmp/threshold_model_compiled.onnx\")\n",
    "        \n",
    "    # package input data as dictionary\n",
    "    input_dict = {\"inp\": x}\n",
    "\n",
    "    # ONNX assumes NCHW format\n",
    "    # HLS-lib assumes NHWC format\n",
    "    x_onnx = np.transpose(x, (0, 3, 1, 2)) # NHWC -> NCHW\n",
    "    y = multithreshold(x_onnx, T)\n",
    "    if act == DataType.BIPOLAR:\n",
    "        # binary to bipolar\n",
    "        y = 2 * y - 1\n",
    "    else:\n",
    "        # signed offset\n",
    "        y += act.min()\n",
    "    y = np.transpose(y, (0, 2, 3, 1)) # NCHW -> NHWC\n",
    "\n",
    "    oshape = model.get_tensor_shape(\"outp\")\n",
    "    y_expected = y.reshape(oshape)\n",
    "    # execute model\n",
    "    y_produced = oxe.execute_onnx(model, input_dict)[\"outp\"]\n",
    "\n",
    "    y_produced = y_produced.reshape(y_expected.shape)\n",
    "\n",
    "    assert (y_produced == y_expected).all(), \"cppsim failed\"\n",
    "\n",
    "    if exec_mode == \"rtlsim\":\n",
    "        hls_synt_res_est = model.analysis(hls_synth_res_estimation)\n",
    "        assert \"Thresholding_Batch_0\" in hls_synt_res_est\n",
    "\n",
    "        node = model.get_nodes_by_op_type(\"Thresholding_Batch\")[0]\n",
    "        inst = getCustomOp(node)\n",
    "        cycles_rtlsim = inst.get_nodeattr(\"cycles_rtlsim\")\n",
    "        exp_cycles_dict = model.analysis(exp_cycles_per_layer)\n",
    "        exp_cycles = exp_cycles_dict[node.name]\n",
    "        assert np.isclose(exp_cycles, cycles_rtlsim, atol=10)\n",
    "        assert exp_cycles != 0\n",
    "\n",
    "\n",
    "def test_runtime_thresholds_single_layer():\n",
    "    mem_mode = \"decoupled\"\n",
    "    act = DataType.INT4\n",
    "    idt = DataType.INT16\n",
    "    nf = 8\n",
    "    ich = 16\n",
    "    pe = ich // nf\n",
    "    assert ich % pe == 0\n",
    "\n",
    "    # generate input data\n",
    "    in_tensor = gen_finn_dt_tensor(idt, (1, ich))\n",
    "\n",
    "    odt = act\n",
    "    n_steps = act.get_num_possible_values() - 1\n",
    "    T = np.random.randint(idt.min(), idt.max() + 1, (ich, n_steps)).astype(np.float32)\n",
    "    # provide non-decreasing thresholds\n",
    "    T = np.sort(T, axis=1)\n",
    "\n",
    "    if odt == DataType.BIPOLAR:\n",
    "        actval = 0\n",
    "    else:\n",
    "        actval = odt.min()\n",
    "\n",
    "    model = make_single_thresholding_modelwrapper(T, pe, idt, odt, actval, mem_mode)\n",
    "    op_inst = getCustomOp(model.graph.node[0])\n",
    "    op_inst.set_nodeattr(\"runtime_writeable_weights\", 1)\n",
    "    op_inst.make_weight_file(T, \"decoupled_runtime\", \"old_weights.dat\")\n",
    "    with open(\"old_weights.dat\", \"r\") as f:\n",
    "        old_weight_stream = f.read().strip()\n",
    "    os.remove(\"old_weights.dat\")\n",
    "    old_weight_stream = map(lambda x: int(x, 16), old_weight_stream.split(\"\\n\"))\n",
    "    old_weight_stream = list(old_weight_stream)\n",
    "    # need to create stitched IP for runtime weight testing\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    model = model.transform(PrepareIP(test_fpga_part, target_clk_ns))\n",
    "    model = model.transform(HLSSynthIP())\n",
    "    model = model.transform(CreateStitchedIP(test_fpga_part, target_clk_ns))\n",
    "    model = model.transform(PrepareRTLSim())\n",
    "    model.set_metadata_prop(\"exec_mode\", \"rtlsim\")\n",
    "    # add two copies of the input tensor as the first one is just used to\n",
    "    # \"flush out\" the pipeline (as mvau already starts receiving old weights while\n",
    "    # we read/write new ones and reads seem to cause a disturbance too)\n",
    "    in_tensor = np.tile(in_tensor, (2, 1))\n",
    "    exec_ctx = {\"inp\": in_tensor}\n",
    "    extracted_weight_stream = []\n",
    "\n",
    "    def read_weights(sim):\n",
    "        addr = 0\n",
    "        for i in range(len(old_weight_stream)):\n",
    "            extracted_weight_stream.append(\n",
    "                axilite_read(sim, addr, basename=\"s_axilite_0_\")\n",
    "            )\n",
    "            addr += 4\n",
    "\n",
    "    rtlsim_exec(model, exec_ctx, pre_hook=read_weights)\n",
    "    assert extracted_weight_stream == old_weight_stream\n",
    "    # only use second batch element in output; first will be invalid due to\n",
    "    # old weights (see above)\n",
    "    y = exec_ctx[\"outp\"][1]\n",
    "    expected = multithreshold(in_tensor, T)[1]\n",
    "    if act == DataType.BIPOLAR:\n",
    "        # binary to bipolar\n",
    "        expected = 2 * expected - 1\n",
    "    else:\n",
    "        # signed offset\n",
    "        expected += act.min()\n",
    "    assert (y == expected).all()\n",
    "\n",
    "    new_weights = np.random.randint(idt.min(), idt.max() + 1, (ich, n_steps)).astype(\n",
    "        np.float32\n",
    "    )\n",
    "    # provide non-decreasing thresholds\n",
    "    new_weights = np.sort(T, axis=1)\n",
    "    op_inst.make_weight_file(new_weights, \"decoupled_runtime\", \"new_weights.dat\")\n",
    "    with open(\"new_weights.dat\", \"r\") as f:\n",
    "        new_weight_stream = f.read().strip()\n",
    "    os.remove(\"new_weights.dat\")\n",
    "    new_weight_stream = map(lambda x: int(x, 16), new_weight_stream.split(\"\\n\"))\n",
    "    new_weight_stream = list(new_weight_stream)\n",
    "\n",
    "    def write_weights(sim):\n",
    "        addr = 0\n",
    "        for nw in new_weight_stream:\n",
    "            axilite_write(sim, addr, nw, basename=\"s_axilite_0_\")\n",
    "            addr += 4\n",
    "\n",
    "    rtlsim_exec(model, exec_ctx, pre_hook=write_weights)\n",
    "    y = exec_ctx[\"outp\"][1]\n",
    "    expected = multithreshold(in_tensor, new_weights)[1]\n",
    "    if act == DataType.BIPOLAR:\n",
    "        # binary to bipolar\n",
    "        expected = 2 * expected - 1\n",
    "    else:\n",
    "        # signed offset\n",
    "        expected += act.min()\n",
    "    assert (y == expected).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b35ee5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# activation: None or DataType\n",
    "act = DataType.INT8\n",
    "# input datatype\n",
    "idt = DataType.INT16\n",
    "# folding, -1 is maximum possible\n",
    "nf = 64\n",
    "#@pytest.mark.parametrize(\"nf\", [-1, 2, 1])\n",
    "# number of input features\n",
    "ich = 64\n",
    "# execution mode\n",
    "exec_mode = \"cppsim\" \n",
    "#exec_mode = \"rtlsim\" \n",
    "# memory mode\n",
    "mem_mode = \"const\"\n",
    "\n",
    "test_fpgadataflow_thresholding(idt, act, nf, ich, exec_mode, mem_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1023f083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/fpgadataflow_threshold.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f96a8144d00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "showInNetron(\"/tmp/fpgadataflow_threshold.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb3b55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c20bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c11d887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code_gen_cppsim__0803bwbs\r\n",
      "code_gen_cppsim__0adxbp2s\r\n",
      "code_gen_cppsim__0gpvwazg\r\n",
      "code_gen_cppsim__0j37lujb\r\n",
      "code_gen_cppsim__0kii_5_g\r\n",
      "code_gen_cppsim__0li_bkch\r\n",
      "code_gen_cppsim__0qhngowl\r\n",
      "code_gen_cppsim__0u8nyiu0\r\n",
      "code_gen_cppsim__0un191yw\r\n",
      "code_gen_cppsim__0vkn17z5\r\n",
      "code_gen_cppsim__0z_0sy6b\r\n",
      "code_gen_cppsim__10fhabui\r\n",
      "code_gen_cppsim__135lr9vh\r\n",
      "code_gen_cppsim__1_j3g77f\r\n",
      "code_gen_cppsim__1jppdo4q\r\n",
      "code_gen_cppsim__1mjyzkcg\r\n",
      "code_gen_cppsim__1ofzcpl1\r\n",
      "code_gen_cppsim__1oyrqrfp\r\n",
      "code_gen_cppsim__1qm_jopy\r\n",
      "code_gen_cppsim__216jy8lp\r\n",
      "code_gen_cppsim__23o44vf8\r\n",
      "code_gen_cppsim__276z_o1y\r\n",
      "code_gen_cppsim__2i0qzfy3\r\n",
      "code_gen_cppsim__2kqw03fs\r\n",
      "code_gen_cppsim__2rzk90td\r\n",
      "code_gen_cppsim__324w97ad\r\n",
      "code_gen_cppsim__33tcosio\r\n",
      "code_gen_cppsim__35el0yrc\r\n",
      "code_gen_cppsim__3hxpyi1p\r\n",
      "code_gen_cppsim__3q36wf5c\r\n",
      "code_gen_cppsim__3u1dmw3x\r\n",
      "code_gen_cppsim__3u75vs2w\r\n",
      "code_gen_cppsim__3zcch8ca\r\n",
      "code_gen_cppsim__3zer_hxw\r\n",
      "code_gen_cppsim__44be2xy1\r\n",
      "code_gen_cppsim__4_rt0276\r\n",
      "code_gen_cppsim__4k4pse8a\r\n",
      "code_gen_cppsim__50urovan\r\n",
      "code_gen_cppsim__55q5qsog\r\n",
      "code_gen_cppsim__5fo63_wq\r\n",
      "code_gen_cppsim__5g8i6nl5\r\n",
      "code_gen_cppsim__5jbd2czk\r\n",
      "code_gen_cppsim__5jiqdauy\r\n",
      "code_gen_cppsim__5kpmthv7\r\n",
      "code_gen_cppsim__5lt9ai1o\r\n",
      "code_gen_cppsim__5tyw851c\r\n",
      "code_gen_cppsim__5w1brzeq\r\n",
      "code_gen_cppsim__65j04h3t\r\n",
      "code_gen_cppsim__6ap55w9v\r\n",
      "code_gen_cppsim__6atv34yz\r\n",
      "code_gen_cppsim__6lhcqdgw\r\n",
      "code_gen_cppsim__6phjjtc6\r\n",
      "code_gen_cppsim__772cna5_\r\n",
      "code_gen_cppsim__7cjpbelx\r\n",
      "code_gen_cppsim__7jtb29_o\r\n",
      "code_gen_cppsim__7mq47duo\r\n",
      "code_gen_cppsim__7xdjqy93\r\n",
      "code_gen_cppsim__82a3k9jg\r\n",
      "code_gen_cppsim__86fj9u2p\r\n",
      "code_gen_cppsim__86ueo_9h\r\n",
      "code_gen_cppsim__87y1g8h0\r\n",
      "code_gen_cppsim__88piin4s\r\n",
      "code_gen_cppsim__8ekewfo4\r\n",
      "code_gen_cppsim__8g5jl757\r\n",
      "code_gen_cppsim__8ies001s\r\n",
      "code_gen_cppsim__8jo_j1w2\r\n",
      "code_gen_cppsim__8jqpff84\r\n",
      "code_gen_cppsim__8mmiauhp\r\n",
      "code_gen_cppsim__8nikd8he\r\n",
      "code_gen_cppsim__8vzm_fuw\r\n",
      "code_gen_cppsim__8z4s4hq9\r\n",
      "code_gen_cppsim__8zix1boa\r\n",
      "code_gen_cppsim__9008qtda\r\n",
      "code_gen_cppsim__92uh3fz2\r\n",
      "code_gen_cppsim__9vx_4ykh\r\n",
      "code_gen_cppsim___7vdzi3p\r\n",
      "code_gen_cppsim___8j83nkp\r\n",
      "code_gen_cppsim___oh5dnol\r\n",
      "code_gen_cppsim___vg0flkb\r\n",
      "code_gen_cppsim___zke7b1v\r\n",
      "code_gen_cppsim__a1vshouw\r\n",
      "code_gen_cppsim__a2imlvuj\r\n",
      "code_gen_cppsim__a4xreflx\r\n",
      "code_gen_cppsim__a8fdd3vt\r\n",
      "code_gen_cppsim__aal6lezo\r\n",
      "code_gen_cppsim__agihh7n6\r\n",
      "code_gen_cppsim__ahnki_l9\r\n",
      "code_gen_cppsim__aiyflc4o\r\n",
      "code_gen_cppsim__akxwi_e_\r\n",
      "code_gen_cppsim__am7schm7\r\n",
      "code_gen_cppsim__anzy0r5s\r\n",
      "code_gen_cppsim__aqkftxtp\r\n",
      "code_gen_cppsim__av2x9ncs\r\n",
      "code_gen_cppsim__av_nd6ld\r\n",
      "code_gen_cppsim__b8j0i00f\r\n",
      "code_gen_cppsim__bfxo9x7m\r\n",
      "code_gen_cppsim__bwek3n3s\r\n",
      "code_gen_cppsim__bwrn961f\r\n",
      "code_gen_cppsim__bzt3nk4h\r\n",
      "code_gen_cppsim__c6v31arj\r\n",
      "code_gen_cppsim__c7wdmuo3\r\n",
      "code_gen_cppsim__c951e9w5\r\n",
      "code_gen_cppsim__c96zzgqh\r\n",
      "code_gen_cppsim__cb0ktg0h\r\n",
      "code_gen_cppsim__ccgcl9z4\r\n",
      "code_gen_cppsim__ccqqy9jm\r\n",
      "code_gen_cppsim__ch_fkhe_\r\n",
      "code_gen_cppsim__chbb25s_\r\n",
      "code_gen_cppsim__ci7mk9fe\r\n",
      "code_gen_cppsim__cida_lj1\r\n",
      "code_gen_cppsim__cl2w2ldd\r\n",
      "code_gen_cppsim__cm1x_oht\r\n",
      "code_gen_cppsim__cnebde9k\r\n",
      "code_gen_cppsim__co48rtoc\r\n",
      "code_gen_cppsim__d0pe_d_5\r\n",
      "code_gen_cppsim__d1xl9jas\r\n",
      "code_gen_cppsim__d6qwjud7\r\n",
      "code_gen_cppsim__d_8uplg_\r\n",
      "code_gen_cppsim__dh_261g4\r\n",
      "code_gen_cppsim__dhlel1eb\r\n",
      "code_gen_cppsim__dj0i51rl\r\n",
      "code_gen_cppsim__dtt1ahwj\r\n",
      "code_gen_cppsim__e3m0phj5\r\n",
      "code_gen_cppsim__e4qn_uyo\r\n",
      "code_gen_cppsim__ed2thp5n\r\n",
      "code_gen_cppsim__eiwr977i\r\n",
      "code_gen_cppsim__eosv5vu4\r\n",
      "code_gen_cppsim__ez3pq7au\r\n",
      "code_gen_cppsim__ffe0nyfw\r\n",
      "code_gen_cppsim__fin547nh\r\n",
      "code_gen_cppsim__fl6vtep_\r\n",
      "code_gen_cppsim__fn2pvhkk\r\n",
      "code_gen_cppsim__fnensbqb\r\n",
      "code_gen_cppsim__fpn_pmz3\r\n",
      "code_gen_cppsim__fwv6bel1\r\n",
      "code_gen_cppsim__g4nwqp5h\r\n",
      "code_gen_cppsim__gadr287t\r\n",
      "code_gen_cppsim__gdqk_2fj\r\n",
      "code_gen_cppsim__gqeu6oat\r\n",
      "code_gen_cppsim__gr3f9yx_\r\n",
      "code_gen_cppsim__gttt1eud\r\n",
      "code_gen_cppsim__i8k6tcwn\r\n",
      "code_gen_cppsim__idw08ns8\r\n",
      "code_gen_cppsim__ihk69d79\r\n",
      "code_gen_cppsim__itkjlrlt\r\n",
      "code_gen_cppsim__iulnk4gy\r\n",
      "code_gen_cppsim__iw3ig1zp\r\n",
      "code_gen_cppsim__ixjx4jmz\r\n",
      "code_gen_cppsim__j2s9golx\r\n",
      "code_gen_cppsim__j2ya72hm\r\n",
      "code_gen_cppsim__j7eem1wr\r\n",
      "code_gen_cppsim__jaazedsm\r\n",
      "code_gen_cppsim__jdgfam35\r\n",
      "code_gen_cppsim__jhke28u2\r\n",
      "code_gen_cppsim__jjhjiz8b\r\n",
      "code_gen_cppsim__jkpm04lu\r\n",
      "code_gen_cppsim__jm3xw35s\r\n",
      "code_gen_cppsim__jp15_ol3\r\n",
      "code_gen_cppsim__jw9_p2um\r\n",
      "code_gen_cppsim__k257hu1a\r\n",
      "code_gen_cppsim__k3o_s9s1\r\n",
      "code_gen_cppsim__k7s0iq17\r\n",
      "code_gen_cppsim__kag88h0i\r\n",
      "code_gen_cppsim__kesunmdg\r\n",
      "code_gen_cppsim__kny5edme\r\n",
      "code_gen_cppsim__ku0geqc4\r\n",
      "code_gen_cppsim__l1h_852i\r\n",
      "code_gen_cppsim__lqwba1h3\r\n",
      "code_gen_cppsim__lsy00dts\r\n",
      "code_gen_cppsim__lu3c7roh\r\n",
      "code_gen_cppsim__m_yxjscn\r\n",
      "code_gen_cppsim__moy_s5ca\r\n",
      "code_gen_cppsim__mruy2iex\r\n",
      "code_gen_cppsim__msujis9s\r\n",
      "code_gen_cppsim__msxwczvr\r\n",
      "code_gen_cppsim__mz_6xuxk\r\n",
      "code_gen_cppsim__n5aewclq\r\n",
      "code_gen_cppsim__n8e2zjxo\r\n",
      "code_gen_cppsim__n98ji_hy\r\n",
      "code_gen_cppsim__nhxewh1b\r\n",
      "code_gen_cppsim__nio7py66\r\n",
      "code_gen_cppsim__nkvw0deq\r\n",
      "code_gen_cppsim__nli2ts38\r\n",
      "code_gen_cppsim__npom60h8\r\n",
      "code_gen_cppsim__o0pvj46y\r\n",
      "code_gen_cppsim__o2f0hjja\r\n",
      "code_gen_cppsim__o787pval\r\n",
      "code_gen_cppsim__ob25ew53\r\n",
      "code_gen_cppsim__oe9gw2pj\r\n",
      "code_gen_cppsim__ok5y_pdt\r\n",
      "code_gen_cppsim__oqpdqll0\r\n",
      "code_gen_cppsim__p2158lhh\r\n",
      "code_gen_cppsim__pdri2n5x\r\n",
      "code_gen_cppsim__pq750mco\r\n",
      "code_gen_cppsim__prghafxi\r\n",
      "code_gen_cppsim__q3b2qezl\r\n",
      "code_gen_cppsim__q7xuyv67\r\n",
      "code_gen_cppsim__qcc82eec\r\n",
      "code_gen_cppsim__qizlkbce\r\n",
      "code_gen_cppsim__qjg3zgbm\r\n",
      "code_gen_cppsim__qow0oq1v\r\n",
      "code_gen_cppsim__rdx12sry\r\n",
      "code_gen_cppsim__rhdidue3\r\n",
      "code_gen_cppsim__ri5rfn3r\r\n",
      "code_gen_cppsim__rke8cot1\r\n",
      "code_gen_cppsim__rny0x9xw\r\n",
      "code_gen_cppsim__rpdbgiq3\r\n",
      "code_gen_cppsim__rwnnh5za\r\n",
      "code_gen_cppsim__rzghsk6_\r\n",
      "code_gen_cppsim__s5yjbqch\r\n",
      "code_gen_cppsim__s67gjc8t\r\n",
      "code_gen_cppsim__s77yocb6\r\n",
      "code_gen_cppsim__sbzwp89y\r\n",
      "code_gen_cppsim__sch6j9z9\r\n",
      "code_gen_cppsim__sps8pf3q\r\n",
      "code_gen_cppsim__sq031j31\r\n",
      "code_gen_cppsim__ss1qzfpp\r\n",
      "code_gen_cppsim__stmc92kg\r\n",
      "code_gen_cppsim__svh6bngq\r\n",
      "code_gen_cppsim__t9q_z3ft\r\n",
      "code_gen_cppsim__tfk58_vk\r\n",
      "code_gen_cppsim__tkod2hxl\r\n",
      "code_gen_cppsim__tmtw0xzp\r\n",
      "code_gen_cppsim__twdcqox_\r\n",
      "code_gen_cppsim__tz9gsxa1\r\n",
      "code_gen_cppsim__u39lfe63\r\n",
      "code_gen_cppsim__udgwlq43\r\n",
      "code_gen_cppsim__uezmvb_h\r\n",
      "code_gen_cppsim__unw4iqdb\r\n",
      "code_gen_cppsim__uw04ddxu\r\n",
      "code_gen_cppsim__uwikpzh3\r\n",
      "code_gen_cppsim__v199rj99\r\n",
      "code_gen_cppsim__v99gsh6e\r\n",
      "code_gen_cppsim__v_7u27aq\r\n",
      "code_gen_cppsim__vn1v_8_b\r\n",
      "code_gen_cppsim__vvrhz8aa\r\n",
      "code_gen_cppsim__vw_yvq29\r\n",
      "code_gen_cppsim__w129uubt\r\n",
      "code_gen_cppsim__w1s3tg0e\r\n",
      "code_gen_cppsim__w27k9zls\r\n",
      "code_gen_cppsim__w92tqbah\r\n",
      "code_gen_cppsim__w_glkkwu\r\n",
      "code_gen_cppsim__wbksiuln\r\n",
      "code_gen_cppsim__widhtvxq\r\n",
      "code_gen_cppsim__wq6i1nih\r\n",
      "code_gen_cppsim__x1kvs_pz\r\n",
      "code_gen_cppsim__x3vkpqi5\r\n",
      "code_gen_cppsim__x5ya249a\r\n",
      "code_gen_cppsim__xifsrrgz\r\n",
      "code_gen_cppsim__xk5h52_3\r\n",
      "code_gen_cppsim__xsumr193\r\n",
      "code_gen_cppsim__xv5ph5r0\r\n",
      "code_gen_cppsim__xzsl7wx3\r\n",
      "code_gen_cppsim__y0w0je5i\r\n",
      "code_gen_cppsim__y2jbjgrv\r\n",
      "code_gen_cppsim__y3b5xik2\r\n",
      "code_gen_cppsim__ye9in1yv\r\n",
      "code_gen_cppsim__ygj22fcl\r\n",
      "code_gen_cppsim__yif8o3zt\r\n",
      "code_gen_cppsim__ypnlig7e\r\n",
      "code_gen_cppsim__yql_ua2e\r\n",
      "code_gen_cppsim__z9_nfsd_\r\n",
      "code_gen_cppsim__zd1_wwr8\r\n",
      "code_gen_cppsim__zfk1p1ku\r\n",
      "code_gen_cppsim__zjy69g8x\r\n",
      "code_gen_cppsim__ztz8qcjs\r\n",
      "code_gen_ipgen_AddStreams_Batch_0_lqsrdcn1\r\n",
      "code_gen_ipgen_ConvolutionInputGenerator1D_0_6jf8hiyh\r\n",
      "code_gen_ipgen_ConvolutionInputGenerator1D_1_0u1qcto8\r\n",
      "code_gen_ipgen_ConvolutionInputGenerator1D_2_ozsnzvo9\r\n",
      "code_gen_ipgen_ConvolutionInputGenerator1D_3_y2xurbtt\r\n",
      "code_gen_ipgen_ConvolutionInputGenerator1D_4_cs69ccfb\r\n",
      "code_gen_ipgen_DuplicateStreams_Batch_0_wu_5u4it\r\n",
      "code_gen_ipgen_FMPadding_Batch_0_dkhdlsgz\r\n",
      "code_gen_ipgen_FMPadding_Batch_1_ssn2ygw8\r\n",
      "code_gen_ipgen_FMPadding_Batch_2_5p639i3a\r\n",
      "code_gen_ipgen_FMPadding_Batch_3_7kbmzokc\r\n",
      "code_gen_ipgen_FMPadding_Batch_4_maqsmsod\r\n",
      "code_gen_ipgen_Vector_Vector_Activate_Batch_0_7i0sr8wg\r\n",
      "code_gen_ipgen_Vector_Vector_Activate_Batch_1_9ajjufp7\r\n",
      "code_gen_ipgen_Vector_Vector_Activate_Batch_2_ipuhczgr\r\n",
      "code_gen_ipgen_Vector_Vector_Activate_Batch_3_jvqwea5t\r\n",
      "code_gen_ipgen_Vector_Vector_Activate_Batch_4_feazw4q8\r\n",
      "finn_dev_mirza\r\n",
      "hls_inferconvinpgen.onnx\r\n",
      "hls_without_threshold.onnx\r\n",
      "pre_hls.onnx\r\n",
      "threshold_model.onnx\r\n",
      "threshold_model_compiled.onnx\r\n",
      "tmp_graph.onnx\r\n"
     ]
    }
   ],
   "source": [
    "!ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ac7b632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/threshold_model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb0f47cc850>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(\"/tmp/threshold_model.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
